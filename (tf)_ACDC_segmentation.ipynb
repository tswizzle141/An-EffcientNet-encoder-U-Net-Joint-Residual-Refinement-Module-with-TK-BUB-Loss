{"cells":[{"cell_type":"markdown","metadata":{"id":"pKPWpR5ItwuX"},"source":["# Library"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1198,"status":"ok","timestamp":1669526607140,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"Ta9r81tyJg-B","outputId":"50b3b480-93e2-4d22-f7ed-4fd3c6986dd9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Nov 27 05:23:25 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22842,"status":"ok","timestamp":1669526631176,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"Ra4WRDaNJgdk","outputId":"6ffd1086-085f-4afa-b582-7438831068b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1w-TuKfFg1p_kmorgOYNhTF-HPfPcx4Ab/brain_mri_segmentation\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd \"/content/drive/MyDrive/brain_mri_segmentation\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"uMZ9kIyKwGE3","executionInfo":{"status":"ok","timestamp":1669526657005,"user_tz":-420,"elapsed":25833,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["from IPython.display import clear_output\n","!pip install import-ipynb\n","!pip install albumentations==0.4.6\n","#!pip install -U efficientnet==0.0.4\n","#!git clone https://github.com/qubvel/efficientnet.git\n","#!pip install -U efficientnet\n","!pip install -U --pre efficientnet\n","!pip install keras-unet-collection\n","!pip install tensorflow-addons\n","!pip install monai\n","clear_output()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8574,"status":"ok","timestamp":1669526665561,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"5JQ9JAM6pPXY","outputId":"e10b4ed2-d7be-4aa6-ab14-fd4127f51e21"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: MatplotlibDeprecationWarning: \n","The mpl_toolkits.axes_grid module was deprecated in Matplotlib 2.1 and will be removed two minor releases later. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist, which provide the same functionality instead.\n"]}],"source":["import sys\n","import os\n","import glob\n","from PIL import Image\n","from IPython.display import clear_output\n","import math\n","import random\n","import scipy.io as sio\n","import re\n","import time\n","from tensorflow.keras import *\n","from tensorflow.keras.utils import get_file\n","from collections import namedtuple\n","from tqdm import tqdm, tqdm_notebook\n","from fastprogress.fastprogress import master_bar, progress_bar\n","from time import sleep\n","\n","import numpy as np\n","import pandas as pd\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid import ImageGrid\n","%matplotlib inline\n","import seaborn as sns\n","import zipfile\n","from skimage import io\n","\n","import tensorflow as tf\n","from tensorflow.python.keras import Sequential\n","from tensorflow.keras import layers, optimizers\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras.initializers import glorot_uniform\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n","from tensorflow.keras.metrics import *\n","import tensorflow.keras.backend as K\n","from sklearn.preprocessing import StandardScaler, normalize\n","from tensorflow.keras.layers.experimental import preprocessing\n","from IPython.display import display\n","from efficientnet.keras import *\n","from keras_unet_collection import models\n","\n","from tensorflow.python.keras import Sequential\n","from tensorflow.keras import layers, optimizers\n","import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras.initializers import glorot_uniform\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.metrics import *\n","from tensorflow.keras.optimizers import *\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","import tensorflow_addons as tfa\n","import gc\n","import os\n","import numpy as np\n","import scipy.io as sio\n","from scipy import ndimage\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from fastprogress import master_bar, progress_bar\n","import nibabel as nib\n","from monai.metrics import compute_hausdorff_distance\n","import glob \n","from sklearn.model_selection import train_test_split\n","NUM_CLASS = 4"]},{"cell_type":"markdown","metadata":{"id":"dYCqESGJ7GSx"},"source":["# Pre-processing Data"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5gEk4sMc2S1f","executionInfo":{"status":"ok","timestamp":1669526665562,"user_tz":-420,"elapsed":5,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def flip(image, mask):\n","    if tf.cast(tf.random.uniform([], maxval=2, dtype=tf.int32), tf.bool):\n","        image = tf.image.flip_left_right(image)\n","        mask = tf.image.flip_left_right(mask)\n","\n","    if tf.cast(tf.random.uniform([], maxval=2, dtype=tf.int32), tf.bool):\n","        image = tf.image.flip_up_down(image)\n","        mask = tf.image.flip_up_down(mask)\n","    return image, mask\n","\n","def rotate_image(image, mask, angle=10):\n","    if tf.cast(tf.random.uniform([], maxval=2, dtype=tf.int32), tf.bool):\n","        comb = tf.concat([image,mask],axis=-1)\n","        image = tfa.image.rotate(image, angles=np.random.uniform(-angle, angle)*np.math.pi / 180)\n","        image, mask =  tf.split(comb, [image.shape[-1], mask.shape[-1]], axis=-1)\n","    return image, mask\n","\n","def normalize(image, mask):\n","    image = tf.cast(image, tf.float32) / 255.0\n","    return image, mask"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3967,"status":"ok","timestamp":1669526669525,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"h211W_C8xFf3","outputId":"e924b17c-bb4a-4faf-8cbd-4489301afa5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["(5248, 128, 128, 1)\n"]}],"source":["data = np.load(\"./dataACDCA/ACDC_train_aug128.npz\")\n","x_train, y_train = np.expand_dims(data[\"image\"], axis=-1)/ 255.0, data[\"mask\"][..., np.newaxis]\n","print(x_train.shape)\n","data = np.load(\"./dataACDCA/ACDC_val_128.npz\")\n","x_val, y_val = np.expand_dims(data[\"image\"], axis=-1)/ 255.0, data[\"mask\"][..., np.newaxis]\n","data = np.load(\"./dataACDCA/ACDC_test_128.npz\")\n","x_test, y_test = np.expand_dims(data[\"image\"], axis=-1)/ 255.0, data[\"mask\"][..., np.newaxis]\n","del data"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"DwZQVphPxJjm","executionInfo":{"status":"ok","timestamp":1669526672873,"user_tz":-420,"elapsed":3355,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["BATCH_SIZE = 32\n","buffer_size = x_train.shape[0]\n","@tf.function\n","def gen_image_aug(image, mask):\n","    image, mask = flip(image, mask)\n","    image, mask = rotate_image(image, mask)\n","    image, mask = normalize(image, mask)\n","    return image, mask\n","AUTO = tf.data.AUTOTUNE\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(buffer_size).batch(BATCH_SIZE).prefetch(buffer_size=AUTO)\n","val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"0Y3uJoJtRp-e"},"source":["# Segmentation Training"]},{"cell_type":"markdown","metadata":{"id":"6etAOgpLSdu_"},"source":["## Preparation"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"SuT2TPVNDL7S","executionInfo":{"status":"ok","timestamp":1669526675770,"user_tz":-420,"elapsed":957,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def mvn(tensor):\n","    '''Performs per-channel spatial mean-variance normalization.'''\n","    epsilon = 1e-6\n","    mean = K.mean(tensor, axis=(1,2), keepdims=True)\n","    std = K.std(tensor, axis=(1,2), keepdims=True)\n","    mvn = (tensor - mean) / (std + epsilon)\n","    \n","    return mvn"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ln7lAgch_So1","executionInfo":{"status":"ok","timestamp":1669526675771,"user_tz":-420,"elapsed":23,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def crop(tensors):\n","    '''\n","    List of 2 tensors, the second tensor having larger spatial dimensions.\n","    '''\n","    h_dims, w_dims = [], []\n","    for t in tensors:\n","        b, h, w, d = K.int_shape(t)\n","        h_dims.append(h)\n","        w_dims.append(w)\n","    crop_h, crop_w = (h_dims[1] - h_dims[0]), (w_dims[1] - w_dims[0])\n","    rem_h = int(crop_h % 2)\n","    rem_w = int(crop_w % 2)\n","    tt_h = int(crop_h / 2)\n","    tt_w = int(crop_w / 2)\n","    crop_h_dims = (tt_h, tt_h + rem_h)\n","    crop_w_dims = (tt_w, tt_w + rem_w)\n","    cropped = Cropping2D(cropping=(crop_h_dims, crop_w_dims))(tensors[1])\n","    \n","    return cropped"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"NGsJHqIorCsT","executionInfo":{"status":"ok","timestamp":1669526675772,"user_tz":-420,"elapsed":23,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def up_and_concate(down_layer, layer, data_format='channels_last'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        in_channel = down_layer.get_shape().as_list()[1]\n","    else:\n","        in_channel = down_layer.get_shape().as_list()[3]\n","\n","    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n","    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n","\n","    if data_format == 'channels_first':\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n","    else:\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n","\n","    concate = my_concat([up, layer])\n","\n","    return concate\n","def attention_up_and_concate(down_layer, layer, data_format='channels_last'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        in_channel = down_layer.get_shape().as_list()[1]\n","    else:\n","        in_channel = down_layer.get_shape().as_list()[3]\n","\n","    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n","    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n","\n","    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n","\n","    if data_format == 'channels_first':\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n","    else:\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n","\n","    concate = my_concat([up, layer])\n","    return concate\n","def attention_block_2d(x, g, inter_channel, data_format='channels_last'):\n","    data_format='channels_last'\n","    # theta_x(?,g_height,g_width,inter_channel)\n","\n","    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n","\n","    # phi_g(?,g_height,g_width,inter_channel)\n","\n","    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n","\n","    # f(?,g_height,g_width,inter_channel)\n","\n","    f = Activation('relu')(add([theta_x, phi_g]))\n","\n","    # psi_f(?,g_height,g_width,1)\n","\n","    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n","\n","    rate = Activation('sigmoid')(psi_f)\n","\n","    # rate(?,x_height,x_width)\n","\n","    # att_x(?,x_height,x_width,x_channel)\n","\n","    att_x = multiply([x, rate])\n","\n","    return att_x\n","def res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n","\n","              padding='same', data_format='channels_first'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        input_n_filters = input_layer.get_shape().as_list()[1]\n","    else:\n","        input_n_filters = input_layer.get_shape().as_list()[3]\n","\n","    layer = input_layer\n","    for i in range(2):\n","        layer = Conv2D(out_n_filters // 4, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n","        if batch_normalization:\n","            layer = BatchNormalization()(layer)\n","        layer = Activation('relu')(layer)\n","        layer = Conv2D(out_n_filters // 4, kernel_size, strides=stride, padding=padding, data_format=data_format)(layer)\n","        layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n","\n","    if out_n_filters != input_n_filters:\n","        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n","            input_layer)\n","    else:\n","        skip_layer = input_layer\n","    out_layer = add([layer, skip_layer])\n","    return out_layer\n","\n","\n","# Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n","def rec_res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n","\n","                  padding='same', data_format='channels_first'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        input_n_filters = input_layer.get_shape().as_list()[1]\n","    else:\n","        input_n_filters = input_layer.get_shape().as_list()[3]\n","\n","    if out_n_filters != input_n_filters:\n","        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n","            input_layer)\n","    else:\n","        skip_layer = input_layer\n","\n","    layer = skip_layer\n","    for j in range(2):\n","\n","        for i in range(2):\n","            if i == 0:\n","\n","                layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n","                    layer)\n","                if batch_normalization:\n","                    layer1 = BatchNormalization()(layer1)\n","                layer1 = Activation('relu')(layer1)\n","            layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n","                add([layer1, layer]))\n","            if batch_normalization:\n","                layer1 = BatchNormalization()(layer1)\n","            layer1 = Activation('relu')(layer1)\n","        layer = layer1\n","\n","    out_layer = add([layer, skip_layer])\n","    return out_layer"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"yY_WD2dUwXNr","executionInfo":{"status":"ok","timestamp":1669526675773,"user_tz":-420,"elapsed":23,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def DilatedInceptionModule(inputs, numFilters = 32): \n","  tower_0 = Conv2D(numFilters, (1,1), padding='same', dilation_rate = (1,1), kernel_initializer = 'he_normal')(inputs)\n","  tower_0 = BatchNormalization()(tower_0)\n","  tower_0 = Activation(\"relu\")(tower_0)\n","    \n","  tower_1 = Conv2D(numFilters, (1,1), padding='same', dilation_rate = (2,2), kernel_initializer = 'he_normal')(inputs)\n","  tower_1 = BatchNormalization()(tower_1)\n","  tower_1 = Activation(\"relu\")(tower_1)\n","    \n","  tower_2 = Conv2D(numFilters, (1,1), padding='same', dilation_rate = (3,3), kernel_initializer = 'he_normal')(inputs)\n","  tower_2 = BatchNormalization()(tower_2)\n","  tower_2 = Activation(\"relu\")(tower_2)\n","    \n","  dilated_inception_module = concatenate([tower_0, tower_1, tower_2], axis = 3)\n","  return dilated_inception_module"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"EthkvqmTTYK_","executionInfo":{"status":"ok","timestamp":1669526675773,"user_tz":-420,"elapsed":22,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def ASPP(x, filter):\n","    shape = x.shape\n","\n","    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n","    y1 = Conv2D(filter, 1, padding=\"same\",use_bias=False,kernel_initializer='he_normal')(y1)\n","    y1 = Lambda(mvn)(y1)\n","    y1 = ReLU()(y1)\n","    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n","\n","    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y2 = Lambda(mvn)(y2)\n","    y2 = ReLU()(y2)\n","\n","    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y3 = Lambda(mvn)(y3)\n","    y3 = ReLU()(y3)\n","\n","    y4 = Conv2D(filter, 5, dilation_rate=12, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y4 = Lambda(mvn)(y4)\n","    y4 = ReLU()(y4)\n","\n","    y5 = Conv2D(filter, 7, dilation_rate=18, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y5 = Lambda(mvn)(y5)\n","    y5 = ReLU()(y5)\n","\n","    y = Concatenate()([y1, y2, y3, y4, y5])\n","\n","    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(y)\n","    y = Lambda(mvn)(y)\n","    y = ReLU()(y)\n","    return y"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"c0Eh95hIozBw","executionInfo":{"status":"ok","timestamp":1669526675774,"user_tz":-420,"elapsed":23,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def refinement_module(x, input_filter, middle_filter):\n","  hx = x\n","  hx0 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx)\n","  #print(hx0.shape)\n","\n","  hx1 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx0)\n","  hx1 = Lambda(mvn)(hx1)\n","  hx1 = ReLU()(hx1)\n","  hx1 = MaxPooling2D(strides=(2,2))(hx1)\n","  #print(hx1.shape)\n","\n","  hx2 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx1)\n","  hx2 = Lambda(mvn)(hx2)\n","  hx2 = ReLU()(hx2)\n","  hx2 = MaxPooling2D(strides=(2,2))(hx2)\n","  #print(hx2.shape)\n","\n","  hx3 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx2)\n","  hx3 = Lambda(mvn)(hx3)\n","  hx3 = ReLU()(hx3)\n","  hx3 = MaxPooling2D(strides=(2,2))(hx3)\n","  #print(hx3.shape)\n","\n","  hx4 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx3)\n","  hx4 = Lambda(mvn)(hx4)\n","  hx4 = ReLU()(hx4)\n","  hx4 = MaxPooling2D(strides=(2,2))(hx4)\n","  #print(hx4.shape)\n","\n","  hx5 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx4)\n","  hx5 = Lambda(mvn)(hx5)\n","  hx5 = ReLU()(hx5)\n","  #print(hx5.shape)\n","  hx5 = UpSampling2D(size=(2,2), interpolation='bilinear')(hx5)\n","  #print(hx5.shape)\n","\n","  hx6 = Concatenate()([hx5, hx3])\n","  hx6 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx6)\n","  hx6 = Lambda(mvn)(hx6)\n","  hx6 = ReLU()(hx6)\n","  hx6 = UpSampling2D(size=(2,2), interpolation='bilinear')(hx6)\n","\n","  hx7 = Concatenate()([hx6, hx2])\n","  hx7 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx7)\n","  hx7 = Lambda(mvn)(hx7)\n","  hx7 = ReLU()(hx7)\n","  hx7 = UpSampling2D(size=(2,2), interpolation='bilinear')(hx7)\n","\n","  hx8 = Concatenate()([hx7, hx1])\n","  hx6 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx8)\n","  hx8 = Lambda(mvn)(hx8)\n","  hx8 = ReLU()(hx8)\n","  hx8 = UpSampling2D(size=(2,2), interpolation='bilinear')(hx8)\n","\n","  hx9 = Concatenate()([hx8, hx0])\n","  hx9 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx9)\n","  hx9 = Lambda(mvn)(hx9)\n","  hx9 = ReLU()(hx9)\n","  #hx9 = UpSampling2D((hx0.shape[1], hx0.shape[2]), interpolation='bilinear')(hx9)\n","\n","  hx10 = Conv2D(input_filter, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx9)\n","  return hx10+x"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"-RGynjxbu1Xb","executionInfo":{"status":"ok","timestamp":1669526675775,"user_tz":-420,"elapsed":24,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n","    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n","    x = Lambda(mvn)(x) #BatchNormalization()(x)\n","    if activation == True:\n","        x =  ReLU()(x) #LeakyReLU(alpha=0.1)(x)\n","    return x\n","\n","def residual_block(blockInput, num_filters=16):\n","    x = LeakyReLU(alpha=0.1)(blockInput)\n","    x = BatchNormalization()(x)\n","    blockInput = BatchNormalization()(blockInput)\n","    x = convolution_block(x, num_filters, (3,3))\n","    x = convolution_block(x, num_filters, (3,3), activation=False)\n","    x = Add()([x, blockInput])\n","    return x\n","\n","def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n","    '''\n","    2D Convolutional layers\n","    \n","    Arguments:\n","        x {keras layer} -- input layer \n","        filters {int} -- number of filters\n","        num_row {int} -- number of rows in filters\n","        num_col {int} -- number of columns in filters\n","    \n","    Keyword Arguments:\n","        padding {str} -- mode of padding (default: {'same'})\n","        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n","        activation {str} -- activation function (default: {'relu'})\n","        name {str} -- name of the layer (default: {None})\n","    \n","    Returns:\n","        [keras layer] -- [output layer]\n","    '''\n","\n","    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n","    x = Lambda(mvn)(x) #BatchNormalization(axis=3, scale=False)(x)\n","\n","    if(activation == None):\n","        return x\n","\n","    x = Activation(activation, name=name)(x)\n","\n","    return x\n","\n","def ResPath(filters, length, inp):\n","    '''\n","    ResPath\n","    \n","    Arguments:\n","        filters {int} -- [description]\n","        length {int} -- length of ResPath\n","        inp {keras layer} -- input layer \n","    \n","    Returns:\n","        [keras layer] -- [output layer]\n","    '''\n","\n","    shortcut = inp\n","    shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')\n","\n","    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n","\n","    out = add([shortcut, out])\n","    out = Activation('relu')(out)\n","    out = Lambda(mvn)(out) #BatchNormalization(axis=3)(out)\n","\n","    for i in range(length-1):\n","\n","        shortcut = out\n","        shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')\n","\n","        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n","\n","        out = add([shortcut, out])\n","        out = Activation('relu')(out)\n","        out = Lambda(mvn)(out) #BatchNormalization(axis=3)(out)\n","\n","    return out"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"-8Zb2c-MBmQo","executionInfo":{"status":"ok","timestamp":1669526675775,"user_tz":-420,"elapsed":23,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["class Swish(tf.keras.layers.Layer):\n","    def __init__(self, name=None, **kwargs):\n","        super().__init__(name=name, **kwargs)\n","\n","    def call(self, inputs, **kwargs):\n","        return tf.nn.swish(inputs)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config['name'] = self.name\n","        return config\n","\n","def squeeze_excite_block(reduce_ratio=0.25,name_block=None):\n","  def call(inputs):\n","    filters = inputs.shape[-1]\n","    num_reduced_filters= max(1, int(filters * reduce_ratio))\n","    se = Lambda(lambda a: K.mean(a, axis=[1,2], keepdims=True))(inputs)\n","\n","    se = Conv2D(\n","            num_reduced_filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            use_bias=True\n","        )(se)\n","    se = Swish()(se)\n","    se = Conv2D(\n","            filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            use_bias=True\n","        )(se)\n","    se = Activation('sigmoid')(se)\n","    if name_block is not None:\n","      out = Multiply(name=name_block)([se, inputs])\n","    else : \n","      out = Multiply()([se, inputs])\n","    return out\n","  return call\n","\n","def conv_block(filters,block_name=None): #kernel_size = (3,3), dilation = 1\n","  def call(inputs):\n","    x = inputs\n","\n","    x = Conv2D(filters, kernel_size=(3,3), padding=\"same\",dilation_rate =1 ,use_bias=False,kernel_initializer='he_normal')(x)\n","    x = BatchNormalization()(x)\n","    x = Swish()(x)\n","\n","    x = Conv2D(filters, kernel_size=(3,3), padding=\"same\",dilation_rate =1, use_bias=False,kernel_initializer='he_normal')(x)\n","    x = BatchNormalization()(x)\n","    x = Swish()(x)\n","\n","    x = squeeze_excite_block(name_block=block_name)(x)\n","\n","    return x\n","  return call"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ikvcgoZ__bcI","executionInfo":{"status":"ok","timestamp":1669526675775,"user_tz":-420,"elapsed":23,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def _ASPP(x, filter):\n","    shape = x.shape\n","\n","    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n","    y1 = Conv2D(filter, 1, padding=\"same\",use_bias=False,kernel_initializer='he_normal')(y1)\n","    y1 = BatchNormalization()(y1)\n","    y1 = Swish()(y1)\n","    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n","    y1 = squeeze_excite_block()(y1)\n","\n","    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y2 = BatchNormalization()(y2)\n","    y2 = Swish()(y2)\n","    y2 = squeeze_excite_block()(y2)\n","\n","    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y3 = BatchNormalization()(y3)\n","    y3 = Swish()(y3)\n","    y3 = squeeze_excite_block()(y3)\n","\n","    y4 = Conv2D(filter, 5, dilation_rate=12, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y4 = BatchNormalization()(y4)\n","    y4 = Swish()(y4)\n","    y4 = squeeze_excite_block()(y4)\n","\n","    y5 = Conv2D(filter, 7, dilation_rate=18, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y5 = BatchNormalization()(y5)\n","    y5 = Swish()(y5)\n","    y5 = squeeze_excite_block()(y5)\n","\n","    y = Concatenate()([y1, y2, y3, y4, y5])\n","\n","    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(y)\n","    y = BatchNormalization()(y)\n","    y = Swish()(y)\n","    y = squeeze_excite_block()(y)\n","    return y"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"tkRNLZpj8PVY","executionInfo":{"status":"ok","timestamp":1669526675776,"user_tz":-420,"elapsed":23,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def decoder_block(n_filter,skip=None):\n","  def call(inputs):\n","    x= Conv2DTranspose(n_filter, (2,2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(inputs)\n","    out = x\n","    if skip is not None :\n","      attention = conv_block(n_filter)(skip)\n","      out = Concatenate()([x,attention])\n","    out = Dropout(0.5)(out)\n","    out = conv_block(n_filter)(out)\n","\n","    return out\n","  return call\n","  \n","def dow_block(kernel_size=(2,2),stride=(2,2)):\n","  def call(inputs):\n","    out = MaxPooling2D(kernel_size, strides=stride)(inputs)\n","    return out\n","  return call"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"LmwPhlbm4u2V","executionInfo":{"status":"ok","timestamp":1669526675776,"user_tz":-420,"elapsed":23,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def encoderSegnet(input_s=(128,128,1)):\n","  inp= Input(shape=input_s)\n","  o = inp\n","  nums_filter=[64,128,256,512,512]\n","  count=0\n","  for f in nums_filter[:-1]:\n","    count+=1\n","    o = conv_block(f,block_name='output_block_'+str(count))(o) \n","    o = dow_block()(o)\n","\n","  o = conv_block(nums_filter[-1],block_name='output_block_'+str(count+1))(o)\n","  #o = Dropout(0.5)(o)\n","  return Model(inp,o)\n","\n","list_skip = [\"output_block_4\", \"output_block_3\", \"output_block_2\", \"output_block_1\"]"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"p5fQBlcBKOX7","executionInfo":{"status":"ok","timestamp":1669526675777,"user_tz":-420,"elapsed":24,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def expend_as(tensor, rep):\n","    my_repeat = Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': rep})(tensor)\n","    return my_repeat\n","\n","def SalientAttentionBlock(f_maps, sal_ins, pool_maps, num_fmaps):\n","    # Inputs: feature maps from UNet, saliency images, pooled layers from UNet, number of output feature maps\n","    conv1_salins = Conv2D(128, (1, 1), activation='relu')(sal_ins)\n","    conv1_fmaps = Conv2D(128, (1, 1), strides=(2, 2), activation='relu')(f_maps)\n","    attn_add = add([conv1_fmaps,conv1_salins])\n","    conv_1d = Conv2D(128, (3, 3), activation='relu', padding='same')(attn_add)\n","    conv_1d = Conv2D(128, (3, 3), activation='relu', padding='same')(conv_1d)\n","    conv_1d = Conv2D(1, (1, 1), activation='relu')(conv_1d)\n","    conv_1d = expend_as(conv_1d,32)\n","    conv_nd = Conv2D(num_fmaps, (1, 1), activation='relu')(conv_1d)\n","    attn_act = Activation('sigmoid')(conv_nd)\n","    attn = multiply([attn_act, pool_maps])\n","    return attn\n","\n","def UNetBlock(in_fmaps, num_fmaps):\n","    # Inputs: feature maps for UNet, number of output feature maps\n","    conv1 = Conv2D(num_fmaps, (3, 3), activation='relu', padding='same')(in_fmaps)\n","    conv_out = Conv2D(num_fmaps, (3, 3), activation='relu', padding='same')(conv1)\n","    return conv_out"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"2HucTfAL2-vC","executionInfo":{"status":"ok","timestamp":1669526675777,"user_tz":-420,"elapsed":24,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def bn_act(x, act=True):\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    if act == True:\n","        x = tf.keras.layers.Activation(\"relu\")(x)\n","    return x \n","\n","def _conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n","    conv = bn_act(x)\n","    conv = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n","    return conv \n","\n","def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n","    conv = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n","    conv = _conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n","\n","    shortcut = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n","    shortcut = bn_act(shortcut, act=False)\n","\n","    output = tf.keras.layers.Add()([conv, shortcut])\n","    return output \n","\n","def _residual_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):\n","    res = _conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n","    res = _conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n","\n","    shortcut = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n","    shortcut = bn_act(shortcut, act=False)\n","    \n","    output = tf.keras.layers.Add()([shortcut, res])\n","    return output\n","\n","def upsample_concat_block(x, xskip):\n","    u = tf.keras.layers.UpSampling2D((2, 2))(x)\n","    c = tf.keras.layers.Concatenate()([u, xskip])\n","    return c "]},{"cell_type":"code","execution_count":21,"metadata":{"id":"goTwuAn_e3-G","executionInfo":{"status":"ok","timestamp":1669526675778,"user_tz":-420,"elapsed":24,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def _convolution_block(\n","    block_input,\n","    num_filters=256,\n","    kernel_size=3,\n","    dilation_rate=1,\n","    padding=\"same\",\n","    use_bias=False,\n","):\n","    x = layers.Conv2D(\n","        num_filters,\n","        kernel_size=kernel_size,\n","        dilation_rate=dilation_rate,\n","        padding=\"same\",\n","        use_bias=use_bias,\n","        kernel_initializer=tf.keras.initializers.HeNormal(),\n","    )(block_input)\n","    x = layers.BatchNormalization()(x)\n","    return tf.nn.relu(x)\n","\n","\n","def DilatedSpatialPyramidPooling(dspp_input):\n","    dims = dspp_input.shape\n","    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n","    x = _convolution_block(x, kernel_size=1, use_bias=True)\n","    out_pool = layers.UpSampling2D(\n","        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n","    )(x)\n","\n","    out_1 = _convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n","    out_6 = _convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n","    out_12 = _convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n","    out_18 = _convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n","\n","    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n","    output = _convolution_block(x, kernel_size=1)\n","    return output"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"eLiRpVpz-juO","executionInfo":{"status":"ok","timestamp":1669526675778,"user_tz":-420,"elapsed":23,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def swin_transformer_stack(X, stack_num, embed_dim, num_patch, num_heads, window_size, num_mlp, shift_window=True, name=''):\n","    '''\n","    Stacked Swin Transformers that share the same token size.\n","    \n","    Alternated Window-MSA and Swin-MSA will be configured if `shift_window=True`, Window-MSA only otherwise.\n","    *Dropout is turned off.\n","    '''\n","    # Turn-off dropouts\n","    mlp_drop_rate = 0 # Droupout after each MLP layer\n","    attn_drop_rate = 0 # Dropout after Swin-Attention\n","    proj_drop_rate = 0 # Dropout at the end of each Swin-Attention block, i.e., after linear projections\n","    drop_path_rate = 0 # Drop-path within skip-connections\n","    \n","    qkv_bias = True # Convert embedded patches to query, key, and values with a learnable additive value\n","    qk_scale = None # None: Re-scale query based on embed dimensions per attention head # Float for user specified scaling factor\n","    \n","    if shift_window:\n","        shift_size = window_size // 2\n","    else:\n","        shift_size = 0\n","    \n","    for i in range(stack_num):\n","    \n","        if i % 2 == 0:\n","            shift_size_temp = 0\n","        else:\n","            shift_size_temp = shift_size\n","\n","        X = swin_layers.SwinTransformerBlock(dim=embed_dim, num_patch=num_patch, num_heads=num_heads, \n","                                 window_size=window_size, shift_size=shift_size_temp, num_mlp=num_mlp, qkv_bias=qkv_bias, qk_scale=qk_scale,\n","                                 mlp_drop=mlp_drop_rate, attn_drop=attn_drop_rate, proj_drop=proj_drop_rate, drop_path_prob=drop_path_rate, \n","                                 name='name{}'.format(i))(X)\n","    return X"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1669526675778,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"N3XaNS8uOC75","outputId":"c2d9c789-aa50-4f93-a1fd-26ae54a0d06a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'class BilinearUpsampling(Layer):\\n    \"\"\"Just a simple bilinear upsampling layer. Works only with TF.\\n       Args:\\n           upsampling: tuple of 2 numbers > 0. The upsampling ratio for h and w\\n           output_size: used instead of upsampling arg if passed!\\n    \"\"\"\\n\\n    def __init__(self, upsampling=(2, 2), output_size=None, data_format=None, **kwargs):\\n\\n        super(BilinearUpsampling, self).__init__(**kwargs)\\n\\n        #self.data_format = K.normalize_data_format(data_format)\\n        self.data_format = None\\n        self.input_spec = InputSpec(ndim=4)\\n        if output_size:\\n            self.output_size = conv_utils.normalize_tuple(\\n                output_size, 2, \\'output_size\\')\\n            self.upsampling = None\\n        else:\\n            self.output_size = None\\n            self.upsampling = conv_utils.normalize_tuple(\\n                upsampling, 2, \\'upsampling\\')\\n\\n    def compute_output_shape(self, input_shape):\\n        if self.upsampling:\\n            height = self.upsampling[0] *                 input_shape[1] if input_shape[1] is not None else None\\n            width = self.upsampling[1] *                 input_shape[2] if input_shape[2] is not None else None\\n        else:\\n            height = self.output_size[0]\\n            width = self.output_size[1]\\n        return (input_shape[0],\\n                height,\\n                width,\\n                input_shape[3])\\n\\n    def call(self, inputs):\\n        if self.upsampling:\\n            return K.tf.image.resize_bilinear(inputs, (inputs.shape[1] * self.upsampling[0],\\n                                                       inputs.shape[2] * self.upsampling[1]),\\n                                              align_corners=True)\\n        else:\\n            return K.tf.image.resize_bilinear(inputs, (self.output_size[0],\\n                                                       self.output_size[1]),\\n                                              align_corners=True)\\n\\n    def get_config(self):\\n        config = {\\'upsampling\\': self.upsampling,\\n                  \\'output_size\\': self.output_size,\\n                  \\'data_format\\': self.data_format}\\n        base_config = super(BilinearUpsampling, self).get_config()\\n        return dict(list(base_config.items()) + list(config.items()))\\n\\n\\ndef SepConv_BN(x, filters, prefix, stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3):\\n    \"\"\" SepConv with BN between depthwise & pointwise. Optionally add activation after BN\\n        Implements right \"same\" padding for even kernel sizes\\n        Args:\\n            x: input tensor\\n            filters: num of filters in pointwise convolution\\n            prefix: prefix before name\\n            stride: stride at depthwise conv\\n            kernel_size: kernel size for depthwise convolution\\n            rate: atrous rate for depthwise convolution\\n            depth_activation: flag to use activation between depthwise & poinwise convs\\n            epsilon: epsilon to use in BN layer\\n    \"\"\"\\n\\n    if stride == 1:\\n        depth_padding = \\'same\\'\\n    else:\\n        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\\n        pad_total = kernel_size_effective - 1\\n        pad_beg = pad_total // 2\\n        pad_end = pad_total - pad_beg\\n        x = ZeroPadding2D((pad_beg, pad_end))(x)\\n        depth_padding = \\'valid\\'\\n\\n    if not depth_activation:\\n        x = Activation(\\'relu\\')(x)\\n    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(stride, stride), dilation_rate=(rate, rate),\\n                        padding=depth_padding, use_bias=False, name=prefix + \\'_depthwise\\')(x)\\n    x = BatchNormalization(name=prefix + \\'_depthwise_BN\\', epsilon=epsilon)(x)\\n    if depth_activation:\\n        x = Activation(\\'relu\\')(x)\\n    x = Conv2D(filters, (1, 1), padding=\\'same\\',\\n               use_bias=False, name=prefix + \\'_pointwise\\')(x)\\n    x = BatchNormalization(name=prefix + \\'_pointwise_BN\\', epsilon=epsilon)(x)\\n    if depth_activation:\\n        x = Activation(\\'relu\\')(x)\\n\\n    return x\\n\\n\\ndef _conv2d_same(x, filters, prefix, stride=1, kernel_size=3, rate=1):\\n    \"\"\"Implements right \\'same\\' padding for even kernel sizes\\n        Without this there is a 1 pixel drift when stride = 2\\n        Args:\\n            x: input tensor\\n            filters: num of filters in pointwise convolution\\n            prefix: prefix before name\\n            stride: stride at depthwise conv\\n            kernel_size: kernel size for depthwise convolution\\n            rate: atrous rate for depthwise convolution\\n    \"\"\"\\n    if stride == 1:\\n        return Conv2D(filters,\\n                      (kernel_size, kernel_size),\\n                      strides=(stride, stride),\\n                      padding=\\'same\\', use_bias=False,\\n                      dilation_rate=(rate, rate),\\n                      name=prefix)(x)\\n    else:\\n        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\\n        pad_total = kernel_size_effective - 1\\n        pad_beg = pad_total // 2\\n        pad_end = pad_total - pad_beg\\n        x = ZeroPadding2D((pad_beg, pad_end))(x)\\n        return Conv2D(filters,\\n                      (kernel_size, kernel_size),\\n                      strides=(stride, stride),\\n                      padding=\\'valid\\', use_bias=False,\\n                      dilation_rate=(rate, rate),\\n                      name=prefix)(x)\\n\\n\\ndef _xception_block(inputs, depth_list, prefix, skip_connection_type, stride,\\n                    rate=1, depth_activation=False, return_skip=False):\\n    \"\"\" Basic building block of modified Xception network\\n        Args:\\n            inputs: input tensor\\n            depth_list: number of filters in each SepConv layer. len(depth_list) == 3\\n            prefix: prefix before name\\n            skip_connection_type: one of {\\'conv\\',\\'sum\\',\\'none\\'}\\n            stride: stride at last depthwise conv\\n            rate: atrous rate for depthwise convolution\\n            depth_activation: flag to use activation between depthwise & pointwise convs\\n            return_skip: flag to return additional tensor after 2 SepConvs for decoder\\n            \"\"\"\\n    residual = inputs\\n    for i in range(3):\\n        residual = SepConv_BN(residual,\\n                              depth_list[i],\\n                              prefix + \\'_separable_conv{}\\'.format(i + 1),\\n                              stride=stride if i == 2 else 1,\\n                              rate=rate,\\n                              depth_activation=depth_activation)\\n        if i == 1:\\n            skip = residual\\n    if skip_connection_type == \\'conv\\':\\n        shortcut = _conv2d_same(inputs, depth_list[-1], prefix + \\'_shortcut\\',\\n                                kernel_size=1,\\n                                stride=stride)\\n        shortcut = BatchNormalization(name=prefix + \\'_shortcut_BN\\')(shortcut)\\n        outputs = layers.add([residual, shortcut])\\n    elif skip_connection_type == \\'sum\\':\\n        outputs = layers.add([residual, inputs])\\n    elif skip_connection_type == \\'none\\':\\n        outputs = residual\\n    if return_skip:\\n        return outputs, skip\\n    else:\\n        return outputs\\n\\n\\ndef relu6(x):\\n    return K.relu(x, max_value=6)\\n\\n\\ndef _make_divisible(v, divisor, min_value=None):\\n    if min_value is None:\\n        min_value = divisor\\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\\n    # Make sure that round down does not go down by more than 10%.\\n    if new_v < 0.9 * v:\\n        new_v += divisor\\n    return new_v\\n\\n\\ndef _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id, skip_connection, rate=1):\\n    in_channels = inputs._keras_shape[-1]\\n    pointwise_conv_filters = int(filters * alpha)\\n    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\\n    x = inputs\\n    prefix = \\'expanded_conv_{}_\\'.format(block_id)\\n    if block_id:\\n        # Expand\\n\\n        x = Conv2D(expansion * in_channels, kernel_size=1, padding=\\'same\\',\\n                   use_bias=False, activation=None,\\n                   name=prefix + \\'expand\\')(x)\\n        x = BatchNormalization(epsilon=1e-3, momentum=0.999,\\n                               name=prefix + \\'expand_BN\\')(x)\\n        x = Activation(relu6, name=prefix + \\'expand_relu\\')(x)\\n    else:\\n        prefix = \\'expanded_conv_\\'\\n    # Depthwise\\n    x = DepthwiseConv2D(kernel_size=3, strides=stride, activation=None,\\n                        use_bias=False, padding=\\'same\\', dilation_rate=(rate, rate),\\n                        name=prefix + \\'depthwise\\')(x)\\n    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\\n                           name=prefix + \\'depthwise_BN\\')(x)\\n\\n    x = Activation(relu6, name=prefix + \\'depthwise_relu\\')(x)\\n\\n    # Project\\n    x = Conv2D(pointwise_filters,\\n               kernel_size=1, padding=\\'same\\', use_bias=False, activation=None,\\n               name=prefix + \\'project\\')(x)\\n    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\\n                           name=prefix + \\'project_BN\\')(x)\\n\\n    if skip_connection:\\n        return Add(name=prefix + \\'add\\')([inputs, x])\\n\\n    # if in_channels == pointwise_filters and stride == 1:\\n    #    return Add(name=\\'res_connect_\\' + str(block_id))([inputs, x])\\n\\n    return x'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}],"source":["'''class BilinearUpsampling(Layer):\n","    \"\"\"Just a simple bilinear upsampling layer. Works only with TF.\n","       Args:\n","           upsampling: tuple of 2 numbers > 0. The upsampling ratio for h and w\n","           output_size: used instead of upsampling arg if passed!\n","    \"\"\"\n","\n","    def __init__(self, upsampling=(2, 2), output_size=None, data_format=None, **kwargs):\n","\n","        super(BilinearUpsampling, self).__init__(**kwargs)\n","\n","        #self.data_format = K.normalize_data_format(data_format)\n","        self.data_format = None\n","        self.input_spec = InputSpec(ndim=4)\n","        if output_size:\n","            self.output_size = conv_utils.normalize_tuple(\n","                output_size, 2, 'output_size')\n","            self.upsampling = None\n","        else:\n","            self.output_size = None\n","            self.upsampling = conv_utils.normalize_tuple(\n","                upsampling, 2, 'upsampling')\n","\n","    def compute_output_shape(self, input_shape):\n","        if self.upsampling:\n","            height = self.upsampling[0] * \\\n","                input_shape[1] if input_shape[1] is not None else None\n","            width = self.upsampling[1] * \\\n","                input_shape[2] if input_shape[2] is not None else None\n","        else:\n","            height = self.output_size[0]\n","            width = self.output_size[1]\n","        return (input_shape[0],\n","                height,\n","                width,\n","                input_shape[3])\n","\n","    def call(self, inputs):\n","        if self.upsampling:\n","            return K.tf.image.resize_bilinear(inputs, (inputs.shape[1] * self.upsampling[0],\n","                                                       inputs.shape[2] * self.upsampling[1]),\n","                                              align_corners=True)\n","        else:\n","            return K.tf.image.resize_bilinear(inputs, (self.output_size[0],\n","                                                       self.output_size[1]),\n","                                              align_corners=True)\n","\n","    def get_config(self):\n","        config = {'upsampling': self.upsampling,\n","                  'output_size': self.output_size,\n","                  'data_format': self.data_format}\n","        base_config = super(BilinearUpsampling, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))\n","\n","\n","def SepConv_BN(x, filters, prefix, stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3):\n","    \"\"\" SepConv with BN between depthwise & pointwise. Optionally add activation after BN\n","        Implements right \"same\" padding for even kernel sizes\n","        Args:\n","            x: input tensor\n","            filters: num of filters in pointwise convolution\n","            prefix: prefix before name\n","            stride: stride at depthwise conv\n","            kernel_size: kernel size for depthwise convolution\n","            rate: atrous rate for depthwise convolution\n","            depth_activation: flag to use activation between depthwise & poinwise convs\n","            epsilon: epsilon to use in BN layer\n","    \"\"\"\n","\n","    if stride == 1:\n","        depth_padding = 'same'\n","    else:\n","        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n","        pad_total = kernel_size_effective - 1\n","        pad_beg = pad_total // 2\n","        pad_end = pad_total - pad_beg\n","        x = ZeroPadding2D((pad_beg, pad_end))(x)\n","        depth_padding = 'valid'\n","\n","    if not depth_activation:\n","        x = Activation('relu')(x)\n","    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(stride, stride), dilation_rate=(rate, rate),\n","                        padding=depth_padding, use_bias=False, name=prefix + '_depthwise')(x)\n","    x = BatchNormalization(name=prefix + '_depthwise_BN', epsilon=epsilon)(x)\n","    if depth_activation:\n","        x = Activation('relu')(x)\n","    x = Conv2D(filters, (1, 1), padding='same',\n","               use_bias=False, name=prefix + '_pointwise')(x)\n","    x = BatchNormalization(name=prefix + '_pointwise_BN', epsilon=epsilon)(x)\n","    if depth_activation:\n","        x = Activation('relu')(x)\n","\n","    return x\n","\n","\n","def _conv2d_same(x, filters, prefix, stride=1, kernel_size=3, rate=1):\n","    \"\"\"Implements right 'same' padding for even kernel sizes\n","        Without this there is a 1 pixel drift when stride = 2\n","        Args:\n","            x: input tensor\n","            filters: num of filters in pointwise convolution\n","            prefix: prefix before name\n","            stride: stride at depthwise conv\n","            kernel_size: kernel size for depthwise convolution\n","            rate: atrous rate for depthwise convolution\n","    \"\"\"\n","    if stride == 1:\n","        return Conv2D(filters,\n","                      (kernel_size, kernel_size),\n","                      strides=(stride, stride),\n","                      padding='same', use_bias=False,\n","                      dilation_rate=(rate, rate),\n","                      name=prefix)(x)\n","    else:\n","        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n","        pad_total = kernel_size_effective - 1\n","        pad_beg = pad_total // 2\n","        pad_end = pad_total - pad_beg\n","        x = ZeroPadding2D((pad_beg, pad_end))(x)\n","        return Conv2D(filters,\n","                      (kernel_size, kernel_size),\n","                      strides=(stride, stride),\n","                      padding='valid', use_bias=False,\n","                      dilation_rate=(rate, rate),\n","                      name=prefix)(x)\n","\n","\n","def _xception_block(inputs, depth_list, prefix, skip_connection_type, stride,\n","                    rate=1, depth_activation=False, return_skip=False):\n","    \"\"\" Basic building block of modified Xception network\n","        Args:\n","            inputs: input tensor\n","            depth_list: number of filters in each SepConv layer. len(depth_list) == 3\n","            prefix: prefix before name\n","            skip_connection_type: one of {'conv','sum','none'}\n","            stride: stride at last depthwise conv\n","            rate: atrous rate for depthwise convolution\n","            depth_activation: flag to use activation between depthwise & pointwise convs\n","            return_skip: flag to return additional tensor after 2 SepConvs for decoder\n","            \"\"\"\n","    residual = inputs\n","    for i in range(3):\n","        residual = SepConv_BN(residual,\n","                              depth_list[i],\n","                              prefix + '_separable_conv{}'.format(i + 1),\n","                              stride=stride if i == 2 else 1,\n","                              rate=rate,\n","                              depth_activation=depth_activation)\n","        if i == 1:\n","            skip = residual\n","    if skip_connection_type == 'conv':\n","        shortcut = _conv2d_same(inputs, depth_list[-1], prefix + '_shortcut',\n","                                kernel_size=1,\n","                                stride=stride)\n","        shortcut = BatchNormalization(name=prefix + '_shortcut_BN')(shortcut)\n","        outputs = layers.add([residual, shortcut])\n","    elif skip_connection_type == 'sum':\n","        outputs = layers.add([residual, inputs])\n","    elif skip_connection_type == 'none':\n","        outputs = residual\n","    if return_skip:\n","        return outputs, skip\n","    else:\n","        return outputs\n","\n","\n","def relu6(x):\n","    return K.relu(x, max_value=6)\n","\n","\n","def _make_divisible(v, divisor, min_value=None):\n","    if min_value is None:\n","        min_value = divisor\n","    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n","    # Make sure that round down does not go down by more than 10%.\n","    if new_v < 0.9 * v:\n","        new_v += divisor\n","    return new_v\n","\n","\n","def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id, skip_connection, rate=1):\n","    in_channels = inputs._keras_shape[-1]\n","    pointwise_conv_filters = int(filters * alpha)\n","    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n","    x = inputs\n","    prefix = 'expanded_conv_{}_'.format(block_id)\n","    if block_id:\n","        # Expand\n","\n","        x = Conv2D(expansion * in_channels, kernel_size=1, padding='same',\n","                   use_bias=False, activation=None,\n","                   name=prefix + 'expand')(x)\n","        x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n","                               name=prefix + 'expand_BN')(x)\n","        x = Activation(relu6, name=prefix + 'expand_relu')(x)\n","    else:\n","        prefix = 'expanded_conv_'\n","    # Depthwise\n","    x = DepthwiseConv2D(kernel_size=3, strides=stride, activation=None,\n","                        use_bias=False, padding='same', dilation_rate=(rate, rate),\n","                        name=prefix + 'depthwise')(x)\n","    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n","                           name=prefix + 'depthwise_BN')(x)\n","\n","    x = Activation(relu6, name=prefix + 'depthwise_relu')(x)\n","\n","    # Project\n","    x = Conv2D(pointwise_filters,\n","               kernel_size=1, padding='same', use_bias=False, activation=None,\n","               name=prefix + 'project')(x)\n","    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n","                           name=prefix + 'project_BN')(x)\n","\n","    if skip_connection:\n","        return Add(name=prefix + 'add')([inputs, x])\n","\n","    # if in_channels == pointwise_filters and stride == 1:\n","    #    return Add(name='res_connect_' + str(block_id))([inputs, x])\n","\n","    return x'''"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"pj1Vfg0rOlPd","executionInfo":{"status":"ok","timestamp":1669526685653,"user_tz":-420,"elapsed":435,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def Deeplabv3(weights='pascal_voc', input_tensor=None, input_shape=(512, 512, 3), classes=21, backbone='mobilenetv2', OS=16, alpha=1.):\n","    \"\"\" Instantiates the Deeplabv3+ architecture\n","\n","    Optionally loads weights pre-trained\n","    on PASCAL VOC. This model is available for TensorFlow only,\n","    and can only be used with inputs following the TensorFlow\n","    data format `(width, height, channels)`.\n","    # Arguments\n","        weights: one of 'pascal_voc' (pre-trained on pascal voc)\n","            or None (random initialization)\n","        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n","            to use as image input for the model.\n","        input_shape: shape of input image. format HxWxC\n","            PASCAL VOC model was trained on (512,512,3) images\n","        classes: number of desired classes. If classes != 21,\n","            last layer is initialized randomly\n","        backbone: backbone to use. one of {'xception','mobilenetv2'}\n","        OS: determines input_shape/feature_extractor_output ratio. One of {8,16}.\n","            Used only for xception backbone.\n","        alpha: controls the width of the MobileNetV2 network. This is known as the\n","            width multiplier in the MobileNetV2 paper.\n","                - If `alpha` < 1.0, proportionally decreases the number\n","                    of filters in each layer.\n","                - If `alpha` > 1.0, proportionally increases the number\n","                    of filters in each layer.\n","                - If `alpha` = 1, default number of filters from the paper\n","                    are used at each layer.\n","            Used only for mobilenetv2 backbone\n","\n","    # Returns\n","        A Keras model instance.\n","\n","    # Raises\n","        RuntimeError: If attempting to run this model with a\n","            backend that does not support separable convolutions.\n","        ValueError: in case of invalid argument for `weights` or `backbone`\n","\n","    \"\"\"\n","\n","    if not (weights in {'pascal_voc', None}):\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization) or `pascal_voc` '\n","                         '(pre-trained on PASCAL VOC)')\n","\n","    if K.backend() != 'tensorflow':\n","        raise RuntimeError('The Deeplabv3+ model is only available with '\n","                           'the TensorFlow backend.')\n","\n","    if not (backbone in {'xception', 'mobilenetv2'}):\n","        raise ValueError('The `backbone` argument should be either '\n","                         '`xception`  or `mobilenetv2` ')\n","\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not K.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","\n","    if backbone == 'xception':\n","        if OS == 8:\n","            entry_block3_stride = 1\n","            middle_block_rate = 2  # ! Not mentioned in paper, but required\n","            exit_block_rates = (2, 4)\n","            atrous_rates = (12, 24, 36)\n","        else:\n","            entry_block3_stride = 2\n","            middle_block_rate = 1\n","            exit_block_rates = (1, 2)\n","            atrous_rates = (6, 12, 18)\n","\n","        x = Conv2D(32, (3, 3), strides=(2, 2),\n","                   name='entry_flow_conv1_1', use_bias=False, padding='same')(img_input)\n","        x = BatchNormalization(name='entry_flow_conv1_1_BN')(x)\n","        x = Activation('relu')(x)\n","\n","        x = _conv2d_same(x, 64, 'entry_flow_conv1_2', kernel_size=3, stride=1)\n","        x = BatchNormalization(name='entry_flow_conv1_2_BN')(x)\n","        x = Activation('relu')(x)\n","\n","        x = _xception_block(x, [128, 128, 128], 'entry_flow_block1',\n","                            skip_connection_type='conv', stride=2,\n","                            depth_activation=False)\n","        x, skip1 = _xception_block(x, [256, 256, 256], 'entry_flow_block2',\n","                                   skip_connection_type='conv', stride=2,\n","                                   depth_activation=False, return_skip=True)\n","\n","        x = _xception_block(x, [728, 728, 728], 'entry_flow_block3',\n","                            skip_connection_type='conv', stride=entry_block3_stride,\n","                            depth_activation=False)\n","        for i in range(16):\n","            x = _xception_block(x, [728, 728, 728], 'middle_flow_unit_{}'.format(i + 1),\n","                                skip_connection_type='sum', stride=1, rate=middle_block_rate,\n","                                depth_activation=False)\n","\n","        x = _xception_block(x, [728, 1024, 1024], 'exit_flow_block1',\n","                            skip_connection_type='conv', stride=1, rate=exit_block_rates[0],\n","                            depth_activation=False)\n","        x = _xception_block(x, [1536, 1536, 2048], 'exit_flow_block2',\n","                            skip_connection_type='none', stride=1, rate=exit_block_rates[1],\n","                            depth_activation=True)\n","\n","    else:\n","        OS = 8\n","        first_block_filters = _make_divisible(32 * alpha, 8)\n","        x = Conv2D(first_block_filters,\n","                   kernel_size=3,\n","                   strides=(2, 2), padding='same',\n","                   use_bias=False, name='Conv')(img_input)\n","        x = BatchNormalization(\n","            epsilon=1e-3, momentum=0.999, name='Conv_BN')(x)\n","        x = Activation(relu6, name='Conv_Relu6')(x)\n","\n","        x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n","                                expansion=1, block_id=0, skip_connection=False)\n","\n","        x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n","                                expansion=6, block_id=1, skip_connection=False)\n","        x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n","                                expansion=6, block_id=2, skip_connection=True)\n","\n","        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n","                                expansion=6, block_id=3, skip_connection=False)\n","        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n","                                expansion=6, block_id=4, skip_connection=True)\n","        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n","                                expansion=6, block_id=5, skip_connection=True)\n","\n","        # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n","        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,  # 1!\n","                                expansion=6, block_id=6, skip_connection=False)\n","        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=7, skip_connection=True)\n","        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=8, skip_connection=True)\n","        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=9, skip_connection=True)\n","\n","        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=10, skip_connection=False)\n","        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=11, skip_connection=True)\n","        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=12, skip_connection=True)\n","\n","        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n","                                expansion=6, block_id=13, skip_connection=False)\n","        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n","                                expansion=6, block_id=14, skip_connection=True)\n","        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n","                                expansion=6, block_id=15, skip_connection=True)\n","\n","        x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1, rate=4,\n","                                expansion=6, block_id=16, skip_connection=False)\n","\n","    # end of feature extractor\n","\n","    # branching for Atrous Spatial Pyramid Pooling\n","\n","    # Image Feature branch\n","    #out_shape = int(np.ceil(input_shape[0] / OS))\n","    b4 = AveragePooling2D(pool_size=(int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(x)\n","    b4 = Conv2D(256, (1, 1), padding='same',\n","                use_bias=False, name='image_pooling')(b4)\n","    b4 = BatchNormalization(name='image_pooling_BN', epsilon=1e-5)(b4)\n","    b4 = Activation('relu')(b4)\n","    b4 = BilinearUpsampling((int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(b4)\n","\n","    # simple 1x1\n","    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False, name='aspp0')(x)\n","    b0 = BatchNormalization(name='aspp0_BN', epsilon=1e-5)(b0)\n","    b0 = Activation('relu', name='aspp0_activation')(b0)\n","\n","    # there are only 2 branches in mobilenetV2. not sure why\n","    if backbone == 'xception':\n","        # rate = 6 (12)\n","        b1 = SepConv_BN(x, 256, 'aspp1',\n","                        rate=atrous_rates[0], depth_activation=True, epsilon=1e-5)\n","        # rate = 12 (24)\n","        b2 = SepConv_BN(x, 256, 'aspp2',\n","                        rate=atrous_rates[1], depth_activation=True, epsilon=1e-5)\n","        # rate = 18 (36)\n","        b3 = SepConv_BN(x, 256, 'aspp3',\n","                        rate=atrous_rates[2], depth_activation=True, epsilon=1e-5)\n","\n","        # concatenate ASPP branches & project\n","        x = Concatenate()([b4, b0, b1, b2, b3])\n","    else:\n","        x = Concatenate()([b4, b0])\n","\n","    x = Conv2D(256, (1, 1), padding='same',\n","               use_bias=False, name='concat_projection')(x)\n","    x = BatchNormalization(name='concat_projection_BN', epsilon=1e-5)(x)\n","    x = Activation('relu')(x)\n","    x = Dropout(0.1)(x)\n","\n","    # DeepLab v.3+ decoder\n","\n","    if backbone == 'xception':\n","        # Feature projection\n","        # x4 (x2) block\n","        x = BilinearUpsampling(output_size=(int(np.ceil(input_shape[0] / 4)),\n","                                            int(np.ceil(input_shape[1] / 4))))(x)\n","        dec_skip1 = Conv2D(48, (1, 1), padding='same',\n","                           use_bias=False, name='feature_projection0')(skip1)\n","        dec_skip1 = BatchNormalization(\n","            name='feature_projection0_BN', epsilon=1e-5)(dec_skip1)\n","        dec_skip1 = Activation('relu')(dec_skip1)\n","        x = Concatenate()([x, dec_skip1])\n","        x = SepConv_BN(x, 256, 'decoder_conv0',\n","                       depth_activation=True, epsilon=1e-5)\n","        x = SepConv_BN(x, 256, 'decoder_conv1',\n","                       depth_activation=True, epsilon=1e-5)\n","\n","    # you can use it with arbitary number of classes\n","    if classes == 21:\n","        last_layer_name = 'logits_semantic'\n","    else:\n","        last_layer_name = 'custom_logits_semantic'\n","\n","    x = Conv2D(classes, (1, 1), padding='same', name=last_layer_name)(x)\n","    x = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    if input_tensor is not None:\n","        inputs = get_source_inputs(input_tensor)\n","    else:\n","        inputs = img_input\n","\n","    model = Model(inputs, x, name='deeplabv3+')\n","\n","    # load weights\n","\n","    if weights == 'pascal_voc':\n","        if backbone == 'xception':\n","            weights_path = get_file('deeplabv3_xception_tf_dim_ordering_tf_kernels.h5',\n","                                    WEIGHTS_PATH_X,\n","                                    cache_subdir='models')\n","        else:\n","            weights_path = get_file('deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels.h5',\n","                                    WEIGHTS_PATH_MOBILE,\n","                                    cache_subdir='models')\n","        model.load_weights(weights_path, by_name=True)\n","    return model"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"v3mE8M522kBo","executionInfo":{"status":"ok","timestamp":1669526686880,"user_tz":-420,"elapsed":4,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}}},"outputs":[],"source":["def activation_block(x):\n","  x = Activation(\"gelu\")(x)\n","  return BatchNormalization()(x) #Lambda(mvn)(x)\n","\n","def conv_mixer_block(x, filters, kernel_size):\n","  # Depthwise convolution\n","  x0 = x\n","  x = DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n","  x = Add()([activation_block(x), x0])  # Residual\n","\n","  # Pointwise convolution\n","  x = Conv2D(filters, kernel_size=1)(x)\n","  x = activation_block(x)\n","\n","  return x"]},{"cell_type":"markdown","metadata":{"id":"E2Y3xZbs4pqe"},"source":["## Vanilla U-Net"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1668678882603,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"43Duwou94uaI","outputId":"e35013e4-9a06-4dcc-96fc-3fb651cca4bf"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"input_shape = (256,256,3)\\ninputs = Input(shape=input_shape, dtype='float', name='data')\\n \\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\\ndrop4 = Dropout(0.5)(conv4)\\npool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\\n\\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\\ndrop5 = Dropout(0.5)(conv5)\\n\\nup6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\\nmerge6 = concatenate([drop4,up6], axis = 3)\\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\\n\\nup7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\\nmerge7 = concatenate([conv3,up7], axis = 3)\\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\\n\\nup8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\\nmerge8 = concatenate([conv2,up8], axis = 3)\\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\\n\\nup9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\\nmerge9 = concatenate([conv1,up9], axis = 3)\\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\\nconv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\\nconv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\\n\\nmodel = Model(inputs = inputs, outputs = conv10)\\nmodel = models.unet_2d(input_size=(256,256,3), filter_num=[64,128,256,512], n_labels=1, stack_num_down=2, stack_num_up=2,\\n            activation='ReLU', output_activation='Softmax', batch_norm=False, pool=True, unpool=True, \\n            backbone=None, weights='imagenet', freeze_backbone=True, freeze_batch_norm=True, name='unet')\\nmodel.summary()\""]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["'''input_shape = (256,256,3)\n","inputs = Input(shape=input_shape, dtype='float', name='data')\n"," \n","conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","drop4 = Dropout(0.5)(conv4)\n","pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","drop5 = Dropout(0.5)(conv5)\n","\n","up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","merge6 = concatenate([drop4,up6], axis = 3)\n","conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","merge7 = concatenate([conv3,up7], axis = 3)\n","conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","merge8 = concatenate([conv2,up8], axis = 3)\n","conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","merge9 = concatenate([conv1,up9], axis = 3)\n","conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","model = Model(inputs = inputs, outputs = conv10)\n","model = models.unet_2d(input_size=(256,256,3), filter_num=[64,128,256,512], n_labels=1, stack_num_down=2, stack_num_up=2,\n","            activation='ReLU', output_activation='Softmax', batch_norm=False, pool=True, unpool=True, \n","            backbone=None, weights='imagenet', freeze_backbone=True, freeze_batch_norm=True, name='unet')\n","model.summary()'''"]},{"cell_type":"markdown","metadata":{"id":"7Ky_Sm9W90Uk"},"source":["## FCN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1668678883141,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"uQqcdoPg93N0","outputId":"61334acb-d3cb-4eda-bef6-b52d03db8a75"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"input_shape = (256,256,3)\\ninputs = Input(shape=input_shape, dtype='float', name='data')\\n\\nmvn0 = Lambda(mvn)(inputs)\\npad0 = ZeroPadding2D(padding = 5)(mvn0)\\n\\nconv1 = Conv2D(64, kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(pad0)\\nmvn1 = Lambda(mvn)(conv1)\\n\\nconv2 = Conv2D(64,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias =True)(mvn1)\\nmvn2 = Lambda(mvn)(conv2)\\n\\nconv3 = Conv2D(64,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias =True)(mvn2)\\nmvn3 = Lambda(mvn)(conv3)\\n\\nmxp1 = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid')(mvn3)\\n\\nconv4 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mxp1)\\nmvn4 = Lambda(mvn)(conv4)\\n\\nconv5 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn4)\\nmvn5 = Lambda(mvn)(conv5)\\n\\nconv6 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn5)\\nmvn6 = Lambda(mvn)(conv6)\\n\\nconv7 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn6)\\nmvn7 = Lambda(mvn)(conv7)\\n\\n#drop1 = Dropout(rate = 0.5)(mvn7)\\n\\nmxp2 = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid')(mvn7)\\n\\nconv8 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mxp2)\\nmvn8 = Lambda(mvn)(conv8)\\n\\nconv9 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn8)\\nmvn9 = Lambda(mvn)(conv9)\\n\\nconv10 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn9)\\nmvn10 = Lambda(mvn)(conv10)\\n\\nconv11 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn10)\\nmvn11 = Lambda(mvn)(conv11)\\n\\nmxp3 = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid')(mvn11)\\n    \\ndrop2 = Dropout(rate = 0.5)(mxp3)\\n\\nconv12 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(drop2)\\nmvn12 = Lambda(mvn)(conv12)\\n\\nconv13 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn12)\\nmvn13 = Lambda(mvn)(conv13)\\n\\nconv14 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn13)\\nmvn14 = Lambda(mvn)(conv14)\\n\\nconv15 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn14)\\nmvn15 = Lambda(mvn)(conv15)\\n\\ndrop3 = Dropout(rate = 0.5)(mvn15)\\n\\nscore_conv15 = Conv2D(1, (1,1), strides = (1,1), use_bias = True, padding = 'valid')(drop3)\\n\\nupsample1 = Conv2DTranspose(1, (3,3), strides = (2,2), use_bias = False, padding = 'valid')(score_conv15)\\n#Conv2DTranspose = Deconvolution : php bin i i ngc li tch chp \\n#t mt th c hnh dng u ra ca 1 php tch chp sang 1 th c hnh dng u vo ca n.\\nscore_conv11 = Conv2D(1, (1,1), strides = (1,1), use_bias = True, padding = 'valid')(mvn11)\\n\\ncrop1 = Lambda(crop)([upsample1, score_conv11])\\nfuse1 = average([crop1, upsample1])\\n\\nupsample2 = Conv2DTranspose(1, (3,3), strides = (2,2), use_bias = False, padding = 'valid')(fuse1)\\n\\nscore_conv7 = Conv2D(1, (1,1), strides = (1,1), use_bias = True, padding = 'valid')(mvn7)\\n\\ncrop2 = Lambda(crop)([upsample2, score_conv7])\\nfuse2 = average([crop2, upsample2])\\n\\nupsample3 = Conv2DTranspose(1, (3,3), strides = (2,2), use_bias = False, padding = 'valid' )(fuse2)\\n\\ncrop3 = Lambda(crop)([inputs, upsample3])\\n    \\npredict = Conv2D(1, (1,1), strides = (1,1), padding = 'valid', activation = 'sigmoid', use_bias = True)(crop3)\\nmodel = Model(inputs=inputs, outputs=predict)\\n\\nmodel.summary()\""]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["'''input_shape = (256,256,3)\n","inputs = Input(shape=input_shape, dtype='float', name='data')\n","\n","mvn0 = Lambda(mvn)(inputs)\n","pad0 = ZeroPadding2D(padding = 5)(mvn0)\n","\n","conv1 = Conv2D(64, kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(pad0)\n","mvn1 = Lambda(mvn)(conv1)\n","\n","conv2 = Conv2D(64,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias =True)(mvn1)\n","mvn2 = Lambda(mvn)(conv2)\n","\n","conv3 = Conv2D(64,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias =True)(mvn2)\n","mvn3 = Lambda(mvn)(conv3)\n","\n","mxp1 = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid')(mvn3)\n","\n","conv4 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mxp1)\n","mvn4 = Lambda(mvn)(conv4)\n","\n","conv5 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn4)\n","mvn5 = Lambda(mvn)(conv5)\n","\n","conv6 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn5)\n","mvn6 = Lambda(mvn)(conv6)\n","\n","conv7 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn6)\n","mvn7 = Lambda(mvn)(conv7)\n","\n","#drop1 = Dropout(rate = 0.5)(mvn7)\n","\n","mxp2 = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid')(mvn7)\n","\n","conv8 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mxp2)\n","mvn8 = Lambda(mvn)(conv8)\n","\n","conv9 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn8)\n","mvn9 = Lambda(mvn)(conv9)\n","\n","conv10 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn9)\n","mvn10 = Lambda(mvn)(conv10)\n","\n","conv11 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn10)\n","mvn11 = Lambda(mvn)(conv11)\n","\n","mxp3 = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid')(mvn11)\n","    \n","drop2 = Dropout(rate = 0.5)(mxp3)\n","\n","conv12 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(drop2)\n","mvn12 = Lambda(mvn)(conv12)\n","\n","conv13 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn12)\n","mvn13 = Lambda(mvn)(conv13)\n","\n","conv14 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn13)\n","mvn14 = Lambda(mvn)(conv14)\n","\n","conv15 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn14)\n","mvn15 = Lambda(mvn)(conv15)\n","\n","drop3 = Dropout(rate = 0.5)(mvn15)\n","\n","score_conv15 = Conv2D(1, (1,1), strides = (1,1), use_bias = True, padding = 'valid')(drop3)\n","\n","upsample1 = Conv2DTranspose(1, (3,3), strides = (2,2), use_bias = False, padding = 'valid')(score_conv15)\n","#Conv2DTranspose = Deconvolution : php bin i i ngc li tch chp \n","#t mt th c hnh dng u ra ca 1 php tch chp sang 1 th c hnh dng u vo ca n.\n","score_conv11 = Conv2D(1, (1,1), strides = (1,1), use_bias = True, padding = 'valid')(mvn11)\n","\n","crop1 = Lambda(crop)([upsample1, score_conv11])\n","fuse1 = average([crop1, upsample1])\n","\n","upsample2 = Conv2DTranspose(1, (3,3), strides = (2,2), use_bias = False, padding = 'valid')(fuse1)\n","\n","score_conv7 = Conv2D(1, (1,1), strides = (1,1), use_bias = True, padding = 'valid')(mvn7)\n","\n","crop2 = Lambda(crop)([upsample2, score_conv7])\n","fuse2 = average([crop2, upsample2])\n","\n","upsample3 = Conv2DTranspose(1, (3,3), strides = (2,2), use_bias = False, padding = 'valid' )(fuse2)\n","\n","crop3 = Lambda(crop)([inputs, upsample3])\n","    \n","predict = Conv2D(1, (1,1), strides = (1,1), padding = 'valid', activation = 'sigmoid', use_bias = True)(crop3)\n","model = Model(inputs=inputs, outputs=predict)\n","\n","model.summary()'''"]},{"cell_type":"markdown","metadata":{"id":"KvDV_mvpTrA6"},"source":["## Attention U-Net"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1668594589134,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"djkb4I5oTt9e","outputId":"622adda3-136b-46b6-d87e-90327f2a1115"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"%run /content/drive/MyDrive/brain_mri_segmentation/EfficientUNet.ipynb\\nmodel3 = get_efficient_unet_b0((256,256,3), pretrained=True, block_type='transpose', concat_input=True,out_channels=1)\\nmodel3.summary()\""]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["'''input_shape = (256,256,3)\n","data = Input(shape=input_shape, dtype='float', name='data')\n","\n","mvn0 = BatchNormalization()(data)\n","conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n","conv1 = BatchNormalization()(conv1)\n","conv1 = Activation('relu')(conv1)\n","conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n","conv1 = BatchNormalization()(conv1)\n","conv1 = Activation('relu')(conv1)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","conv2 = Conv2D(128, 3,  padding = 'same')(pool1)\n","conv2 = BatchNormalization()(conv2)\n","conv2 = Activation('relu')(conv2)\n","conv2 = Conv2D(128, 3,  padding = 'same')(conv2)\n","conv2 = BatchNormalization()(conv2)\n","conv2 = Activation('relu')(conv2)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","conv3 = Conv2D(256, 3,  padding = 'same')(pool2)\n","conv3 = BatchNormalization()(conv3)\n","conv3 = Activation('relu')(conv3)\n","conv3 = Conv2D(256, 3,  padding = 'same')(conv3)\n","conv3 = BatchNormalization()(conv3)\n","conv3 = Activation('relu')(conv3)\n","pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    \n","conv4 = Conv2D(512, 3,  padding = 'same')(pool3)\n","conv4 = BatchNormalization()(conv4)\n","conv4 = Activation('relu')(conv4)\n","conv4 = Conv2D(512, 3,  padding = 'same')(conv4)\n","conv4 = BatchNormalization()(conv4)\n","conv4 = Activation('relu')(conv4)\n","drop4 = Dropout(0.5)(conv4)\n","pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","#pool4 = ASPP(pool4,1024)\n","\n","conv5 = Conv2D(1024, 3,  padding = 'same')(pool4)\n","conv5 = BatchNormalization()(conv5)\n","conv5 = Activation('relu')(conv5)\n","conv5 = Conv2D(1024, 3,  padding = 'same')(conv5)\n","conv5 = BatchNormalization()(conv5)\n","conv5 = Activation('relu')(conv5)\n","drop5 = Dropout(0.5)(conv5)\n","\n","merge6 = attention_up_and_concate(conv5,conv4)\n","conv6 = Conv2D(512, 3,  padding = 'same')(merge6)\n","conv6 = BatchNormalization()(conv6)\n","conv6 = Activation('relu')(conv6)\n","conv6 = Conv2D(512, 3,  padding = 'same')(conv6)\n","conv6 = BatchNormalization()(conv6)\n","conv6 = Activation('relu')(conv6)\n","\n","merge7 = attention_up_and_concate(conv6,conv3)\n","conv7 = Conv2D(256, 3,  padding = 'same')(merge7)\n","conv7 = BatchNormalization()(conv7)\n","conv7 = Activation('relu')(conv7)\n","conv7 = Conv2D(256, 3,  padding = 'same')(conv7)\n","conv7 = BatchNormalization()(conv7)\n","conv7 = Activation('relu')(conv7)\n","\n","merge8 = attention_up_and_concate(conv7,conv2)\n","conv8 = Conv2D(128, 3,  padding = 'same')(merge8)\n","conv8 = BatchNormalization()(conv8)\n","conv8 = Activation('relu')(conv8)\n","conv8 = Conv2D(128, 3,  padding = 'same')(conv8)\n","conv8 = BatchNormalization()(conv8)\n","conv8 = Activation('relu')(conv8)\n","\n","merge9 = attention_up_and_concate(conv8,conv1)\n","conv9 = Conv2D(64, 3,  padding = 'same')(merge9)\n","conv9 = BatchNormalization()(conv9)\n","conv9 = Activation('relu')(conv9)\n","conv9 = Conv2D(64, 3,  padding = 'same')(conv9)\n","conv9 = BatchNormalization()(conv9)\n","conv9 = Activation('relu')(conv9)\n","conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","model3 = Model(data, conv10) \n","model3.summary()'''\n","#0.9043\n","\n","'''%run /content/drive/MyDrive/brain_mri_segmentation/EfficientUNet.ipynb\n","model3 = get_efficient_unet_b0((256,256,3), pretrained=True, block_type='transpose', concat_input=True,out_channels=1)\n","model3.summary()'''"]},{"cell_type":"markdown","metadata":{"id":"6Hj2Sf2wcv5k"},"source":["## UNet with EfficientNet encoder and Residual decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1668594589134,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"PhPSb6zGcvLu","outputId":"825e0ee1-2071-48a7-e01c-cdbe6b3e2964"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'input_shape = (256,256,3)\\ndropout_rate = 0.5\\n\\nbackbone = EfficientNetB4(weights=\\'imagenet\\', include_top=False, input_shape=input_shape)\\ninput = backbone.input\\nstart_neurons = 16\\n\\nconv4 = backbone.layers[342].output\\nconv4 = Lambda(mvn)(conv4)\\nconv4 = ReLU()(conv4) #LeakyReLU(alpha=0.1)(conv4)\\npool4 = MaxPooling2D((2, 2))(conv4)\\npool4 = ASPP(pool4,start_neurons * 32)\\npool4 = Dropout(dropout_rate)(pool4)\\n    \\n# Middle\\nconvm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\\nconvm = residual_block(convm,start_neurons * 32)\\nconvm = residual_block(convm,start_neurons * 32)\\nconvm = Lambda(mvn)(convm)\\nconvm = ReLU()(convm) #LeakyReLU(alpha=0.1)(convm)\\n    \\ndeconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\\nuconv4 = concatenate([deconv4, conv4])\\nuconv4 = Dropout(dropout_rate)(uconv4)\\n    \\nuconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\\nuconv4 = residual_block(uconv4,start_neurons * 16)\\nuconv4 = residual_block(uconv4,start_neurons * 16)\\nuconv4 = Lambda(mvn)(uconv4)\\nuconv4 = ReLU()(uconv4) #LeakyReLU(alpha=0.1)(uconv4)\\n    \\ndeconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\\nconv3 = backbone.layers[154].output\\nuconv3 = concatenate([deconv3, conv3])    \\nuconv3 = Dropout(dropout_rate)(uconv3)\\n    \\nuconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\\nuconv3 = residual_block(uconv3,start_neurons * 8)\\nuconv3 = residual_block(uconv3,start_neurons * 8)\\nuconv3 = Lambda(mvn)(uconv3)\\nuconv3 = ReLU()(uconv3) #LeakyReLU(alpha=0.1)(uconv3)\\n\\ndeconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\\nconv2 = backbone.layers[94].output\\nuconv2 = concatenate([deconv2, conv2])\\n        \\nuconv2 = Dropout(0.1)(uconv2)\\nuconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\\nuconv2 = residual_block(uconv2,start_neurons * 4)\\nuconv2 = residual_block(uconv2,start_neurons * 4)\\nuconv2 = Lambda(mvn)(uconv2)\\nuconv2 = ReLU()(uconv2) #LeakyReLU(alpha=0.1)(uconv2)\\n    \\ndeconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\\nconv1 = backbone.layers[30].output\\nuconv1 = concatenate([deconv1, conv1])\\n    \\nuconv1 = Dropout(0.1)(uconv1)\\nuconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\\nuconv1 = residual_block(uconv1,start_neurons * 2)\\nuconv1 = residual_block(uconv1,start_neurons * 2)\\nuconv1 = Lambda(mvn)(uconv1)\\nuconv1 = ReLU()(uconv1) #LeakyReLU(alpha=0.1)(uconv1)\\n    \\nuconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \\nuconv0 = Dropout(0.1)(uconv0)\\nuconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\\nuconv0 = residual_block(uconv0,start_neurons * 1)\\nuconv0 = residual_block(uconv0,start_neurons * 1)\\nuconv0 = Lambda(mvn)(uconv0)\\nuconv0 = ReLU()(uconv0) #LeakyReLU(alpha=0.1)(uconv0)\\n\\nuconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \\nuconv0 = Dropout(dropout_rate/2)(uconv0)\\noutput_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \\n    \\nmodel = Model(input, output_layer)\\nmodel.summary()\\n#0.9150'"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["'''input_shape = (256,256,3)\n","dropout_rate = 0.5\n","\n","backbone = EfficientNetB4(weights='imagenet', include_top=False, input_shape=input_shape)\n","input = backbone.input\n","start_neurons = 16\n","\n","conv4 = backbone.layers[342].output\n","conv4 = Lambda(mvn)(conv4)\n","conv4 = ReLU()(conv4) #LeakyReLU(alpha=0.1)(conv4)\n","pool4 = MaxPooling2D((2, 2))(conv4)\n","pool4 = ASPP(pool4,start_neurons * 32)\n","pool4 = Dropout(dropout_rate)(pool4)\n","    \n","# Middle\n","convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","convm = residual_block(convm,start_neurons * 32)\n","convm = residual_block(convm,start_neurons * 32)\n","convm = Lambda(mvn)(convm)\n","convm = ReLU()(convm) #LeakyReLU(alpha=0.1)(convm)\n","    \n","deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","uconv4 = concatenate([deconv4, conv4])\n","uconv4 = Dropout(dropout_rate)(uconv4)\n","    \n","uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n","uconv4 = residual_block(uconv4,start_neurons * 16)\n","uconv4 = residual_block(uconv4,start_neurons * 16)\n","uconv4 = Lambda(mvn)(uconv4)\n","uconv4 = ReLU()(uconv4) #LeakyReLU(alpha=0.1)(uconv4)\n","    \n","deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","conv3 = backbone.layers[154].output\n","uconv3 = concatenate([deconv3, conv3])    \n","uconv3 = Dropout(dropout_rate)(uconv3)\n","    \n","uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n","uconv3 = residual_block(uconv3,start_neurons * 8)\n","uconv3 = residual_block(uconv3,start_neurons * 8)\n","uconv3 = Lambda(mvn)(uconv3)\n","uconv3 = ReLU()(uconv3) #LeakyReLU(alpha=0.1)(uconv3)\n","\n","deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","conv2 = backbone.layers[94].output\n","uconv2 = concatenate([deconv2, conv2])\n","        \n","uconv2 = Dropout(0.1)(uconv2)\n","uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n","uconv2 = residual_block(uconv2,start_neurons * 4)\n","uconv2 = residual_block(uconv2,start_neurons * 4)\n","uconv2 = Lambda(mvn)(uconv2)\n","uconv2 = ReLU()(uconv2) #LeakyReLU(alpha=0.1)(uconv2)\n","    \n","deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","conv1 = backbone.layers[30].output\n","uconv1 = concatenate([deconv1, conv1])\n","    \n","uconv1 = Dropout(0.1)(uconv1)\n","uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","uconv1 = residual_block(uconv1,start_neurons * 2)\n","uconv1 = residual_block(uconv1,start_neurons * 2)\n","uconv1 = Lambda(mvn)(uconv1)\n","uconv1 = ReLU()(uconv1) #LeakyReLU(alpha=0.1)(uconv1)\n","    \n","uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","uconv0 = Dropout(0.1)(uconv0)\n","uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","uconv0 = residual_block(uconv0,start_neurons * 1)\n","uconv0 = residual_block(uconv0,start_neurons * 1)\n","uconv0 = Lambda(mvn)(uconv0)\n","uconv0 = ReLU()(uconv0) #LeakyReLU(alpha=0.1)(uconv0)\n","\n","uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \n","uconv0 = Dropout(dropout_rate/2)(uconv0)\n","output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n","    \n","model = Model(input, output_layer)\n","model.summary()\n","#0.9150''' "]},{"cell_type":"markdown","metadata":{"id":"BxnCiIzBxyln"},"source":["## Proposed Model\n","#### (y l model gc ca paper anh nh)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9401,"status":"ok","timestamp":1669451867943,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"0MRo5P-mx1PV","outputId":"c22eee71-811b-4d3f-ad84-5ca0172eef3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 128, 128, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," stem_conv (Conv2D)             (None, 64, 64, 48)   432         ['input_2[0][0]']                \n","                                                                                                  \n"," stem_bn (BatchNormalization)   (None, 64, 64, 48)   192         ['stem_conv[0][0]']              \n","                                                                                                  \n"," stem_activation (Activation)   (None, 64, 64, 48)   0           ['stem_bn[0][0]']                \n","                                                                                                  \n"," block1a_dwconv (DepthwiseConv2  (None, 64, 64, 48)  432         ['stem_activation[0][0]']        \n"," D)                                                                                               \n","                                                                                                  \n"," block1a_bn (BatchNormalization  (None, 64, 64, 48)  192         ['block1a_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block1a_activation (Activation  (None, 64, 64, 48)  0           ['block1a_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block1a_se_squeeze (GlobalAver  (None, 48)          0           ['block1a_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block1a_se_reshape (Reshape)   (None, 1, 1, 48)     0           ['block1a_se_squeeze[0][0]']     \n","                                                                                                  \n"," block1a_se_reduce (Conv2D)     (None, 1, 1, 12)     588         ['block1a_se_reshape[0][0]']     \n","                                                                                                  \n"," block1a_se_expand (Conv2D)     (None, 1, 1, 48)     624         ['block1a_se_reduce[0][0]']      \n","                                                                                                  \n"," block1a_se_excite (Multiply)   (None, 64, 64, 48)   0           ['block1a_activation[0][0]',     \n","                                                                  'block1a_se_expand[0][0]']      \n","                                                                                                  \n"," block1a_project_conv (Conv2D)  (None, 64, 64, 24)   1152        ['block1a_se_excite[0][0]']      \n","                                                                                                  \n"," block1a_project_bn (BatchNorma  (None, 64, 64, 24)  96          ['block1a_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block1b_dwconv (DepthwiseConv2  (None, 64, 64, 24)  216         ['block1a_project_bn[0][0]']     \n"," D)                                                                                               \n","                                                                                                  \n"," block1b_bn (BatchNormalization  (None, 64, 64, 24)  96          ['block1b_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block1b_activation (Activation  (None, 64, 64, 24)  0           ['block1b_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block1b_se_squeeze (GlobalAver  (None, 24)          0           ['block1b_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block1b_se_reshape (Reshape)   (None, 1, 1, 24)     0           ['block1b_se_squeeze[0][0]']     \n","                                                                                                  \n"," block1b_se_reduce (Conv2D)     (None, 1, 1, 6)      150         ['block1b_se_reshape[0][0]']     \n","                                                                                                  \n"," block1b_se_expand (Conv2D)     (None, 1, 1, 24)     168         ['block1b_se_reduce[0][0]']      \n","                                                                                                  \n"," block1b_se_excite (Multiply)   (None, 64, 64, 24)   0           ['block1b_activation[0][0]',     \n","                                                                  'block1b_se_expand[0][0]']      \n","                                                                                                  \n"," block1b_project_conv (Conv2D)  (None, 64, 64, 24)   576         ['block1b_se_excite[0][0]']      \n","                                                                                                  \n"," block1b_project_bn (BatchNorma  (None, 64, 64, 24)  96          ['block1b_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block1b_drop (FixedDropout)    (None, 64, 64, 24)   0           ['block1b_project_bn[0][0]']     \n","                                                                                                  \n"," block1b_add (Add)              (None, 64, 64, 24)   0           ['block1b_drop[0][0]',           \n","                                                                  'block1a_project_bn[0][0]']     \n","                                                                                                  \n"," block2a_expand_conv (Conv2D)   (None, 64, 64, 144)  3456        ['block1b_add[0][0]']            \n","                                                                                                  \n"," block2a_expand_bn (BatchNormal  (None, 64, 64, 144)  576        ['block2a_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block2a_expand_activation (Act  (None, 64, 64, 144)  0          ['block2a_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block2a_dwconv (DepthwiseConv2  (None, 32, 32, 144)  1296       ['block2a_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block2a_bn (BatchNormalization  (None, 32, 32, 144)  576        ['block2a_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block2a_activation (Activation  (None, 32, 32, 144)  0          ['block2a_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block2a_se_squeeze (GlobalAver  (None, 144)         0           ['block2a_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block2a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2a_se_squeeze[0][0]']     \n","                                                                                                  \n"," block2a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2a_se_reshape[0][0]']     \n","                                                                                                  \n"," block2a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2a_se_reduce[0][0]']      \n","                                                                                                  \n"," block2a_se_excite (Multiply)   (None, 32, 32, 144)  0           ['block2a_activation[0][0]',     \n","                                                                  'block2a_se_expand[0][0]']      \n","                                                                                                  \n"," block2a_project_conv (Conv2D)  (None, 32, 32, 32)   4608        ['block2a_se_excite[0][0]']      \n","                                                                                                  \n"," block2a_project_bn (BatchNorma  (None, 32, 32, 32)  128         ['block2a_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block2b_expand_conv (Conv2D)   (None, 32, 32, 192)  6144        ['block2a_project_bn[0][0]']     \n","                                                                                                  \n"," block2b_expand_bn (BatchNormal  (None, 32, 32, 192)  768        ['block2b_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block2b_expand_activation (Act  (None, 32, 32, 192)  0          ['block2b_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block2b_dwconv (DepthwiseConv2  (None, 32, 32, 192)  1728       ['block2b_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block2b_bn (BatchNormalization  (None, 32, 32, 192)  768        ['block2b_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block2b_activation (Activation  (None, 32, 32, 192)  0          ['block2b_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block2b_se_squeeze (GlobalAver  (None, 192)         0           ['block2b_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block2b_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2b_se_squeeze[0][0]']     \n","                                                                                                  \n"," block2b_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2b_se_reshape[0][0]']     \n","                                                                                                  \n"," block2b_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2b_se_reduce[0][0]']      \n","                                                                                                  \n"," block2b_se_excite (Multiply)   (None, 32, 32, 192)  0           ['block2b_activation[0][0]',     \n","                                                                  'block2b_se_expand[0][0]']      \n","                                                                                                  \n"," block2b_project_conv (Conv2D)  (None, 32, 32, 32)   6144        ['block2b_se_excite[0][0]']      \n","                                                                                                  \n"," block2b_project_bn (BatchNorma  (None, 32, 32, 32)  128         ['block2b_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block2b_drop (FixedDropout)    (None, 32, 32, 32)   0           ['block2b_project_bn[0][0]']     \n","                                                                                                  \n"," block2b_add (Add)              (None, 32, 32, 32)   0           ['block2b_drop[0][0]',           \n","                                                                  'block2a_project_bn[0][0]']     \n","                                                                                                  \n"," block2c_expand_conv (Conv2D)   (None, 32, 32, 192)  6144        ['block2b_add[0][0]']            \n","                                                                                                  \n"," block2c_expand_bn (BatchNormal  (None, 32, 32, 192)  768        ['block2c_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block2c_expand_activation (Act  (None, 32, 32, 192)  0          ['block2c_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block2c_dwconv (DepthwiseConv2  (None, 32, 32, 192)  1728       ['block2c_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block2c_bn (BatchNormalization  (None, 32, 32, 192)  768        ['block2c_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block2c_activation (Activation  (None, 32, 32, 192)  0          ['block2c_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block2c_se_squeeze (GlobalAver  (None, 192)         0           ['block2c_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block2c_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2c_se_squeeze[0][0]']     \n","                                                                                                  \n"," block2c_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2c_se_reshape[0][0]']     \n","                                                                                                  \n"," block2c_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2c_se_reduce[0][0]']      \n","                                                                                                  \n"," block2c_se_excite (Multiply)   (None, 32, 32, 192)  0           ['block2c_activation[0][0]',     \n","                                                                  'block2c_se_expand[0][0]']      \n","                                                                                                  \n"," block2c_project_conv (Conv2D)  (None, 32, 32, 32)   6144        ['block2c_se_excite[0][0]']      \n","                                                                                                  \n"," block2c_project_bn (BatchNorma  (None, 32, 32, 32)  128         ['block2c_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block2c_drop (FixedDropout)    (None, 32, 32, 32)   0           ['block2c_project_bn[0][0]']     \n","                                                                                                  \n"," block2c_add (Add)              (None, 32, 32, 32)   0           ['block2c_drop[0][0]',           \n","                                                                  'block2b_add[0][0]']            \n","                                                                                                  \n"," block2d_expand_conv (Conv2D)   (None, 32, 32, 192)  6144        ['block2c_add[0][0]']            \n","                                                                                                  \n"," block2d_expand_bn (BatchNormal  (None, 32, 32, 192)  768        ['block2d_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block2d_expand_activation (Act  (None, 32, 32, 192)  0          ['block2d_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block2d_dwconv (DepthwiseConv2  (None, 32, 32, 192)  1728       ['block2d_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block2d_bn (BatchNormalization  (None, 32, 32, 192)  768        ['block2d_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block2d_activation (Activation  (None, 32, 32, 192)  0          ['block2d_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block2d_se_squeeze (GlobalAver  (None, 192)         0           ['block2d_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block2d_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2d_se_squeeze[0][0]']     \n","                                                                                                  \n"," block2d_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2d_se_reshape[0][0]']     \n","                                                                                                  \n"," block2d_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2d_se_reduce[0][0]']      \n","                                                                                                  \n"," block2d_se_excite (Multiply)   (None, 32, 32, 192)  0           ['block2d_activation[0][0]',     \n","                                                                  'block2d_se_expand[0][0]']      \n","                                                                                                  \n"," block2d_project_conv (Conv2D)  (None, 32, 32, 32)   6144        ['block2d_se_excite[0][0]']      \n","                                                                                                  \n"," block2d_project_bn (BatchNorma  (None, 32, 32, 32)  128         ['block2d_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block2d_drop (FixedDropout)    (None, 32, 32, 32)   0           ['block2d_project_bn[0][0]']     \n","                                                                                                  \n"," block2d_add (Add)              (None, 32, 32, 32)   0           ['block2d_drop[0][0]',           \n","                                                                  'block2c_add[0][0]']            \n","                                                                                                  \n"," block3a_expand_conv (Conv2D)   (None, 32, 32, 192)  6144        ['block2d_add[0][0]']            \n","                                                                                                  \n"," block3a_expand_bn (BatchNormal  (None, 32, 32, 192)  768        ['block3a_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block3a_expand_activation (Act  (None, 32, 32, 192)  0          ['block3a_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block3a_dwconv (DepthwiseConv2  (None, 16, 16, 192)  4800       ['block3a_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block3a_bn (BatchNormalization  (None, 16, 16, 192)  768        ['block3a_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block3a_activation (Activation  (None, 16, 16, 192)  0          ['block3a_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block3a_se_squeeze (GlobalAver  (None, 192)         0           ['block3a_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block3a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block3a_se_squeeze[0][0]']     \n","                                                                                                  \n"," block3a_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block3a_se_reshape[0][0]']     \n","                                                                                                  \n"," block3a_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block3a_se_reduce[0][0]']      \n","                                                                                                  \n"," block3a_se_excite (Multiply)   (None, 16, 16, 192)  0           ['block3a_activation[0][0]',     \n","                                                                  'block3a_se_expand[0][0]']      \n","                                                                                                  \n"," block3a_project_conv (Conv2D)  (None, 16, 16, 56)   10752       ['block3a_se_excite[0][0]']      \n","                                                                                                  \n"," block3a_project_bn (BatchNorma  (None, 16, 16, 56)  224         ['block3a_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block3b_expand_conv (Conv2D)   (None, 16, 16, 336)  18816       ['block3a_project_bn[0][0]']     \n","                                                                                                  \n"," block3b_expand_bn (BatchNormal  (None, 16, 16, 336)  1344       ['block3b_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block3b_expand_activation (Act  (None, 16, 16, 336)  0          ['block3b_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block3b_dwconv (DepthwiseConv2  (None, 16, 16, 336)  8400       ['block3b_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block3b_bn (BatchNormalization  (None, 16, 16, 336)  1344       ['block3b_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block3b_activation (Activation  (None, 16, 16, 336)  0          ['block3b_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block3b_se_squeeze (GlobalAver  (None, 336)         0           ['block3b_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block3b_se_reshape (Reshape)   (None, 1, 1, 336)    0           ['block3b_se_squeeze[0][0]']     \n","                                                                                                  \n"," block3b_se_reduce (Conv2D)     (None, 1, 1, 14)     4718        ['block3b_se_reshape[0][0]']     \n","                                                                                                  \n"," block3b_se_expand (Conv2D)     (None, 1, 1, 336)    5040        ['block3b_se_reduce[0][0]']      \n","                                                                                                  \n"," block3b_se_excite (Multiply)   (None, 16, 16, 336)  0           ['block3b_activation[0][0]',     \n","                                                                  'block3b_se_expand[0][0]']      \n","                                                                                                  \n"," block3b_project_conv (Conv2D)  (None, 16, 16, 56)   18816       ['block3b_se_excite[0][0]']      \n","                                                                                                  \n"," block3b_project_bn (BatchNorma  (None, 16, 16, 56)  224         ['block3b_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block3b_drop (FixedDropout)    (None, 16, 16, 56)   0           ['block3b_project_bn[0][0]']     \n","                                                                                                  \n"," block3b_add (Add)              (None, 16, 16, 56)   0           ['block3b_drop[0][0]',           \n","                                                                  'block3a_project_bn[0][0]']     \n","                                                                                                  \n"," block3c_expand_conv (Conv2D)   (None, 16, 16, 336)  18816       ['block3b_add[0][0]']            \n","                                                                                                  \n"," block3c_expand_bn (BatchNormal  (None, 16, 16, 336)  1344       ['block3c_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block3c_expand_activation (Act  (None, 16, 16, 336)  0          ['block3c_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block3c_dwconv (DepthwiseConv2  (None, 16, 16, 336)  8400       ['block3c_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block3c_bn (BatchNormalization  (None, 16, 16, 336)  1344       ['block3c_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block3c_activation (Activation  (None, 16, 16, 336)  0          ['block3c_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block3c_se_squeeze (GlobalAver  (None, 336)         0           ['block3c_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block3c_se_reshape (Reshape)   (None, 1, 1, 336)    0           ['block3c_se_squeeze[0][0]']     \n","                                                                                                  \n"," block3c_se_reduce (Conv2D)     (None, 1, 1, 14)     4718        ['block3c_se_reshape[0][0]']     \n","                                                                                                  \n"," block3c_se_expand (Conv2D)     (None, 1, 1, 336)    5040        ['block3c_se_reduce[0][0]']      \n","                                                                                                  \n"," block3c_se_excite (Multiply)   (None, 16, 16, 336)  0           ['block3c_activation[0][0]',     \n","                                                                  'block3c_se_expand[0][0]']      \n","                                                                                                  \n"," block3c_project_conv (Conv2D)  (None, 16, 16, 56)   18816       ['block3c_se_excite[0][0]']      \n","                                                                                                  \n"," block3c_project_bn (BatchNorma  (None, 16, 16, 56)  224         ['block3c_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block3c_drop (FixedDropout)    (None, 16, 16, 56)   0           ['block3c_project_bn[0][0]']     \n","                                                                                                  \n"," block3c_add (Add)              (None, 16, 16, 56)   0           ['block3c_drop[0][0]',           \n","                                                                  'block3b_add[0][0]']            \n","                                                                                                  \n"," block3d_expand_conv (Conv2D)   (None, 16, 16, 336)  18816       ['block3c_add[0][0]']            \n","                                                                                                  \n"," block3d_expand_bn (BatchNormal  (None, 16, 16, 336)  1344       ['block3d_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block3d_expand_activation (Act  (None, 16, 16, 336)  0          ['block3d_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block3d_dwconv (DepthwiseConv2  (None, 16, 16, 336)  8400       ['block3d_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block3d_bn (BatchNormalization  (None, 16, 16, 336)  1344       ['block3d_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block3d_activation (Activation  (None, 16, 16, 336)  0          ['block3d_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block3d_se_squeeze (GlobalAver  (None, 336)         0           ['block3d_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block3d_se_reshape (Reshape)   (None, 1, 1, 336)    0           ['block3d_se_squeeze[0][0]']     \n","                                                                                                  \n"," block3d_se_reduce (Conv2D)     (None, 1, 1, 14)     4718        ['block3d_se_reshape[0][0]']     \n","                                                                                                  \n"," block3d_se_expand (Conv2D)     (None, 1, 1, 336)    5040        ['block3d_se_reduce[0][0]']      \n","                                                                                                  \n"," block3d_se_excite (Multiply)   (None, 16, 16, 336)  0           ['block3d_activation[0][0]',     \n","                                                                  'block3d_se_expand[0][0]']      \n","                                                                                                  \n"," block3d_project_conv (Conv2D)  (None, 16, 16, 56)   18816       ['block3d_se_excite[0][0]']      \n","                                                                                                  \n"," block3d_project_bn (BatchNorma  (None, 16, 16, 56)  224         ['block3d_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block3d_drop (FixedDropout)    (None, 16, 16, 56)   0           ['block3d_project_bn[0][0]']     \n","                                                                                                  \n"," block3d_add (Add)              (None, 16, 16, 56)   0           ['block3d_drop[0][0]',           \n","                                                                  'block3c_add[0][0]']            \n","                                                                                                  \n"," block4a_expand_conv (Conv2D)   (None, 16, 16, 336)  18816       ['block3d_add[0][0]']            \n","                                                                                                  \n"," block4a_expand_bn (BatchNormal  (None, 16, 16, 336)  1344       ['block4a_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block4a_expand_activation (Act  (None, 16, 16, 336)  0          ['block4a_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block4a_dwconv (DepthwiseConv2  (None, 8, 8, 336)   3024        ['block4a_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block4a_bn (BatchNormalization  (None, 8, 8, 336)   1344        ['block4a_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block4a_activation (Activation  (None, 8, 8, 336)   0           ['block4a_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block4a_se_squeeze (GlobalAver  (None, 336)         0           ['block4a_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block4a_se_reshape (Reshape)   (None, 1, 1, 336)    0           ['block4a_se_squeeze[0][0]']     \n","                                                                                                  \n"," block4a_se_reduce (Conv2D)     (None, 1, 1, 14)     4718        ['block4a_se_reshape[0][0]']     \n","                                                                                                  \n"," block4a_se_expand (Conv2D)     (None, 1, 1, 336)    5040        ['block4a_se_reduce[0][0]']      \n","                                                                                                  \n"," block4a_se_excite (Multiply)   (None, 8, 8, 336)    0           ['block4a_activation[0][0]',     \n","                                                                  'block4a_se_expand[0][0]']      \n","                                                                                                  \n"," block4a_project_conv (Conv2D)  (None, 8, 8, 112)    37632       ['block4a_se_excite[0][0]']      \n","                                                                                                  \n"," block4a_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block4a_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block4b_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block4a_project_bn[0][0]']     \n","                                                                                                  \n"," block4b_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block4b_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block4b_expand_activation (Act  (None, 8, 8, 672)   0           ['block4b_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block4b_dwconv (DepthwiseConv2  (None, 8, 8, 672)   6048        ['block4b_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block4b_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block4b_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block4b_activation (Activation  (None, 8, 8, 672)   0           ['block4b_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block4b_se_squeeze (GlobalAver  (None, 672)         0           ['block4b_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block4b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block4b_se_squeeze[0][0]']     \n","                                                                                                  \n"," block4b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block4b_se_reshape[0][0]']     \n","                                                                                                  \n"," block4b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block4b_se_reduce[0][0]']      \n","                                                                                                  \n"," block4b_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block4b_activation[0][0]',     \n","                                                                  'block4b_se_expand[0][0]']      \n","                                                                                                  \n"," block4b_project_conv (Conv2D)  (None, 8, 8, 112)    75264       ['block4b_se_excite[0][0]']      \n","                                                                                                  \n"," block4b_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block4b_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block4b_drop (FixedDropout)    (None, 8, 8, 112)    0           ['block4b_project_bn[0][0]']     \n","                                                                                                  \n"," block4b_add (Add)              (None, 8, 8, 112)    0           ['block4b_drop[0][0]',           \n","                                                                  'block4a_project_bn[0][0]']     \n","                                                                                                  \n"," block4c_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block4b_add[0][0]']            \n","                                                                                                  \n"," block4c_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block4c_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block4c_expand_activation (Act  (None, 8, 8, 672)   0           ['block4c_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block4c_dwconv (DepthwiseConv2  (None, 8, 8, 672)   6048        ['block4c_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block4c_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block4c_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block4c_activation (Activation  (None, 8, 8, 672)   0           ['block4c_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block4c_se_squeeze (GlobalAver  (None, 672)         0           ['block4c_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block4c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block4c_se_squeeze[0][0]']     \n","                                                                                                  \n"," block4c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block4c_se_reshape[0][0]']     \n","                                                                                                  \n"," block4c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block4c_se_reduce[0][0]']      \n","                                                                                                  \n"," block4c_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block4c_activation[0][0]',     \n","                                                                  'block4c_se_expand[0][0]']      \n","                                                                                                  \n"," block4c_project_conv (Conv2D)  (None, 8, 8, 112)    75264       ['block4c_se_excite[0][0]']      \n","                                                                                                  \n"," block4c_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block4c_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block4c_drop (FixedDropout)    (None, 8, 8, 112)    0           ['block4c_project_bn[0][0]']     \n","                                                                                                  \n"," block4c_add (Add)              (None, 8, 8, 112)    0           ['block4c_drop[0][0]',           \n","                                                                  'block4b_add[0][0]']            \n","                                                                                                  \n"," block4d_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block4c_add[0][0]']            \n","                                                                                                  \n"," block4d_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block4d_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block4d_expand_activation (Act  (None, 8, 8, 672)   0           ['block4d_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block4d_dwconv (DepthwiseConv2  (None, 8, 8, 672)   6048        ['block4d_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block4d_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block4d_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block4d_activation (Activation  (None, 8, 8, 672)   0           ['block4d_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block4d_se_squeeze (GlobalAver  (None, 672)         0           ['block4d_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block4d_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block4d_se_squeeze[0][0]']     \n","                                                                                                  \n"," block4d_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block4d_se_reshape[0][0]']     \n","                                                                                                  \n"," block4d_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block4d_se_reduce[0][0]']      \n","                                                                                                  \n"," block4d_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block4d_activation[0][0]',     \n","                                                                  'block4d_se_expand[0][0]']      \n","                                                                                                  \n"," block4d_project_conv (Conv2D)  (None, 8, 8, 112)    75264       ['block4d_se_excite[0][0]']      \n","                                                                                                  \n"," block4d_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block4d_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block4d_drop (FixedDropout)    (None, 8, 8, 112)    0           ['block4d_project_bn[0][0]']     \n","                                                                                                  \n"," block4d_add (Add)              (None, 8, 8, 112)    0           ['block4d_drop[0][0]',           \n","                                                                  'block4c_add[0][0]']            \n","                                                                                                  \n"," block4e_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block4d_add[0][0]']            \n","                                                                                                  \n"," block4e_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block4e_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block4e_expand_activation (Act  (None, 8, 8, 672)   0           ['block4e_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block4e_dwconv (DepthwiseConv2  (None, 8, 8, 672)   6048        ['block4e_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block4e_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block4e_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block4e_activation (Activation  (None, 8, 8, 672)   0           ['block4e_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block4e_se_squeeze (GlobalAver  (None, 672)         0           ['block4e_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block4e_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block4e_se_squeeze[0][0]']     \n","                                                                                                  \n"," block4e_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block4e_se_reshape[0][0]']     \n","                                                                                                  \n"," block4e_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block4e_se_reduce[0][0]']      \n","                                                                                                  \n"," block4e_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block4e_activation[0][0]',     \n","                                                                  'block4e_se_expand[0][0]']      \n","                                                                                                  \n"," block4e_project_conv (Conv2D)  (None, 8, 8, 112)    75264       ['block4e_se_excite[0][0]']      \n","                                                                                                  \n"," block4e_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block4e_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block4e_drop (FixedDropout)    (None, 8, 8, 112)    0           ['block4e_project_bn[0][0]']     \n","                                                                                                  \n"," block4e_add (Add)              (None, 8, 8, 112)    0           ['block4e_drop[0][0]',           \n","                                                                  'block4d_add[0][0]']            \n","                                                                                                  \n"," block4f_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block4e_add[0][0]']            \n","                                                                                                  \n"," block4f_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block4f_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block4f_expand_activation (Act  (None, 8, 8, 672)   0           ['block4f_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block4f_dwconv (DepthwiseConv2  (None, 8, 8, 672)   6048        ['block4f_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block4f_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block4f_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block4f_activation (Activation  (None, 8, 8, 672)   0           ['block4f_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block4f_se_squeeze (GlobalAver  (None, 672)         0           ['block4f_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block4f_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block4f_se_squeeze[0][0]']     \n","                                                                                                  \n"," block4f_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block4f_se_reshape[0][0]']     \n","                                                                                                  \n"," block4f_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block4f_se_reduce[0][0]']      \n","                                                                                                  \n"," block4f_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block4f_activation[0][0]',     \n","                                                                  'block4f_se_expand[0][0]']      \n","                                                                                                  \n"," block4f_project_conv (Conv2D)  (None, 8, 8, 112)    75264       ['block4f_se_excite[0][0]']      \n","                                                                                                  \n"," block4f_project_bn (BatchNorma  (None, 8, 8, 112)   448         ['block4f_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block4f_drop (FixedDropout)    (None, 8, 8, 112)    0           ['block4f_project_bn[0][0]']     \n","                                                                                                  \n"," block4f_add (Add)              (None, 8, 8, 112)    0           ['block4f_drop[0][0]',           \n","                                                                  'block4e_add[0][0]']            \n","                                                                                                  \n"," block5a_expand_conv (Conv2D)   (None, 8, 8, 672)    75264       ['block4f_add[0][0]']            \n","                                                                                                  \n"," block5a_expand_bn (BatchNormal  (None, 8, 8, 672)   2688        ['block5a_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block5a_expand_activation (Act  (None, 8, 8, 672)   0           ['block5a_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block5a_dwconv (DepthwiseConv2  (None, 8, 8, 672)   16800       ['block5a_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block5a_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block5a_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block5a_activation (Activation  (None, 8, 8, 672)   0           ['block5a_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block5a_se_squeeze (GlobalAver  (None, 672)         0           ['block5a_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block5a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5a_se_squeeze[0][0]']     \n","                                                                                                  \n"," block5a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5a_se_reshape[0][0]']     \n","                                                                                                  \n"," block5a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5a_se_reduce[0][0]']      \n","                                                                                                  \n"," block5a_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block5a_activation[0][0]',     \n","                                                                  'block5a_se_expand[0][0]']      \n","                                                                                                  \n"," block5a_project_conv (Conv2D)  (None, 8, 8, 160)    107520      ['block5a_se_excite[0][0]']      \n","                                                                                                  \n"," block5a_project_bn (BatchNorma  (None, 8, 8, 160)   640         ['block5a_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block5b_expand_conv (Conv2D)   (None, 8, 8, 960)    153600      ['block5a_project_bn[0][0]']     \n","                                                                                                  \n"," block5b_expand_bn (BatchNormal  (None, 8, 8, 960)   3840        ['block5b_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block5b_expand_activation (Act  (None, 8, 8, 960)   0           ['block5b_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block5b_dwconv (DepthwiseConv2  (None, 8, 8, 960)   24000       ['block5b_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block5b_bn (BatchNormalization  (None, 8, 8, 960)   3840        ['block5b_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block5b_activation (Activation  (None, 8, 8, 960)   0           ['block5b_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block5b_se_squeeze (GlobalAver  (None, 960)         0           ['block5b_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block5b_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5b_se_squeeze[0][0]']     \n","                                                                                                  \n"," block5b_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5b_se_reshape[0][0]']     \n","                                                                                                  \n"," block5b_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5b_se_reduce[0][0]']      \n","                                                                                                  \n"," block5b_se_excite (Multiply)   (None, 8, 8, 960)    0           ['block5b_activation[0][0]',     \n","                                                                  'block5b_se_expand[0][0]']      \n","                                                                                                  \n"," block5b_project_conv (Conv2D)  (None, 8, 8, 160)    153600      ['block5b_se_excite[0][0]']      \n","                                                                                                  \n"," block5b_project_bn (BatchNorma  (None, 8, 8, 160)   640         ['block5b_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block5b_drop (FixedDropout)    (None, 8, 8, 160)    0           ['block5b_project_bn[0][0]']     \n","                                                                                                  \n"," block5b_add (Add)              (None, 8, 8, 160)    0           ['block5b_drop[0][0]',           \n","                                                                  'block5a_project_bn[0][0]']     \n","                                                                                                  \n"," block5c_expand_conv (Conv2D)   (None, 8, 8, 960)    153600      ['block5b_add[0][0]']            \n","                                                                                                  \n"," block5c_expand_bn (BatchNormal  (None, 8, 8, 960)   3840        ['block5c_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block5c_expand_activation (Act  (None, 8, 8, 960)   0           ['block5c_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block5c_dwconv (DepthwiseConv2  (None, 8, 8, 960)   24000       ['block5c_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block5c_bn (BatchNormalization  (None, 8, 8, 960)   3840        ['block5c_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block5c_activation (Activation  (None, 8, 8, 960)   0           ['block5c_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block5c_se_squeeze (GlobalAver  (None, 960)         0           ['block5c_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block5c_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5c_se_squeeze[0][0]']     \n","                                                                                                  \n"," block5c_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5c_se_reshape[0][0]']     \n","                                                                                                  \n"," block5c_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5c_se_reduce[0][0]']      \n","                                                                                                  \n"," block5c_se_excite (Multiply)   (None, 8, 8, 960)    0           ['block5c_activation[0][0]',     \n","                                                                  'block5c_se_expand[0][0]']      \n","                                                                                                  \n"," block5c_project_conv (Conv2D)  (None, 8, 8, 160)    153600      ['block5c_se_excite[0][0]']      \n","                                                                                                  \n"," block5c_project_bn (BatchNorma  (None, 8, 8, 160)   640         ['block5c_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block5c_drop (FixedDropout)    (None, 8, 8, 160)    0           ['block5c_project_bn[0][0]']     \n","                                                                                                  \n"," block5c_add (Add)              (None, 8, 8, 160)    0           ['block5c_drop[0][0]',           \n","                                                                  'block5b_add[0][0]']            \n","                                                                                                  \n"," block5d_expand_conv (Conv2D)   (None, 8, 8, 960)    153600      ['block5c_add[0][0]']            \n","                                                                                                  \n"," block5d_expand_bn (BatchNormal  (None, 8, 8, 960)   3840        ['block5d_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block5d_expand_activation (Act  (None, 8, 8, 960)   0           ['block5d_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block5d_dwconv (DepthwiseConv2  (None, 8, 8, 960)   24000       ['block5d_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block5d_bn (BatchNormalization  (None, 8, 8, 960)   3840        ['block5d_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block5d_activation (Activation  (None, 8, 8, 960)   0           ['block5d_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block5d_se_squeeze (GlobalAver  (None, 960)         0           ['block5d_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block5d_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5d_se_squeeze[0][0]']     \n","                                                                                                  \n"," block5d_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5d_se_reshape[0][0]']     \n","                                                                                                  \n"," block5d_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5d_se_reduce[0][0]']      \n","                                                                                                  \n"," block5d_se_excite (Multiply)   (None, 8, 8, 960)    0           ['block5d_activation[0][0]',     \n","                                                                  'block5d_se_expand[0][0]']      \n","                                                                                                  \n"," block5d_project_conv (Conv2D)  (None, 8, 8, 160)    153600      ['block5d_se_excite[0][0]']      \n","                                                                                                  \n"," block5d_project_bn (BatchNorma  (None, 8, 8, 160)   640         ['block5d_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block5d_drop (FixedDropout)    (None, 8, 8, 160)    0           ['block5d_project_bn[0][0]']     \n","                                                                                                  \n"," block5d_add (Add)              (None, 8, 8, 160)    0           ['block5d_drop[0][0]',           \n","                                                                  'block5c_add[0][0]']            \n","                                                                                                  \n"," block5e_expand_conv (Conv2D)   (None, 8, 8, 960)    153600      ['block5d_add[0][0]']            \n","                                                                                                  \n"," block5e_expand_bn (BatchNormal  (None, 8, 8, 960)   3840        ['block5e_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block5e_expand_activation (Act  (None, 8, 8, 960)   0           ['block5e_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block5e_dwconv (DepthwiseConv2  (None, 8, 8, 960)   24000       ['block5e_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block5e_bn (BatchNormalization  (None, 8, 8, 960)   3840        ['block5e_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block5e_activation (Activation  (None, 8, 8, 960)   0           ['block5e_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block5e_se_squeeze (GlobalAver  (None, 960)         0           ['block5e_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block5e_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5e_se_squeeze[0][0]']     \n","                                                                                                  \n"," block5e_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5e_se_reshape[0][0]']     \n","                                                                                                  \n"," block5e_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5e_se_reduce[0][0]']      \n","                                                                                                  \n"," block5e_se_excite (Multiply)   (None, 8, 8, 960)    0           ['block5e_activation[0][0]',     \n","                                                                  'block5e_se_expand[0][0]']      \n","                                                                                                  \n"," block5e_project_conv (Conv2D)  (None, 8, 8, 160)    153600      ['block5e_se_excite[0][0]']      \n","                                                                                                  \n"," block5e_project_bn (BatchNorma  (None, 8, 8, 160)   640         ['block5e_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block5e_drop (FixedDropout)    (None, 8, 8, 160)    0           ['block5e_project_bn[0][0]']     \n","                                                                                                  \n"," block5e_add (Add)              (None, 8, 8, 160)    0           ['block5e_drop[0][0]',           \n","                                                                  'block5d_add[0][0]']            \n","                                                                                                  \n"," block5f_expand_conv (Conv2D)   (None, 8, 8, 960)    153600      ['block5e_add[0][0]']            \n","                                                                                                  \n"," block5f_expand_bn (BatchNormal  (None, 8, 8, 960)   3840        ['block5f_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block5f_expand_activation (Act  (None, 8, 8, 960)   0           ['block5f_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block5f_dwconv (DepthwiseConv2  (None, 8, 8, 960)   24000       ['block5f_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block5f_bn (BatchNormalization  (None, 8, 8, 960)   3840        ['block5f_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block5f_activation (Activation  (None, 8, 8, 960)   0           ['block5f_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block5f_se_squeeze (GlobalAver  (None, 960)         0           ['block5f_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block5f_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5f_se_squeeze[0][0]']     \n","                                                                                                  \n"," block5f_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5f_se_reshape[0][0]']     \n","                                                                                                  \n"," block5f_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5f_se_reduce[0][0]']      \n","                                                                                                  \n"," block5f_se_excite (Multiply)   (None, 8, 8, 960)    0           ['block5f_activation[0][0]',     \n","                                                                  'block5f_se_expand[0][0]']      \n","                                                                                                  \n"," block5f_project_conv (Conv2D)  (None, 8, 8, 160)    153600      ['block5f_se_excite[0][0]']      \n","                                                                                                  \n"," block5f_project_bn (BatchNorma  (None, 8, 8, 160)   640         ['block5f_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block5f_drop (FixedDropout)    (None, 8, 8, 160)    0           ['block5f_project_bn[0][0]']     \n","                                                                                                  \n"," block5f_add (Add)              (None, 8, 8, 160)    0           ['block5f_drop[0][0]',           \n","                                                                  'block5e_add[0][0]']            \n","                                                                                                  \n"," block6a_expand_conv (Conv2D)   (None, 8, 8, 960)    153600      ['block5f_add[0][0]']            \n","                                                                                                  \n"," block6a_expand_bn (BatchNormal  (None, 8, 8, 960)   3840        ['block6a_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block6a_expand_activation (Act  (None, 8, 8, 960)   0           ['block6a_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block6a_dwconv (DepthwiseConv2  (None, 4, 4, 960)   24000       ['block6a_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block6a_bn (BatchNormalization  (None, 4, 4, 960)   3840        ['block6a_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block6a_activation (Activation  (None, 4, 4, 960)   0           ['block6a_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block6a_se_squeeze (GlobalAver  (None, 960)         0           ['block6a_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block6a_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block6a_se_squeeze[0][0]']     \n","                                                                                                  \n"," block6a_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block6a_se_reshape[0][0]']     \n","                                                                                                  \n"," block6a_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block6a_se_reduce[0][0]']      \n","                                                                                                  \n"," block6a_se_excite (Multiply)   (None, 4, 4, 960)    0           ['block6a_activation[0][0]',     \n","                                                                  'block6a_se_expand[0][0]']      \n","                                                                                                  \n"," block6a_project_conv (Conv2D)  (None, 4, 4, 272)    261120      ['block6a_se_excite[0][0]']      \n","                                                                                                  \n"," block6a_project_bn (BatchNorma  (None, 4, 4, 272)   1088        ['block6a_project_conv[0][0]']   \n"," lization)                                                                                        \n","                                                                                                  \n"," block6b_expand_conv (Conv2D)   (None, 4, 4, 1632)   443904      ['block6a_project_bn[0][0]']     \n","                                                                                                  \n"," block6b_expand_bn (BatchNormal  (None, 4, 4, 1632)  6528        ['block6b_expand_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," block6b_expand_activation (Act  (None, 4, 4, 1632)  0           ['block6b_expand_bn[0][0]']      \n"," ivation)                                                                                         \n","                                                                                                  \n"," block6b_dwconv (DepthwiseConv2  (None, 4, 4, 1632)  40800       ['block6b_expand_activation[0][0]\n"," D)                                                              ']                               \n","                                                                                                  \n"," block6b_bn (BatchNormalization  (None, 4, 4, 1632)  6528        ['block6b_dwconv[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," block6b_activation (Activation  (None, 4, 4, 1632)  0           ['block6b_bn[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," block6b_se_squeeze (GlobalAver  (None, 1632)        0           ['block6b_activation[0][0]']     \n"," agePooling2D)                                                                                    \n","                                                                                                  \n"," block6b_se_reshape (Reshape)   (None, 1, 1, 1632)   0           ['block6b_se_squeeze[0][0]']     \n","                                                                                                  \n"," block6b_se_reduce (Conv2D)     (None, 1, 1, 68)     111044      ['block6b_se_reshape[0][0]']     \n","                                                                                                  \n"," block6b_se_expand (Conv2D)     (None, 1, 1, 1632)   112608      ['block6b_se_reduce[0][0]']      \n","                                                                                                  \n"," block6b_se_excite (Multiply)   (None, 4, 4, 1632)   0           ['block6b_activation[0][0]',     \n","                                                                  'block6b_se_expand[0][0]']      \n","                                                                                                  \n"," block6b_project_conv (Conv2D)  (None, 4, 4, 272)    443904      ['block6b_se_excite[0][0]']      \n","                                                                                                  \n"," lambda_16 (Lambda)             (None, 4, 4, 272)    0           ['block6b_project_conv[0][0]']   \n","                                                                                                  \n"," re_lu_16 (ReLU)                (None, 4, 4, 272)    0           ['lambda_16[0][0]']              \n","                                                                                                  \n"," max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 272)   0           ['re_lu_16[0][0]']               \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 2, 2, 272)    0           ['max_pooling2d_5[0][0]']        \n","                                                                                                  \n"," depthwise_conv2d_10 (Depthwise  (None, 2, 2, 272)   7072        ['dropout_5[0][0]']              \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," activation_20 (Activation)     (None, 2, 2, 272)    0           ['depthwise_conv2d_10[0][0]']    \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 2, 2, 272)   1088        ['activation_20[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_10 (Add)                   (None, 2, 2, 272)    0           ['batch_normalization_20[0][0]', \n","                                                                  'dropout_5[0][0]']              \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 2, 2, 512)    139776      ['add_10[0][0]']                 \n","                                                                                                  \n"," activation_21 (Activation)     (None, 2, 2, 512)    0           ['conv2d_28[0][0]']              \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 2, 2, 512)   2048        ['activation_21[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," depthwise_conv2d_11 (Depthwise  (None, 2, 2, 512)   13312       ['batch_normalization_21[0][0]'] \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," activation_22 (Activation)     (None, 2, 2, 512)    0           ['depthwise_conv2d_11[0][0]']    \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 2, 2, 512)   2048        ['activation_22[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_11 (Add)                   (None, 2, 2, 512)    0           ['batch_normalization_22[0][0]', \n","                                                                  'batch_normalization_21[0][0]'] \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 2, 2, 512)    262656      ['add_11[0][0]']                 \n","                                                                                                  \n"," activation_23 (Activation)     (None, 2, 2, 512)    0           ['conv2d_29[0][0]']              \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 2, 2, 512)   2048        ['activation_23[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," depthwise_conv2d_12 (Depthwise  (None, 2, 2, 512)   13312       ['batch_normalization_23[0][0]'] \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," activation_24 (Activation)     (None, 2, 2, 512)    0           ['depthwise_conv2d_12[0][0]']    \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 2, 2, 512)   2048        ['activation_24[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_12 (Add)                   (None, 2, 2, 512)    0           ['batch_normalization_24[0][0]', \n","                                                                  'batch_normalization_23[0][0]'] \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 2, 2, 512)    262656      ['add_12[0][0]']                 \n","                                                                                                  \n"," activation_25 (Activation)     (None, 2, 2, 512)    0           ['conv2d_30[0][0]']              \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 2, 2, 512)   2048        ['activation_25[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," depthwise_conv2d_13 (Depthwise  (None, 2, 2, 512)   13312       ['batch_normalization_25[0][0]'] \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," activation_26 (Activation)     (None, 2, 2, 512)    0           ['depthwise_conv2d_13[0][0]']    \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 2, 2, 512)   2048        ['activation_26[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_13 (Add)                   (None, 2, 2, 512)    0           ['batch_normalization_26[0][0]', \n","                                                                  'batch_normalization_25[0][0]'] \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 2, 2, 512)    262656      ['add_13[0][0]']                 \n","                                                                                                  \n"," activation_27 (Activation)     (None, 2, 2, 512)    0           ['conv2d_31[0][0]']              \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 2, 2, 512)   2048        ['activation_27[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," depthwise_conv2d_14 (Depthwise  (None, 2, 2, 512)   13312       ['batch_normalization_27[0][0]'] \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," activation_28 (Activation)     (None, 2, 2, 512)    0           ['depthwise_conv2d_14[0][0]']    \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 2, 2, 512)   2048        ['activation_28[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_14 (Add)                   (None, 2, 2, 512)    0           ['batch_normalization_28[0][0]', \n","                                                                  'batch_normalization_27[0][0]'] \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 2, 2, 512)    262656      ['add_14[0][0]']                 \n","                                                                                                  \n"," activation_29 (Activation)     (None, 2, 2, 512)    0           ['conv2d_32[0][0]']              \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 2, 2, 512)   2048        ['activation_29[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," depthwise_conv2d_15 (Depthwise  (None, 2, 2, 512)   13312       ['batch_normalization_29[0][0]'] \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," activation_30 (Activation)     (None, 2, 2, 512)    0           ['depthwise_conv2d_15[0][0]']    \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 2, 2, 512)   2048        ['activation_30[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_15 (Add)                   (None, 2, 2, 512)    0           ['batch_normalization_30[0][0]', \n","                                                                  'batch_normalization_29[0][0]'] \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 2, 2, 512)    262656      ['add_15[0][0]']                 \n","                                                                                                  \n"," activation_31 (Activation)     (None, 2, 2, 512)    0           ['conv2d_33[0][0]']              \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 2, 2, 512)   2048        ['activation_31[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," depthwise_conv2d_16 (Depthwise  (None, 2, 2, 512)   13312       ['batch_normalization_31[0][0]'] \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," activation_32 (Activation)     (None, 2, 2, 512)    0           ['depthwise_conv2d_16[0][0]']    \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 2, 2, 512)   2048        ['activation_32[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_16 (Add)                   (None, 2, 2, 512)    0           ['batch_normalization_32[0][0]', \n","                                                                  'batch_normalization_31[0][0]'] \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 2, 2, 512)    262656      ['add_16[0][0]']                 \n","                                                                                                  \n"," activation_33 (Activation)     (None, 2, 2, 512)    0           ['conv2d_34[0][0]']              \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 2, 2, 512)   2048        ['activation_33[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," depthwise_conv2d_17 (Depthwise  (None, 2, 2, 512)   13312       ['batch_normalization_33[0][0]'] \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," activation_34 (Activation)     (None, 2, 2, 512)    0           ['depthwise_conv2d_17[0][0]']    \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 2, 2, 512)   2048        ['activation_34[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_17 (Add)                   (None, 2, 2, 512)    0           ['batch_normalization_34[0][0]', \n","                                                                  'batch_normalization_33[0][0]'] \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 2, 2, 512)    262656      ['add_17[0][0]']                 \n","                                                                                                  \n"," activation_35 (Activation)     (None, 2, 2, 512)    0           ['conv2d_35[0][0]']              \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 2, 2, 512)   2048        ['activation_35[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," depthwise_conv2d_18 (Depthwise  (None, 2, 2, 512)   13312       ['batch_normalization_35[0][0]'] \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," activation_36 (Activation)     (None, 2, 2, 512)    0           ['depthwise_conv2d_18[0][0]']    \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 2, 2, 512)   2048        ['activation_36[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_18 (Add)                   (None, 2, 2, 512)    0           ['batch_normalization_36[0][0]', \n","                                                                  'batch_normalization_35[0][0]'] \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 2, 2, 512)    262656      ['add_18[0][0]']                 \n","                                                                                                  \n"," activation_37 (Activation)     (None, 2, 2, 512)    0           ['conv2d_36[0][0]']              \n","                                                                                                  \n"," batch_normalization_37 (BatchN  (None, 2, 2, 512)   2048        ['activation_37[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," depthwise_conv2d_19 (Depthwise  (None, 2, 2, 512)   13312       ['batch_normalization_37[0][0]'] \n"," Conv2D)                                                                                          \n","                                                                                                  \n"," activation_38 (Activation)     (None, 2, 2, 512)    0           ['depthwise_conv2d_19[0][0]']    \n","                                                                                                  \n"," batch_normalization_38 (BatchN  (None, 2, 2, 512)   2048        ['activation_38[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_19 (Add)                   (None, 2, 2, 512)    0           ['batch_normalization_38[0][0]', \n","                                                                  'batch_normalization_37[0][0]'] \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 2, 2, 512)    262656      ['add_19[0][0]']                 \n","                                                                                                  \n"," activation_39 (Activation)     (None, 2, 2, 512)    0           ['conv2d_37[0][0]']              \n","                                                                                                  \n"," batch_normalization_39 (BatchN  (None, 2, 2, 512)   2048        ['activation_39[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_transpose_6 (Conv2DTran  (None, 4, 4, 256)   1179904     ['batch_normalization_39[0][0]'] \n"," spose)                                                                                           \n","                                                                                                  \n"," concatenate_8 (Concatenate)    (None, 4, 4, 528)    0           ['conv2d_transpose_6[0][0]',     \n","                                                                  're_lu_16[0][0]']               \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 4, 4, 528)    0           ['concatenate_8[0][0]']          \n","                                                                                                  \n"," conv2d_38 (Conv2D)             (None, 4, 4, 256)    1216768     ['dropout_6[0][0]']              \n","                                                                                                  \n"," lambda_17 (Lambda)             (None, 4, 4, 256)    0           ['conv2d_38[0][0]']              \n","                                                                                                  \n"," re_lu_17 (ReLU)                (None, 4, 4, 256)    0           ['lambda_17[0][0]']              \n","                                                                                                  \n"," conv2d_transpose_7 (Conv2DTran  (None, 8, 8, 128)   295040      ['re_lu_17[0][0]']               \n"," spose)                                                                                           \n","                                                                                                  \n"," concatenate_9 (Concatenate)    (None, 8, 8, 240)    0           ['conv2d_transpose_7[0][0]',     \n","                                                                  'block4a_project_bn[0][0]']     \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 8, 8, 240)    0           ['concatenate_9[0][0]']          \n","                                                                                                  \n"," conv2d_39 (Conv2D)             (None, 8, 8, 128)    276608      ['dropout_7[0][0]']              \n","                                                                                                  \n"," lambda_18 (Lambda)             (None, 8, 8, 128)    0           ['conv2d_39[0][0]']              \n","                                                                                                  \n"," re_lu_18 (ReLU)                (None, 8, 8, 128)    0           ['lambda_18[0][0]']              \n","                                                                                                  \n"," conv2d_transpose_8 (Conv2DTran  (None, 16, 16, 64)  73792       ['re_lu_18[0][0]']               \n"," spose)                                                                                           \n","                                                                                                  \n"," concatenate_10 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_transpose_8[0][0]',     \n","                                                                  'block3a_se_excite[0][0]']      \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, 16, 16, 256)  0           ['concatenate_10[0][0]']         \n","                                                                                                  \n"," conv2d_40 (Conv2D)             (None, 16, 16, 64)   147520      ['dropout_8[0][0]']              \n","                                                                                                  \n"," lambda_19 (Lambda)             (None, 16, 16, 64)   0           ['conv2d_40[0][0]']              \n","                                                                                                  \n"," re_lu_19 (ReLU)                (None, 16, 16, 64)   0           ['lambda_19[0][0]']              \n","                                                                                                  \n"," conv2d_transpose_9 (Conv2DTran  (None, 32, 32, 32)  18464       ['re_lu_19[0][0]']               \n"," spose)                                                                                           \n","                                                                                                  \n"," concatenate_11 (Concatenate)   (None, 32, 32, 176)  0           ['conv2d_transpose_9[0][0]',     \n","                                                                  'block2a_bn[0][0]']             \n","                                                                                                  \n"," dropout_9 (Dropout)            (None, 32, 32, 176)  0           ['concatenate_11[0][0]']         \n","                                                                                                  \n"," conv2d_41 (Conv2D)             (None, 32, 32, 32)   50720       ['dropout_9[0][0]']              \n","                                                                                                  \n"," lambda_20 (Lambda)             (None, 32, 32, 32)   0           ['conv2d_41[0][0]']              \n","                                                                                                  \n"," re_lu_20 (ReLU)                (None, 32, 32, 32)   0           ['lambda_20[0][0]']              \n","                                                                                                  \n"," conv2d_transpose_10 (Conv2DTra  (None, 64, 64, 16)  4624        ['re_lu_20[0][0]']               \n"," nspose)                                                                                          \n","                                                                                                  \n"," conv2d_42 (Conv2D)             (None, 64, 64, 16)   2320        ['conv2d_transpose_10[0][0]']    \n","                                                                                                  \n"," lambda_21 (Lambda)             (None, 64, 64, 16)   0           ['conv2d_42[0][0]']              \n","                                                                                                  \n"," re_lu_21 (ReLU)                (None, 64, 64, 16)   0           ['lambda_21[0][0]']              \n","                                                                                                  \n"," conv2d_transpose_11 (Conv2DTra  (None, 128, 128, 16  2320       ['re_lu_21[0][0]']               \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," conv2d_43 (Conv2D)             (None, 128, 128, 64  9216        ['conv2d_transpose_11[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_44 (Conv2D)             (None, 128, 128, 64  36864       ['conv2d_43[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," lambda_22 (Lambda)             (None, 128, 128, 64  0           ['conv2d_44[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," re_lu_22 (ReLU)                (None, 128, 128, 64  0           ['lambda_22[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 64)  0           ['re_lu_22[0][0]']               \n","                                                                                                  \n"," conv2d_45 (Conv2D)             (None, 64, 64, 64)   36864       ['max_pooling2d_6[0][0]']        \n","                                                                                                  \n"," lambda_23 (Lambda)             (None, 64, 64, 64)   0           ['conv2d_45[0][0]']              \n","                                                                                                  \n"," re_lu_23 (ReLU)                (None, 64, 64, 64)   0           ['lambda_23[0][0]']              \n","                                                                                                  \n"," max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 64)  0           ['re_lu_23[0][0]']               \n","                                                                                                  \n"," conv2d_46 (Conv2D)             (None, 32, 32, 64)   36864       ['max_pooling2d_7[0][0]']        \n","                                                                                                  \n"," lambda_24 (Lambda)             (None, 32, 32, 64)   0           ['conv2d_46[0][0]']              \n","                                                                                                  \n"," re_lu_24 (ReLU)                (None, 32, 32, 64)   0           ['lambda_24[0][0]']              \n","                                                                                                  \n"," max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 64)  0           ['re_lu_24[0][0]']               \n","                                                                                                  \n"," conv2d_47 (Conv2D)             (None, 16, 16, 64)   36864       ['max_pooling2d_8[0][0]']        \n","                                                                                                  \n"," lambda_25 (Lambda)             (None, 16, 16, 64)   0           ['conv2d_47[0][0]']              \n","                                                                                                  \n"," re_lu_25 (ReLU)                (None, 16, 16, 64)   0           ['lambda_25[0][0]']              \n","                                                                                                  \n"," max_pooling2d_9 (MaxPooling2D)  (None, 8, 8, 64)    0           ['re_lu_25[0][0]']               \n","                                                                                                  \n"," conv2d_48 (Conv2D)             (None, 8, 8, 64)     36864       ['max_pooling2d_9[0][0]']        \n","                                                                                                  \n"," lambda_26 (Lambda)             (None, 8, 8, 64)     0           ['conv2d_48[0][0]']              \n","                                                                                                  \n"," re_lu_26 (ReLU)                (None, 8, 8, 64)     0           ['lambda_26[0][0]']              \n","                                                                                                  \n"," up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 64)  0           ['re_lu_26[0][0]']               \n","                                                                                                  \n"," concatenate_12 (Concatenate)   (None, 16, 16, 128)  0           ['up_sampling2d_4[0][0]',        \n","                                                                  'max_pooling2d_8[0][0]']        \n","                                                                                                  \n"," conv2d_49 (Conv2D)             (None, 16, 16, 64)   73728       ['concatenate_12[0][0]']         \n","                                                                                                  \n"," lambda_27 (Lambda)             (None, 16, 16, 64)   0           ['conv2d_49[0][0]']              \n","                                                                                                  \n"," re_lu_27 (ReLU)                (None, 16, 16, 64)   0           ['lambda_27[0][0]']              \n","                                                                                                  \n"," up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 64)  0           ['re_lu_27[0][0]']               \n","                                                                                                  \n"," concatenate_13 (Concatenate)   (None, 32, 32, 128)  0           ['up_sampling2d_5[0][0]',        \n","                                                                  'max_pooling2d_7[0][0]']        \n","                                                                                                  \n"," conv2d_50 (Conv2D)             (None, 32, 32, 64)   73728       ['concatenate_13[0][0]']         \n","                                                                                                  \n"," lambda_28 (Lambda)             (None, 32, 32, 64)   0           ['conv2d_50[0][0]']              \n","                                                                                                  \n"," re_lu_28 (ReLU)                (None, 32, 32, 64)   0           ['lambda_28[0][0]']              \n","                                                                                                  \n"," up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 64)  0           ['re_lu_28[0][0]']               \n","                                                                                                  \n"," concatenate_14 (Concatenate)   (None, 64, 64, 128)  0           ['up_sampling2d_6[0][0]',        \n","                                                                  'max_pooling2d_6[0][0]']        \n","                                                                                                  \n"," lambda_29 (Lambda)             (None, 64, 64, 128)  0           ['concatenate_14[0][0]']         \n","                                                                                                  \n"," re_lu_29 (ReLU)                (None, 64, 64, 128)  0           ['lambda_29[0][0]']              \n","                                                                                                  \n"," up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 12  0          ['re_lu_29[0][0]']               \n","                                8)                                                                \n","                                                                                                  \n"," concatenate_15 (Concatenate)   (None, 128, 128, 19  0           ['up_sampling2d_7[0][0]',        \n","                                2)                                'conv2d_43[0][0]']              \n","                                                                                                  \n"," conv2d_52 (Conv2D)             (None, 128, 128, 64  110592      ['concatenate_15[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," lambda_30 (Lambda)             (None, 128, 128, 64  0           ['conv2d_52[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," re_lu_30 (ReLU)                (None, 128, 128, 64  0           ['lambda_30[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_53 (Conv2D)             (None, 128, 128, 16  9216        ['re_lu_30[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, 128, 128, 16  0          ['conv2d_53[0][0]',              \n"," mbda)                          )                                 'conv2d_transpose_11[0][0]']    \n","                                                                                                  \n"," conv2d_54 (Conv2D)             (None, 128, 128, 64  9280        ['tf.__operators__.add_1[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," lambda_31 (Lambda)             (None, 128, 128, 64  0           ['conv2d_54[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," re_lu_31 (ReLU)                (None, 128, 128, 64  0           ['lambda_31[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_55 (Conv2D)             (None, 128, 128, 4)  2308        ['re_lu_31[0][0]']               \n","                                                                                                  \n"," softmax (Activation)           (None, 128, 128, 4)  0           ['conv2d_55[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 11,785,408\n","Trainable params: 11,705,840\n","Non-trainable params: 79,568\n","__________________________________________________________________________________________________\n"]}],"source":["'''\n","from tensorflow.keras.utils import get_file\n","import tensorflow as tf\n","edit: keras_utils to tf.keras.utils \n","'''\n","\n","input_shape = (128,128,1)\n","dropout_rate = 0.3 #anh thay cai nay\n","\n","backbone = EfficientNetB4(weights=None, include_top=False, input_shape=input_shape)\n","input = backbone.input\n","start_neurons = 16\n","\n","conv4 = backbone.layers[342].output\n","#print('conv4: ', conv4.shape)\n","conv4 = Lambda(mvn)(conv4)\n","conv4 = ReLU()(conv4)\n","pool4 = MaxPooling2D((2, 2))(conv4) #272\n","#pool4 = _ASPP(pool4,272) #start_neurons * 32\n","convm = Dropout(dropout_rate)(pool4)\n","    \n","# Middle\n","#convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","#print('convm: ', convm.shape)\n","#convm = Lambda(mvn)(convm)\n","#convm = ReLU()(convm)\n","for _ in range(10): \n","  convm = conv_mixer_block(convm, filters=512, kernel_size=5)\n","    \n","deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","uconv4 = concatenate([deconv4, conv4])\n","#print('uconv4: ', uconv4.shape)\n","uconv4 = Dropout(dropout_rate)(uconv4)\n","    \n","uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n","uconv4 = Lambda(mvn)(uconv4)\n","uconv4 = ReLU()(uconv4) \n","    \n","deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","conv3 = backbone.layers[154].output #112\n","#print('conv3: ', conv3.shape)\n","uconv3 = concatenate([deconv3, conv3])\n","#print('uconv3: ', uconv3.shape)    \n","uconv3 = Dropout(dropout_rate)(uconv3)\n","    \n","uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n","uconv3 = Lambda(mvn)(uconv3)\n","uconv3 = ReLU()(uconv3) \n","\n","deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","conv2 = backbone.layers[94].output #192\n","#print('conv2: ', conv2.shape)\n","uconv2 = concatenate([deconv2, conv2])\n","#print('uconv2: ', uconv2.shape)\n","        \n","uconv2 = Dropout(dropout_rate)(uconv2)\n","uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n","uconv2 = Lambda(mvn)(uconv2)\n","uconv2 = ReLU()(uconv2)\n","    \n","deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","conv1 = backbone.layers[30].output #144\n","#print('conv1: ', conv1.shape)\n","uconv1 = concatenate([deconv1, conv1])\n","#print('uconv1: ', uconv1.shape)\n","    \n","uconv1 = Dropout(dropout_rate)(uconv1)\n","uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","#print('uconv1: ', uconv1.shape)\n","uconv1 = Lambda(mvn)(uconv1)\n","uconv1 = ReLU()(uconv1)\n","\n","uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","#print('uconv0: ', uconv0.shape)\n","uconv0 = Lambda(mvn)(uconv0)\n","uconv0 = ReLU()(uconv0) \n","# uconv0 = Dropout(0.1)(uconv0)\n","uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0) \n","#print('uconv0: ', uconv0.shape) \n","\n","# output_layer = Conv2D(NUM_CLASS, (3,3), padding=\"same\", kernel_initializer='he_normal', activation=\"relu\")(uconv0)\n","output_layer = refinement_module(uconv0, start_neurons, 64)\n","output_layer = Conv2D(64, (3,3), padding=\"same\", kernel_initializer='he_normal')(output_layer)\n","output_layer = Lambda(mvn)(output_layer)\n","output_layer = ReLU()(output_layer)\n","output_layer = Conv2D(NUM_CLASS, (3,3), padding=\"same\", kernel_initializer='he_normal')(output_layer)  \n","output_layer = Activation('softmax', name=\"softmax\")(output_layer)\n","\n","model = Model(input, output_layer)\n","model.summary()\n","#0.9190"]},{"cell_type":"markdown","metadata":{"id":"90WG2qodcUKV"},"source":["## Proposed Model with BatchNorm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1668594600033,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"hoFpocwacUKf","outputId":"a0a2b9b3-9274-4b55-c977-e5a6641b1471"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'input_shape = (256,256,3)\\ndropout_rate = 0.5\\n\\nbackbone = EfficientNetB4(weights=\\'imagenet\\', include_top=False, input_shape=input_shape)\\ninput = backbone.input\\nstart_neurons = 16\\n\\nconv4 = backbone.layers[342].output\\nconv4 = BatchNormalization()(conv4)\\nconv4 = ReLU()(conv4)\\npool4 = MaxPooling2D((2, 2))(conv4) #272\\n#pool4 = _ASPP(pool4,272) #start_neurons * 32\\nconvm = Dropout(dropout_rate)(pool4)\\n    \\n# Middle\\n#convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\\n#convm = BatchNormalization()(convm)\\n#convm = ReLU()(convm)\\nfor _ in range(15): \\n  convm = conv_mixer_block(convm, filters=512, kernel_size=5)\\n    \\ndeconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\\nuconv4 = concatenate([deconv4, conv4])\\nuconv4 = Dropout(dropout_rate)(uconv4)\\n    \\nuconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\\nuconv4 = BatchNormalization()(uconv4)\\nuconv4 = ReLU()(uconv4) \\n    \\ndeconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\\nconv3 = backbone.layers[154].output #112\\nuconv3 = concatenate([deconv3, conv3])    \\nuconv3 = Dropout(dropout_rate)(uconv3)\\n    \\nuconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\\nuconv3 = BatchNormalization()(uconv3)\\nuconv3 = ReLU()(uconv3) \\n\\ndeconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\\nconv2 = backbone.layers[94].output #192\\nuconv2 = concatenate([deconv2, conv2])\\n        \\nuconv2 = Dropout(0.1)(uconv2)\\nuconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\\nuconv2 = BatchNormalization()(uconv2)\\nuconv2 = ReLU()(uconv2)\\n    \\ndeconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\\nconv1 = backbone.layers[30].output #144\\nuconv1 = concatenate([deconv1, conv1])\\n    \\nuconv1 = Dropout(0.1)(uconv1)\\nuconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\\nuconv1 = BatchNormalization()(uconv1)\\nuconv1 = ReLU()(uconv1)\\n    \\nuconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \\nuconv0 = Dropout(0.1)(uconv0)\\nuconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\\nuconv0 = BatchNormalization()(uconv0)\\nuconv0 = ReLU()(uconv0) \\n\\nuconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \\nuconv0 = Dropout(dropout_rate/2)(uconv0)\\noutput_layer = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv0)  \\noutput_layer = refinement_module(output_layer, 1, 64)\\noutput_layer = Activation(\\'sigmoid\\')(output_layer)\\n    \\nmodel = Model(input, output_layer)'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","from tensorflow.keras.utils import get_file\n","import tensorflow as tf\n","edit: keras_utils to tf.keras.utils \n","'''\n","\n","'''input_shape = (256,256,3)\n","dropout_rate = 0.5\n","\n","backbone = EfficientNetB4(weights='imagenet', include_top=False, input_shape=input_shape)\n","input = backbone.input\n","start_neurons = 16\n","\n","conv4 = backbone.layers[342].output\n","conv4 = BatchNormalization()(conv4)\n","conv4 = ReLU()(conv4)\n","pool4 = MaxPooling2D((2, 2))(conv4) #272\n","#pool4 = _ASPP(pool4,272) #start_neurons * 32\n","convm = Dropout(dropout_rate)(pool4)\n","    \n","# Middle\n","#convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","#convm = BatchNormalization()(convm)\n","#convm = ReLU()(convm)\n","for _ in range(15): \n","  convm = conv_mixer_block(convm, filters=512, kernel_size=5)\n","    \n","deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","uconv4 = concatenate([deconv4, conv4])\n","uconv4 = Dropout(dropout_rate)(uconv4)\n","    \n","uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n","uconv4 = BatchNormalization()(uconv4)\n","uconv4 = ReLU()(uconv4) \n","    \n","deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","conv3 = backbone.layers[154].output #112\n","uconv3 = concatenate([deconv3, conv3])    \n","uconv3 = Dropout(dropout_rate)(uconv3)\n","    \n","uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n","uconv3 = BatchNormalization()(uconv3)\n","uconv3 = ReLU()(uconv3) \n","\n","deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","conv2 = backbone.layers[94].output #192\n","uconv2 = concatenate([deconv2, conv2])\n","        \n","uconv2 = Dropout(0.1)(uconv2)\n","uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n","uconv2 = BatchNormalization()(uconv2)\n","uconv2 = ReLU()(uconv2)\n","    \n","deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","conv1 = backbone.layers[30].output #144\n","uconv1 = concatenate([deconv1, conv1])\n","    \n","uconv1 = Dropout(0.1)(uconv1)\n","uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","uconv1 = BatchNormalization()(uconv1)\n","uconv1 = ReLU()(uconv1)\n","    \n","uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","uconv0 = Dropout(0.1)(uconv0)\n","uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","uconv0 = BatchNormalization()(uconv0)\n","uconv0 = ReLU()(uconv0) \n","\n","uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \n","uconv0 = Dropout(dropout_rate/2)(uconv0)\n","output_layer = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv0)  \n","output_layer = refinement_module(output_layer, 1, 64)\n","output_layer = Activation('sigmoid')(output_layer)\n","    \n","model = Model(input, output_layer)'''\n","#model.summary()"]},{"cell_type":"markdown","metadata":{"id":"IBQgiYIcyXvG"},"source":["## Salient Attention Unet (based SOD)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1668594600033,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"6Mw7mc_5ybHu","outputId":"ccf62498-0ca0-4dfe-9161-c035e1b53b32"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"input_shape = (256,256,3)\\ninput = Input(shape=input_shape)\\n\\nconv1 = UNetBlock(input, 64)\\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\\n    \\ninput2 = Input(shape=input_shape) #not having saliency map\\n    \\ndwns1 = MaxPooling2D(2,2)(input2)\\nattn1 = SalientAttentionBlock(conv1, dwns1, pool1, 64)\\n\\nconv2 = UNetBlock(attn1, 64)\\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\\n\\ndwns2 = MaxPooling2D(4,4)(input2)\\nattn2 = SalientAttentionBlock(conv2, dwns2, pool2, 64)\\n\\nconv3 = UNetBlock(attn2, 128)\\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\\n\\ndwns3 = MaxPooling2D(8,8)(input2)\\nattn3 = SalientAttentionBlock(conv3, dwns3, pool3, 128)\\n\\nconv4 = UNetBlock(attn3, 128)\\npool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\\n\\ndwns4 = MaxPooling2D(16,16)(input2)\\nattn4 = SalientAttentionBlock(conv4, dwns4, pool4, 128)\\n\\nconv5 = UNetBlock(attn4, 256)\\npool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\\n\\ndwns5 = MaxPooling2D(32,32)(input2)\\nattn5 = SalientAttentionBlock(conv5, dwns5, pool5, 256)\\n\\nconv6 = UNetBlock(attn5, 256)\\npool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\\n\\ndwns6 = MaxPooling2D(64,64)(input2)\\nattn6 = SalientAttentionBlock(conv6, dwns6, pool6, 256)\\n\\nconv7 = UNetBlock(attn6, 512)\\n\\nup8 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv7), attn5], axis=3)\\nconv8 = UNetBlock(up8, 256)\\n\\nup9 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv8), attn4], axis=3)\\nconv9 = UNetBlock(up9, 256)\\n\\nup10 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv9), attn3], axis=3)\\nconv10 = UNetBlock(up10, 128)\\n\\nup11 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv10), attn2], axis=3)\\nconv11 = UNetBlock(up11, 128)\\n\\nup12 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv11), attn1], axis=3)\\nconv12 = UNetBlock(up12, 64)\\n\\nup13 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv12), conv1], axis=3)\\nconv13 = UNetBlock(up13, 64)\\n\\nconv14 = Conv2D(1, (1, 1), activation='sigmoid')(conv13)\\nmodel = Model(inputs = [input, input2], outputs = conv14)\\nmodel.summary()\""]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["'''input_shape = (256,256,3)\n","input = Input(shape=input_shape)\n","\n","conv1 = UNetBlock(input, 64)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    \n","input2 = Input(shape=input_shape) #not having saliency map\n","    \n","dwns1 = MaxPooling2D(2,2)(input2)\n","attn1 = SalientAttentionBlock(conv1, dwns1, pool1, 64)\n","\n","conv2 = UNetBlock(attn1, 64)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","dwns2 = MaxPooling2D(4,4)(input2)\n","attn2 = SalientAttentionBlock(conv2, dwns2, pool2, 64)\n","\n","conv3 = UNetBlock(attn2, 128)\n","pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","dwns3 = MaxPooling2D(8,8)(input2)\n","attn3 = SalientAttentionBlock(conv3, dwns3, pool3, 128)\n","\n","conv4 = UNetBlock(attn3, 128)\n","pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","dwns4 = MaxPooling2D(16,16)(input2)\n","attn4 = SalientAttentionBlock(conv4, dwns4, pool4, 128)\n","\n","conv5 = UNetBlock(attn4, 256)\n","pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n","\n","dwns5 = MaxPooling2D(32,32)(input2)\n","attn5 = SalientAttentionBlock(conv5, dwns5, pool5, 256)\n","\n","conv6 = UNetBlock(attn5, 256)\n","pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n","\n","dwns6 = MaxPooling2D(64,64)(input2)\n","attn6 = SalientAttentionBlock(conv6, dwns6, pool6, 256)\n","\n","conv7 = UNetBlock(attn6, 512)\n","\n","up8 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv7), attn5], axis=3)\n","conv8 = UNetBlock(up8, 256)\n","\n","up9 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv8), attn4], axis=3)\n","conv9 = UNetBlock(up9, 256)\n","\n","up10 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv9), attn3], axis=3)\n","conv10 = UNetBlock(up10, 128)\n","\n","up11 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv10), attn2], axis=3)\n","conv11 = UNetBlock(up11, 128)\n","\n","up12 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv11), attn1], axis=3)\n","conv12 = UNetBlock(up12, 64)\n","\n","up13 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv12), conv1], axis=3)\n","conv13 = UNetBlock(up13, 64)\n","\n","conv14 = Conv2D(1, (1, 1), activation='sigmoid')(conv13)\n","model = Model(inputs = [input, input2], outputs = conv14)\n","model.summary()'''"]},{"cell_type":"markdown","metadata":{"id":"NlgBqYz83sqZ"},"source":["## Seg-UNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9MmIu2lug_lf"},"outputs":[],"source":["# input_shape = (256,256,3)\n","# encoder = encoderSegnet(input_s = input_shape)\n","# skip_connect=[encoder.get_layer(i).output for i in list_skip]\n","# num_filters = [512,256, 128, 64]\n","\n","# o = encoder.output\n","# o = _ASPP(o,128)\n","  \n","# for i, f in enumerate(num_filters):\n","#   o = decoder_block(f,skip=skip_connect[i])(o)\n","  \n","# o = Conv2D(1,(3, 3), padding='same', kernel_initializer='he_normal')(o)\n","# # yn = Activation('softmax')(o[...,:-1])\n","# # bn = o[...,-1:]\n","# # output = Concatenate()([yn,bn])\n","# #if out_channels > 1 : \n","#   #output = Activation('softmax', name = 'softmax')(o)\n","# #else :\n","# output = Activation('sigmoid', name = 'sigmoid')(o)\n","# model = Model(encoder.input,output)\n","# model.summary()\n","#0.9163"]},{"cell_type":"markdown","metadata":{"id":"52QrHPPLGPGw"},"source":["## EfficientUNet B0-B7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eVo0GwaNGR7j"},"outputs":[],"source":["#%run /content/drive/MyDrive/brain_mri_segmentation/EfficientUNet.ipynb #0.9100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4wEsarzNLH-"},"outputs":[],"source":["#model4 = get_efficient_unet_b2((256,256,3), pretrained=True, block_type='transpose', concat_input=True,out_channels=1)\n","#model4.summary()"]},{"cell_type":"markdown","metadata":{"id":"gzAyEyor3Xci"},"source":["## ResUNet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":123,"status":"ok","timestamp":1668594600035,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"hw3ZZVp03WZL","outputId":"23b88442-9177-42b9-c8b0-42314b97911c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"f = [16, 32, 64, 128, 256]\\ninput_shape = (256,256,3)\\ninputs = Input(shape=input_shape, dtype='float', name='data')\\n\\n## ENCODER \\ne0 = inputs\\ne1 = stem(e0, f[0])\\ne2 = _residual_block(e1, f[1], strides=2)\\ne3 = _residual_block(e2, f[2], strides=2)\\ne4 = _residual_block(e3, f[3], strides=2)\\ne5 = _residual_block(e4, f[4], strides=2)\\n\\n# BRIDGE\\nb0 = _conv_block(e5, f[4], strides=1)\\nb1 = _conv_block(b0, f[4], strides=1)\\n\\n# DECODER \\nu1 = upsample_concat_block(b1, e4)\\nd1 = _residual_block(u1, f[4])\\n\\nu2 = upsample_concat_block(d1, e3)\\nd2 = _residual_block(u2, f[3])\\n\\nu3 = upsample_concat_block(d2, e2)\\nd3 = _residual_block(u3, f[2])\\n\\nu4 = upsample_concat_block(d3, e1)\\nd4 = _residual_block(u4, f[1])\\n\\noutputs = Conv2D(1, (1, 1), padding='same', activation='sigmoid')(d4)\\nmodel2 = Model(inputs, outputs)\\n\\nmodel2.summary()\""]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["'''f = [16, 32, 64, 128, 256]\n","input_shape = (256,256,3)\n","inputs = Input(shape=input_shape, dtype='float', name='data')\n","\n","## ENCODER \n","e0 = inputs\n","e1 = stem(e0, f[0])\n","e2 = _residual_block(e1, f[1], strides=2)\n","e3 = _residual_block(e2, f[2], strides=2)\n","e4 = _residual_block(e3, f[3], strides=2)\n","e5 = _residual_block(e4, f[4], strides=2)\n","\n","# BRIDGE\n","b0 = _conv_block(e5, f[4], strides=1)\n","b1 = _conv_block(b0, f[4], strides=1)\n","\n","# DECODER \n","u1 = upsample_concat_block(b1, e4)\n","d1 = _residual_block(u1, f[4])\n","\n","u2 = upsample_concat_block(d1, e3)\n","d2 = _residual_block(u2, f[3])\n","\n","u3 = upsample_concat_block(d2, e2)\n","d3 = _residual_block(u3, f[2])\n","\n","u4 = upsample_concat_block(d3, e1)\n","d4 = _residual_block(u4, f[1])\n","\n","outputs = Conv2D(1, (1, 1), padding='same', activation='sigmoid')(d4)\n","model2 = Model(inputs, outputs)\n","\n","model2.summary()'''"]},{"cell_type":"markdown","metadata":{"id":"tPiu7yXRoGl9"},"source":["## PraNet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":123,"status":"ok","timestamp":1668594600036,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"MOWiUNFVoGmB","outputId":"a4513db7-19d3-4d5c-cbc3-d756f9125e72"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'input_shape = (256,256,3)\\ninput = Input(shape=input_shape)\\n\\nfe_backbone = FE_backbone(model_architecture=\\'resnet50\\', inshape=input_shape, is_trainable=True)\\nbackbone_feature_extractor = fe_backbone.get_fe_backbone()\\nfeatures = backbone_feature_extractor(input)\\n\\n# RFB\\nfeat2_rfb = RFB(filters=32, name=\"rfb_2\")(features[1])  # => level_2(batch,h/8,w/8,32)\\nfeat3_rfb = RFB(filters=32, name=\"rfb_3\")(features[2])  # => level_3(batch,h/16,w/16,32)\\nfeat4_rfb = RFB(filters=32, name=\"rfb_4\")(features[3])  # => level_4(batch,h/32,w/32,32)\\n\\n# Partial decoder \\nsg = PartialDecoder(filters=32, name=\"partial_decoder\")(feat4_rfb, feat3_rfb, feat2_rfb) # => (batch,h/8,w/8,1) Global saliency map\\nlateral_out_sg = preprocessing.Resizing(256, 256, name=\\'salient_out_5\\')(sg) # resize (batch,h/8,w/8,1) => (batch,h,w,1) #out 5\\n\\n# reverse attention branch 4 \\nresized_sg = preprocessing.Resizing(256//32, 256//32, name=\"resize4\")(sg) # resize (batch, h/8,w/8,1) => (batch, h/32,w/32,1)\\ns4 = ReverseAttention(filters=256, kernel_size=(5, 5),branch=\\'gsmap\\', name=\"reverse_attention_br4\")(features[3],resized_sg)\\nlateral_out_s4 = preprocessing.Resizing(256, 256, name=\"salient_out_4\")(s4) # resize (batch,h/32,w/32,1) => (batch,h,w,1) #out 4\\n\\n# reverse attention branch 3\\nresized_s4 = preprocessing.Resizing(256//16, 256//16, name=\"resize3\")(s4) # resize (batch, h/32,w/32,1) => (batch, h/16,w/16,1)\\ns3 = ReverseAttention(filters=64, name=\"reverse_attention_br3\")(features[2],resized_s4)\\nlateral_out_s3 = preprocessing.Resizing(256, 256, name=\"salient_out_3\")(s3) # resize (batch,h/16,w/16,1) => (batch,h,w,1) #out 3\\n\\n# reverse attention branch 2\\nresized_s3 = preprocessing.Resizing(256//8, 256//8, name=\"resize2\")(s3)# resize (batch, h/16,w/16,1) => (batch, h/8,w/8,1)\\ns2 = ReverseAttention(filters=64, name=\"reverse_attention_br2\")(features[1],resized_s3)\\nlateral_out_s2 = preprocessing.Resizing(256, 256, name=\"final_salient_out_2\")(s2)# resize (batch,h/8,w/8,1) => (batch,h,w,1) #out 2\\nlateral_out_s2 = Activation(\\'sigmoid\\')(lateral_out_s2)\\n\\nmodel1 = Model(inputs = input, outputs = lateral_out_s2)\\nmodel1.summary()'"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["'''input_shape = (256,256,3)\n","input = Input(shape=input_shape)\n","\n","fe_backbone = FE_backbone(model_architecture='resnet50', inshape=input_shape, is_trainable=True)\n","backbone_feature_extractor = fe_backbone.get_fe_backbone()\n","features = backbone_feature_extractor(input)\n","\n","# RFB\n","feat2_rfb = RFB(filters=32, name=\"rfb_2\")(features[1])  # => level_2(batch,h/8,w/8,32)\n","feat3_rfb = RFB(filters=32, name=\"rfb_3\")(features[2])  # => level_3(batch,h/16,w/16,32)\n","feat4_rfb = RFB(filters=32, name=\"rfb_4\")(features[3])  # => level_4(batch,h/32,w/32,32)\n","\n","# Partial decoder \n","sg = PartialDecoder(filters=32, name=\"partial_decoder\")(feat4_rfb, feat3_rfb, feat2_rfb) # => (batch,h/8,w/8,1) Global saliency map\n","lateral_out_sg = preprocessing.Resizing(256, 256, name='salient_out_5')(sg) # resize (batch,h/8,w/8,1) => (batch,h,w,1) #out 5\n","\n","# reverse attention branch 4 \n","resized_sg = preprocessing.Resizing(256//32, 256//32, name=\"resize4\")(sg) # resize (batch, h/8,w/8,1) => (batch, h/32,w/32,1)\n","s4 = ReverseAttention(filters=256, kernel_size=(5, 5),branch='gsmap', name=\"reverse_attention_br4\")(features[3],resized_sg)\n","lateral_out_s4 = preprocessing.Resizing(256, 256, name=\"salient_out_4\")(s4) # resize (batch,h/32,w/32,1) => (batch,h,w,1) #out 4\n","\n","# reverse attention branch 3\n","resized_s4 = preprocessing.Resizing(256//16, 256//16, name=\"resize3\")(s4) # resize (batch, h/32,w/32,1) => (batch, h/16,w/16,1)\n","s3 = ReverseAttention(filters=64, name=\"reverse_attention_br3\")(features[2],resized_s4)\n","lateral_out_s3 = preprocessing.Resizing(256, 256, name=\"salient_out_3\")(s3) # resize (batch,h/16,w/16,1) => (batch,h,w,1) #out 3\n","\n","# reverse attention branch 2\n","resized_s3 = preprocessing.Resizing(256//8, 256//8, name=\"resize2\")(s3)# resize (batch, h/16,w/16,1) => (batch, h/8,w/8,1)\n","s2 = ReverseAttention(filters=64, name=\"reverse_attention_br2\")(features[1],resized_s3)\n","lateral_out_s2 = preprocessing.Resizing(256, 256, name=\"final_salient_out_2\")(s2)# resize (batch,h/8,w/8,1) => (batch,h,w,1) #out 2\n","lateral_out_s2 = Activation('sigmoid')(lateral_out_s2)\n","\n","model1 = Model(inputs = input, outputs = lateral_out_s2)\n","model1.summary()'''\n","#0.8916"]},{"cell_type":"markdown","metadata":{"id":"KyJ2U-32eULg"},"source":["## DeepLab V3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":120,"status":"ok","timestamp":1668594600036,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"AcbFJBVBeyIx","outputId":"7581043e-888e-45f8-870e-f31a2ae3e204"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'input_shape = (256,256,3)\\ninput = Input(shape=input_shape)\\nresnet50 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_tensor=input)\\nx = resnet50.get_layer(\"conv4_block6_2_relu\").output\\nx = DilatedSpatialPyramidPooling(x)\\n\\ninput_a = layers.UpSampling2D(size=(256 // 4 // x.shape[1], 256 // 4 // x.shape[2]),interpolation=\"bilinear\",)(x)\\ninput_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\\ninput_b = _convolution_block(input_b, num_filters=48, kernel_size=1)\\n\\nx = layers.Concatenate(axis=-1)([input_a, input_b])\\nx = _convolution_block(x)\\nx = _convolution_block(x)\\nx = layers.UpSampling2D(size=(256 // x.shape[1], 256 // x.shape[2]),interpolation=\"bilinear\",)(x)\\nmodel_output = layers.Conv2D(1, kernel_size=(1, 1), padding=\"same\")(x)\\nmodel = Model(inputs=input, outputs=model_output)\\nmodel = Deeplabv3(input_shape=(256,256,3),backbone=\"mobilenetv2\", classes=1)\\nmodel.summary()'"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["'''input_shape = (256,256,3)\n","input = Input(shape=input_shape)\n","resnet50 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_tensor=input)\n","x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n","x = DilatedSpatialPyramidPooling(x)\n","\n","input_a = layers.UpSampling2D(size=(256 // 4 // x.shape[1], 256 // 4 // x.shape[2]),interpolation=\"bilinear\",)(x)\n","input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n","input_b = _convolution_block(input_b, num_filters=48, kernel_size=1)\n","\n","x = layers.Concatenate(axis=-1)([input_a, input_b])\n","x = _convolution_block(x)\n","x = _convolution_block(x)\n","x = layers.UpSampling2D(size=(256 // x.shape[1], 256 // x.shape[2]),interpolation=\"bilinear\",)(x)\n","model_output = layers.Conv2D(1, kernel_size=(1, 1), padding=\"same\")(x)\n","model = Model(inputs=input, outputs=model_output)\n","model = Deeplabv3(input_shape=(256,256,3),backbone=\"mobilenetv2\", classes=1)\n","model.summary()'''"]},{"cell_type":"markdown","metadata":{"id":"PXubga4p9D5g"},"source":["## Swin UNet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":119,"status":"ok","timestamp":1668594600037,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"5k7DhwUF-95z","outputId":"1fa6aef1-c038-4ac5-d0ce-6c28f6263c95"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'filter_num_begin = 32     # number of channels in the first downsampling block; it is also the number of embedded dimensions\\ndepth = 4                  # the depth of SwinUNET; depth=4 means three down/upsampling levels and a bottom level \\nstack_num_down = 2         # number of Swin Transformers per downsampling level\\nstack_num_up = 2           # number of Swin Transformers per upsampling level\\npatch_size = (4, 4)        # Extract 2-by-2 patches from the input image. Height and width of the patch must be equal.\\nnum_heads = [4, 8, 8, 8]   # number of attention heads per down/upsampling level\\nwindow_size = [4, 2, 2, 2] # the size of attention window per down/upsampling level\\nnum_mlp = 512              # number of MLP nodes within the Transformer\\nshift_window=True          # Apply window shifting, i.e., Swin-MSA\\n\\ndef swin_unet_2d_base(input_tensor, filter_num_begin, depth, stack_num_down, stack_num_up, \\n                      patch_size, num_heads, window_size, num_mlp, shift_window=True, name=\\'swin_unet\\'):\\n    #The base of SwinUNET.\\n    # Compute number be patches to be embeded\\n    input_size = input_tensor.shape.as_list()[1:]\\n    num_patch_x = input_size[0]//patch_size[0]\\n    num_patch_y = input_size[1]//patch_size[1]\\n    \\n    # Number of Embedded dimensions\\n    embed_dim = filter_num_begin\\n    \\n    depth_ = depth\\n    \\n    X_skip = []\\n\\n    X = input_tensor\\n    \\n    # Patch extraction\\n    X = transformer_layers.patch_extract(patch_size)(X)\\n\\n    # Embed patches to tokens\\n    X = transformer_layers.patch_embedding(num_patch_x*num_patch_y, embed_dim)(X)\\n    \\n    # The first Swin Transformer stack\\n    X = swin_transformer_stack(X, stack_num=stack_num_down, \\n                               embed_dim=embed_dim, num_patch=(num_patch_x, num_patch_y), \\n                               num_heads=num_heads[0], window_size=window_size[0], num_mlp=num_mlp, \\n                               shift_window=shift_window, name=\\'{}_swin_down0\\'.format(name))\\n    X_skip.append(X)\\n    \\n    # Downsampling blocks\\n    for i in range(depth_-1):\\n        \\n        # Patch merging\\n        X = transformer_layers.patch_merging((num_patch_x, num_patch_y), embed_dim=embed_dim, name=\\'down{}\\'.format(i))(X)\\n        \\n        # update token shape info\\n        embed_dim = embed_dim*2\\n        num_patch_x = num_patch_x//2\\n        num_patch_y = num_patch_y//2\\n        \\n        # Swin Transformer stacks\\n        X = swin_transformer_stack(X, stack_num=stack_num_down, \\n                                   embed_dim=embed_dim, num_patch=(num_patch_x, num_patch_y), \\n                                   num_heads=num_heads[i+1], window_size=window_size[i+1], num_mlp=num_mlp, \\n                                   shift_window=shift_window, name=\\'{}_swin_down{}\\'.format(name, i+1))\\n        \\n        # Store tensors for concat\\n        X_skip.append(X)\\n        \\n    # reverse indexing encoded tensors and hyperparams\\n    X_skip = X_skip[::-1]\\n    num_heads = num_heads[::-1]\\n    window_size = window_size[::-1]\\n    \\n    # upsampling begins at the deepest available tensor\\n    X = X_skip[0]\\n    \\n    # other tensors are preserved for concatenation\\n    X_decode = X_skip[1:]\\n    \\n    depth_decode = len(X_decode)\\n    \\n    for i in range(depth_decode):\\n        \\n        # Patch expanding\\n        X = transformer_layers.patch_expanding(num_patch=(num_patch_x, num_patch_y), \\n                                               embed_dim=embed_dim, upsample_rate=2, return_vector=True)(X)\\n        \\n\\n        # update token shape info\\n        embed_dim = embed_dim//2\\n        num_patch_x = num_patch_x*2\\n        num_patch_y = num_patch_y*2\\n        \\n        # Concatenation and linear projection\\n        X = concatenate([X, X_decode[i]], axis=-1, name=\\'{}_concat_{}\\'.format(name, i))\\n        X = Dense(embed_dim, use_bias=False, name=\\'{}_concat_linear_proj_{}\\'.format(name, i))(X)\\n        \\n        # Swin Transformer stacks\\n        X = swin_transformer_stack(X, stack_num=stack_num_up, \\n                           embed_dim=embed_dim, num_patch=(num_patch_x, num_patch_y), \\n                           num_heads=num_heads[i], window_size=window_size[i], num_mlp=num_mlp, \\n                           shift_window=shift_window, name=\\'{}_swin_up{}\\'.format(name, i))\\n        \\n    # The last expanding layer; it produces full-size feature maps based on the patch size\\n    # !!! <--- \"patch_size[0]\" is used; it assumes patch_size = (size, size)\\n    X = transformer_layers.patch_expanding(num_patch=(num_patch_x, num_patch_y), \\n                                               embed_dim=embed_dim, upsample_rate=patch_size[0], return_vector=False)(X)\\n    print(X.shape)\\n    print(X_skip)\\n    \\n    return X, X_skip\\n\\ninput_size = (256,256,3)\\nIN = Input(input_size)\\n\\nX, X_skip = swin_unet_2d_base(IN, filter_num_begin, depth, stack_num_down, stack_num_up, \\n                  patch_size, num_heads, window_size, num_mlp, shift_window=shift_window, name=\\'swin_unet\\')\\n\\nn_labels = 1\\nOUT = Conv2D(n_labels, kernel_size=1, use_bias=False, activation=\\'sigmoid\\')(X)\\n\\n# Model configuration\\nmodel = Model(inputs=[IN,], outputs=[OUT,])\\n#model = models.swin_unet_2d(input_size=(256,256,3), filter_num_begin=filter_num_begin, n_labels=1, depth=depth, stack_num_down=stack_num_down, stack_num_up=stack_num_up, patch_size=patch_size, num_heads=num_heads, window_size=window_size, num_mlp=num_mlp, output_activation=\\'Sigmoid\\', shift_window=True, name=\\'swin_unet\\')\\nmodel.summary()'"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["'''filter_num_begin = 32     # number of channels in the first downsampling block; it is also the number of embedded dimensions\n","depth = 4                  # the depth of SwinUNET; depth=4 means three down/upsampling levels and a bottom level \n","stack_num_down = 2         # number of Swin Transformers per downsampling level\n","stack_num_up = 2           # number of Swin Transformers per upsampling level\n","patch_size = (4, 4)        # Extract 2-by-2 patches from the input image. Height and width of the patch must be equal.\n","num_heads = [4, 8, 8, 8]   # number of attention heads per down/upsampling level\n","window_size = [4, 2, 2, 2] # the size of attention window per down/upsampling level\n","num_mlp = 512              # number of MLP nodes within the Transformer\n","shift_window=True          # Apply window shifting, i.e., Swin-MSA\n","\n","def swin_unet_2d_base(input_tensor, filter_num_begin, depth, stack_num_down, stack_num_up, \n","                      patch_size, num_heads, window_size, num_mlp, shift_window=True, name='swin_unet'):\n","    #The base of SwinUNET.\n","    # Compute number be patches to be embeded\n","    input_size = input_tensor.shape.as_list()[1:]\n","    num_patch_x = input_size[0]//patch_size[0]\n","    num_patch_y = input_size[1]//patch_size[1]\n","    \n","    # Number of Embedded dimensions\n","    embed_dim = filter_num_begin\n","    \n","    depth_ = depth\n","    \n","    X_skip = []\n","\n","    X = input_tensor\n","    \n","    # Patch extraction\n","    X = transformer_layers.patch_extract(patch_size)(X)\n","\n","    # Embed patches to tokens\n","    X = transformer_layers.patch_embedding(num_patch_x*num_patch_y, embed_dim)(X)\n","    \n","    # The first Swin Transformer stack\n","    X = swin_transformer_stack(X, stack_num=stack_num_down, \n","                               embed_dim=embed_dim, num_patch=(num_patch_x, num_patch_y), \n","                               num_heads=num_heads[0], window_size=window_size[0], num_mlp=num_mlp, \n","                               shift_window=shift_window, name='{}_swin_down0'.format(name))\n","    X_skip.append(X)\n","    \n","    # Downsampling blocks\n","    for i in range(depth_-1):\n","        \n","        # Patch merging\n","        X = transformer_layers.patch_merging((num_patch_x, num_patch_y), embed_dim=embed_dim, name='down{}'.format(i))(X)\n","        \n","        # update token shape info\n","        embed_dim = embed_dim*2\n","        num_patch_x = num_patch_x//2\n","        num_patch_y = num_patch_y//2\n","        \n","        # Swin Transformer stacks\n","        X = swin_transformer_stack(X, stack_num=stack_num_down, \n","                                   embed_dim=embed_dim, num_patch=(num_patch_x, num_patch_y), \n","                                   num_heads=num_heads[i+1], window_size=window_size[i+1], num_mlp=num_mlp, \n","                                   shift_window=shift_window, name='{}_swin_down{}'.format(name, i+1))\n","        \n","        # Store tensors for concat\n","        X_skip.append(X)\n","        \n","    # reverse indexing encoded tensors and hyperparams\n","    X_skip = X_skip[::-1]\n","    num_heads = num_heads[::-1]\n","    window_size = window_size[::-1]\n","    \n","    # upsampling begins at the deepest available tensor\n","    X = X_skip[0]\n","    \n","    # other tensors are preserved for concatenation\n","    X_decode = X_skip[1:]\n","    \n","    depth_decode = len(X_decode)\n","    \n","    for i in range(depth_decode):\n","        \n","        # Patch expanding\n","        X = transformer_layers.patch_expanding(num_patch=(num_patch_x, num_patch_y), \n","                                               embed_dim=embed_dim, upsample_rate=2, return_vector=True)(X)\n","        \n","\n","        # update token shape info\n","        embed_dim = embed_dim//2\n","        num_patch_x = num_patch_x*2\n","        num_patch_y = num_patch_y*2\n","        \n","        # Concatenation and linear projection\n","        X = concatenate([X, X_decode[i]], axis=-1, name='{}_concat_{}'.format(name, i))\n","        X = Dense(embed_dim, use_bias=False, name='{}_concat_linear_proj_{}'.format(name, i))(X)\n","        \n","        # Swin Transformer stacks\n","        X = swin_transformer_stack(X, stack_num=stack_num_up, \n","                           embed_dim=embed_dim, num_patch=(num_patch_x, num_patch_y), \n","                           num_heads=num_heads[i], window_size=window_size[i], num_mlp=num_mlp, \n","                           shift_window=shift_window, name='{}_swin_up{}'.format(name, i))\n","        \n","    # The last expanding layer; it produces full-size feature maps based on the patch size\n","    # !!! <--- \"patch_size[0]\" is used; it assumes patch_size = (size, size)\n","    X = transformer_layers.patch_expanding(num_patch=(num_patch_x, num_patch_y), \n","                                               embed_dim=embed_dim, upsample_rate=patch_size[0], return_vector=False)(X)\n","    print(X.shape)\n","    print(X_skip)\n","    \n","    return X, X_skip\n","\n","input_size = (256,256,3)\n","IN = Input(input_size)\n","\n","X, X_skip = swin_unet_2d_base(IN, filter_num_begin, depth, stack_num_down, stack_num_up, \n","                  patch_size, num_heads, window_size, num_mlp, shift_window=shift_window, name='swin_unet')\n","\n","n_labels = 1\n","OUT = Conv2D(n_labels, kernel_size=1, use_bias=False, activation='sigmoid')(X)\n","\n","# Model configuration\n","model = Model(inputs=[IN,], outputs=[OUT,])\n","#model = models.swin_unet_2d(input_size=(256,256,3), filter_num_begin=filter_num_begin, n_labels=1, depth=depth, stack_num_down=stack_num_down, stack_num_up=stack_num_up, patch_size=patch_size, num_heads=num_heads, window_size=window_size, num_mlp=num_mlp, output_activation='Sigmoid', shift_window=True, name='swin_unet')\n","model.summary()'''"]},{"cell_type":"markdown","metadata":{"id":"QsG4QWY3cchZ"},"source":["## TransU-Net"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1668594600037,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"wcHHsNDbcfjj","outputId":"b2687869-1eb5-4a65-fb01-c5f7e1048944"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"model = models.transunet_2d(input_size=(256,256,3), filter_num=[32, 64, 128, 256], n_labels=1, stack_num_down=2, stack_num_up=2,\\n                 embed_dim=768, num_mlp = 3072, num_heads=12, num_transformer=12,\\n                 activation='ReLU', mlp_activation='GELU', output_activation='Softmax', batch_norm=False, pool=True, unpool=True, \\n                 backbone=None, weights='imagenet', freeze_backbone=True, freeze_batch_norm=True, name='transunet')\\nmodel.summary()\""]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["'''model = models.transunet_2d(input_size=(256,256,3), filter_num=[32, 64, 128, 256], n_labels=1, stack_num_down=2, stack_num_up=2,\n","                 embed_dim=768, num_mlp = 3072, num_heads=12, num_transformer=12,\n","                 activation='ReLU', mlp_activation='GELU', output_activation='Softmax', batch_norm=False, pool=True, unpool=True, \n","                 backbone=None, weights='imagenet', freeze_backbone=True, freeze_batch_norm=True, name='transunet')\n","model.summary()'''"]},{"cell_type":"markdown","metadata":{"id":"_EQP0AkXi0Gi"},"source":["## U-Net++"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1369,"status":"ok","timestamp":1669528075620,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"-EfiEYyRiyrb","outputId":"2b78a12a-3407-4ef8-9400-6750abeb53ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," data (InputLayer)              [(None, 256, 256, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 256, 256, 3)  12         ['data[0][0]']                   \n"," alization)                                                                                       \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 256, 256, 8)  224         ['batch_normalization[0][0]']    \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 256, 256, 8)  32         ['conv2d[0][0]']                 \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation (Activation)        (None, 256, 256, 8)  0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 256, 256, 8)  584         ['activation[0][0]']             \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 256, 256, 8)  32         ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_1 (Activation)      (None, 256, 256, 8)  0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 128, 128, 8)  0           ['activation_1[0][0]']           \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 128, 128, 16  1168        ['max_pooling2d[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 128, 128, 16  64         ['conv2d_2[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_2 (Activation)      (None, 128, 128, 16  0           ['batch_normalization_3[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 128, 128, 16  2320        ['activation_2[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 128, 128, 16  64         ['conv2d_3[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_3 (Activation)      (None, 128, 128, 16  0           ['batch_normalization_4[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)  0           ['activation_3[0][0]']           \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 64, 64, 32)   4640        ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 64, 64, 32)   9248        ['activation_4[0][0]']           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_5 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)  0           ['activation_5[0][0]']           \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 32, 32, 64)   18496       ['max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_6 (Activation)      (None, 32, 32, 64)   0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 32, 32, 64)   36928       ['activation_6[0][0]']           \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_7[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_7 (Activation)      (None, 32, 32, 64)   0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)  0           ['activation_7[0][0]']           \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 16, 16, 128)  73856       ['max_pooling2d_3[0][0]']        \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_8[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_8 (Activation)      (None, 16, 16, 128)  0           ['batch_normalization_9[0][0]']  \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 16, 16, 128)  147584      ['activation_8[0][0]']           \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 16, 16, 128)  512        ['conv2d_9[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_9 (Activation)      (None, 16, 16, 128)  0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," dropout (Dropout)              (None, 16, 16, 128)  0           ['activation_9[0][0]']           \n","                                                                                                  \n"," max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 128)   0           ['dropout[0][0]']                \n","                                                                                                  \n"," conv_middle (Conv2D)           (None, 8, 8, 256)    295168      ['max_pooling2d_4[0][0]']        \n","                                                                                                  \n"," re_lu (ReLU)                   (None, 8, 8, 256)    0           ['conv_middle[0][0]']            \n","                                                                                                  \n"," conv2d_transpose (Conv2DTransp  (None, 16, 16, 128)  295040     ['re_lu[0][0]']                  \n"," ose)                                                                                             \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_transpose[0][0]',       \n","                                                                  'activation_9[0][0]']           \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 16, 16, 256)  0           ['concatenate[0][0]']            \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 16, 16, 128)  295040      ['dropout_1[0][0]']              \n","                                                                                                  \n"," re_lu_1 (ReLU)                 (None, 16, 16, 128)  0           ['conv2d_10[0][0]']              \n","                                                                                                  \n"," conv2d_transpose_4 (Conv2DTran  (None, 32, 32, 64)  73792       ['re_lu_1[0][0]']                \n"," spose)                                                                                           \n","                                                                                                  \n"," conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 128)  147584     ['conv2d_transpose[0][0]']       \n"," spose)                                                                                           \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 32, 32, 256)  0           ['conv2d_transpose_4[0][0]',     \n","                                                                  'conv2d_transpose_1[0][0]',     \n","                                                                  'activation_7[0][0]']           \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 32, 32, 256)  0           ['concatenate_1[0][0]']          \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 32, 32, 64)   147520      ['dropout_2[0][0]']              \n","                                                                                                  \n"," re_lu_2 (ReLU)                 (None, 32, 32, 64)   0           ['conv2d_11[0][0]']              \n","                                                                                                  \n"," conv2d_transpose_7 (Conv2DTran  (None, 64, 64, 32)  18464       ['re_lu_2[0][0]']                \n"," spose)                                                                                           \n","                                                                                                  \n"," conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 64)  36928       ['conv2d_transpose_4[0][0]']     \n"," spose)                                                                                           \n","                                                                                                  \n"," conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 128)  147584     ['conv2d_transpose_1[0][0]']     \n"," spose)                                                                                           \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_transpose_7[0][0]',     \n","                                                                  'conv2d_transpose_5[0][0]',     \n","                                                                  'conv2d_transpose_2[0][0]',     \n","                                                                  'activation_5[0][0]']           \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 64, 64, 256)  0           ['concatenate_2[0][0]']          \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 64, 64, 32)   73760       ['dropout_3[0][0]']              \n","                                                                                                  \n"," re_lu_3 (ReLU)                 (None, 64, 64, 32)   0           ['conv2d_12[0][0]']              \n","                                                                                                  \n"," conv2d_transpose_9 (Conv2DTran  (None, 128, 128, 16  4624       ['re_lu_3[0][0]']                \n"," spose)                         )                                                                 \n","                                                                                                  \n"," conv2d_transpose_8 (Conv2DTran  (None, 128, 128, 32  9248       ['conv2d_transpose_7[0][0]']     \n"," spose)                         )                                                                 \n","                                                                                                  \n"," conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 64  36928      ['conv2d_transpose_5[0][0]']     \n"," spose)                         )                                                                 \n","                                                                                                  \n"," conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 12  147584     ['conv2d_transpose_2[0][0]']     \n"," spose)                         8)                                                                \n","                                                                                                  \n"," concatenate_3 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_9[0][0]',     \n","                                6)                                'conv2d_transpose_8[0][0]',     \n","                                                                  'conv2d_transpose_6[0][0]',     \n","                                                                  'conv2d_transpose_3[0][0]',     \n","                                                                  'activation_3[0][0]']           \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 128, 128, 25  0           ['concatenate_3[0][0]']          \n","                                6)                                                                \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 128, 128, 16  36880       ['dropout_4[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," re_lu_4 (ReLU)                 (None, 128, 128, 16  0           ['conv2d_13[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_10 (Conv2DTra  (None, 256, 256, 8)  1160       ['re_lu_4[0][0]']                \n"," nspose)                                                                                          \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 256, 256, 8)  0           ['conv2d_transpose_10[0][0]']    \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 256, 256, 8)  584         ['dropout_5[0][0]']              \n","                                                                                                  \n"," re_lu_5 (ReLU)                 (None, 256, 256, 8)  0           ['conv2d_14[0][0]']              \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 256, 256, 8)  0           ['re_lu_5[0][0]']                \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 256, 256, 1)  9           ['dropout_6[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,064,941\n","Trainable params: 2,063,943\n","Non-trainable params: 998\n","__________________________________________________________________________________________________\n"]}],"source":["# start_neurons = 8\n","\n","# input_shape = (256,256,3)\n","# data = Input(shape=input_shape, dtype='float', name='data')\n","\n","# mvn0 = BatchNormalization()(data)\n","# conv0 = Conv2D(8, 3, padding = 'same')(mvn0)\n","# conv0 = BatchNormalization()(conv0)\n","# conv0 = Activation('relu')(conv0)\n","# conv0 = Conv2D(8, 3,  padding = 'same')(conv0)\n","# conv0 = BatchNormalization()(conv0)\n","# conv0 = Activation('relu')(conv0)\n","# pool0 = MaxPooling2D(pool_size=(2, 2))(conv0)\n","\n","# conv1 = Conv2D(16, 3,  padding = 'same')(pool0)\n","# conv1 = BatchNormalization()(conv1)\n","# conv1 = Activation('relu')(conv1)\n","# conv1 = Conv2D(16, 3,  padding = 'same')(conv1)\n","# conv1 = BatchNormalization()(conv1)\n","# conv1 = Activation('relu')(conv1)\n","# pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","# conv2 = Conv2D(32, 3,  padding = 'same')(pool1)\n","# conv2 = BatchNormalization()(conv2)\n","# conv2 = Activation('relu')(conv2)\n","# conv2 = Conv2D(32, 3,  padding = 'same')(conv2)\n","# conv2 = BatchNormalization()(conv2)\n","# conv2 = Activation('relu')(conv2)\n","# pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    \n","# conv3 = Conv2D(64, 3,  padding = 'same')(pool2)\n","# conv3 = BatchNormalization()(conv3)\n","# conv3 = Activation('relu')(conv3)\n","# conv3 = Conv2D(64, 3,  padding = 'same')(conv3)\n","# conv3 = BatchNormalization()(conv3)\n","# conv3 = Activation('relu')(conv3)\n","# pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","# conv4 = Conv2D(128, 3,  padding = 'same')(pool3)\n","# conv4 = BatchNormalization()(conv4)\n","# conv4 = Activation('relu')(conv4)\n","# conv4 = Conv2D(128, 3,  padding = 'same')(conv4)\n","# conv4 = BatchNormalization()(conv4)\n","# conv4 = Activation('relu')(conv4)\n","# drop4 = Dropout(0.5)(conv4)\n","# pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","    \n","# # Middle\n","# convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\",name='conv_middle')(pool4)\n","# convm = ReLU()(convm)\n","    \n","# deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","# deconv4_up1 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4)\n","# deconv4_up2 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4_up1)\n","# deconv4_up3 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4_up2)\n","# uconv4 = concatenate([deconv4, conv4])\n","# uconv4 = Dropout(0.5)(uconv4) \n","    \n","# uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n","# uconv4 = ReLU()(uconv4)  #conv1_2\n","    \n","# deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","# deconv3_up1 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(deconv3)\n","# deconv3_up2 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(deconv3_up1)\n","# uconv3 = concatenate([deconv3,deconv4_up1, conv3])    \n","# uconv3 = Dropout(0.5)(uconv3)\n","    \n","# uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n","# uconv3 = ReLU()(uconv3)\n","# deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","# deconv2_up1 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(deconv2)\n","# uconv2 = concatenate([deconv2,deconv3_up1,deconv4_up2, conv2])\n","        \n","# uconv2 = Dropout(0.2)(uconv2)\n","# uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n","# uconv2 = ReLU()(uconv2)\n","    \n","# deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","# uconv1 = concatenate([deconv1,deconv2_up1,deconv3_up2,deconv4_up3, conv1])\n","# uconv1 = Dropout(0.2)(uconv1)\n","# uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","# uconv1 = ReLU()(uconv1)\n","    \n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","# uconv0 = Dropout(0.2)(uconv0)\n","# uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","# uconv0 = ReLU()(uconv0)\n","    \n","# uconv0 = Dropout(0.2)(uconv0)\n","# output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n","    \n","# model = Model(data, output_layer)\n","# model.summary()"]},{"cell_type":"markdown","metadata":{"id":"WexV0MuasmaS"},"source":["## Dilated Inception U-Net"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1668594600038,"user":{"displayName":"Hai Ninh Nham Do","userId":"15777938739034634289"},"user_tz":-420},"id":"hUbRmBETsp17","outputId":"1e6f0229-11a7-4295-d60d-e338aaa0a4d3"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"numFilters = 32\\n\\ninput_shape = (256,256,3)\\ninputs = Input(input_shape)\\n        \\nconv1 = DilatedInceptionModule(inputs, numFilters)\\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\\n    \\nconv2 = DilatedInceptionModule(pool1, 2*numFilters)\\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\\n    \\nconv3 = DilatedInceptionModule(pool2, 4*numFilters)\\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\\n    \\nconv4 = DilatedInceptionModule(pool3, 8*numFilters)\\npool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\\n\\nconv5 = DilatedInceptionModule(pool4,16*numFilters)\\n\\nup6 = UpSampling2D(size=(2,2))(conv5)\\nup6 = DilatedInceptionModule(up6, 8*numFilters)\\nmerge6 = concatenate([conv4,up6],axis=3)\\n    \\nup7 = UpSampling2D(size=(2,2))(merge6)\\nup7 = DilatedInceptionModule(up7, 4*numFilters)\\nmerge7 = concatenate([conv3,up7],axis=3)\\n    \\nup8 = UpSampling2D(size=(2,2))(merge7)\\nup8 = DilatedInceptionModule(up8, 2*numFilters)\\nmerge8 = concatenate([conv2,up8],axis=3)\\n    \\nup9 = UpSampling2D(size=(2,2))(merge8)\\nup9 = DilatedInceptionModule(up9, numFilters)\\nmerge9 = concatenate([conv1,up9],axis=3)\\n    \\nconv10 = Convolution2D(1, (1,1),  padding = 'same', kernel_initializer = 'he_normal')(merge9)\\nconv10 = BatchNormalization()(conv10)\\noutputs = Activation('sigmoid')(conv10)\\n    \\nmodel = Model(inputs = inputs, outputs = outputs)\\nmodel.summary()\""]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["'''numFilters = 32\n","\n","input_shape = (256,256,3)\n","inputs = Input(input_shape)\n","        \n","conv1 = DilatedInceptionModule(inputs, numFilters)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    \n","conv2 = DilatedInceptionModule(pool1, 2*numFilters)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    \n","conv3 = DilatedInceptionModule(pool2, 4*numFilters)\n","pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    \n","conv4 = DilatedInceptionModule(pool3, 8*numFilters)\n","pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","conv5 = DilatedInceptionModule(pool4,16*numFilters)\n","\n","up6 = UpSampling2D(size=(2,2))(conv5)\n","up6 = DilatedInceptionModule(up6, 8*numFilters)\n","merge6 = concatenate([conv4,up6],axis=3)\n","    \n","up7 = UpSampling2D(size=(2,2))(merge6)\n","up7 = DilatedInceptionModule(up7, 4*numFilters)\n","merge7 = concatenate([conv3,up7],axis=3)\n","    \n","up8 = UpSampling2D(size=(2,2))(merge7)\n","up8 = DilatedInceptionModule(up8, 2*numFilters)\n","merge8 = concatenate([conv2,up8],axis=3)\n","    \n","up9 = UpSampling2D(size=(2,2))(merge8)\n","up9 = DilatedInceptionModule(up9, numFilters)\n","merge9 = concatenate([conv1,up9],axis=3)\n","    \n","conv10 = Convolution2D(1, (1,1),  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","conv10 = BatchNormalization()(conv10)\n","outputs = Activation('sigmoid')(conv10)\n","    \n","model = Model(inputs = inputs, outputs = outputs)\n","model.summary()'''"]},{"cell_type":"markdown","metadata":{"id":"bxV40RuFDL7T"},"source":["## Metric"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7dPNE37T6xn7"},"outputs":[],"source":["def dice_rv(y_true, y_pred, smooth = 1e-5):\n","    y_pred = K.expand_dims(K.argmax(y_pred, axis=-1))\n","    y_pred = tf.where(y_pred == 1, 1., 0.)\n","    y_true = tf.where(y_true == 1, 1., 0.)\n","    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n","    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n","    return K.mean((2 * intersection + smooth) / (union + smooth))\n","\n","def dice_myo(y_true, y_pred, smooth = 1e-5):\n","    y_pred = K.expand_dims(K.argmax(y_pred, axis=-1))\n","    y_pred = tf.where(y_pred == 2, 1., 0.)\n","    y_true = tf.where(y_true == 2, 1., 0.)\n","    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n","    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n","    return K.mean((2 * intersection + smooth) / (union + smooth))\n","\n","def dice_lv(y_true, y_pred, smooth = 1e-5):\n","    y_pred = K.expand_dims(K.argmax(y_pred, axis=-1))\n","    y_pred = tf.where(y_pred == 3, 1., 0.)\n","    y_true = tf.where(y_true == 3, 1., 0.)\n","    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n","    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n","    return K.mean((2 * intersection + smooth) / (union + smooth))\n","def mean_dice(y_true, y_pred):\n","    return (dice_rv(y_true, y_pred)+dice_myo(y_true, y_pred)+dice_lv(y_true, y_pred)) /3 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKbp7KhAslBV"},"outputs":[],"source":["def hausdorff_distance(y_true, y_pred, percentile=100):\n","    # In this function, y_pred must have shape = (B, H, W, (D)) with label: 0, 1, 2, ...\n","\n","    # Instruction to use function \"compute_hausdorff_distance\":\n","        # y_pred: input data to compute, typical segmentation model output.\n","        # y_pred.shape = y_true.shape = (B, C_one_hot, H, W, (D))\n","        # Args:\n","        # y_pred: input data to compute, typical segmentation model output.\n","        #     It must be one-hot format and first dim is batch, example shape: [16, 3, 32, 32]. The values\n","        # should be binarized.\n","        # y: ground truth to compute mean the distance. It must be one-hot format and first dim is batch.\n","        #     The values should be binarized.\n","    if len(y_true.shape) == 4: # if y_true.shape = (B, H, W, D)\n","        y_true_one_hot = tf.keras.utils.to_categorical(y_true).transpose(0, -1, 1, 2, 3)\n","        y_pred_one_hot = tf.keras.utils.to_categorical(y_pred).transpose(0, -1, 1, 2, 3)\n","    else:\n","        y_true_one_hot = tf.keras.utils.to_categorical(y_true).transpose(0, -1, 1, 2)\n","        y_pred_one_hot = tf.keras.utils.to_categorical(y_pred).transpose(0, -1, 1, 2)\n","    return compute_hausdorff_distance(y_pred_one_hot, y_true_one_hot, percentile=percentile)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MeWN17bCNdyG"},"outputs":[],"source":["# y_true = tf.ones((2, 128, 128, 1), dtype=tf.uint8) * 3\n","# y_true_onehot = tf.one_hot(tf.squeeze(y_true), depth=NUM_CLASS)\n","def dice_coef_loss(y_true, y_pred, num_class = NUM_CLASS, smooth=1e-10):\n","    y_true_onehot = tf.one_hot(tf.squeeze(y_true), depth=num_class)[...,1:]\n","    y_pred = y_pred[...,1:]\n","\n","    true_pos = K.sum(y_true_onehot * y_pred, axis=[1,2,3])\n","    summation = K.sum(y_true_onehot + y_pred, axis=[1,2,3])\n","    loss = (2.0 * true_pos + smooth) / (summation + smooth)\n","    return 1-K.mean(loss)\n","\n","def tversky_loss(y_true, y_pred, num_class = NUM_CLASS, alpha = 0.7):\n","    y_true_onehot = tf.one_hot(tf.squeeze(y_true), depth=num_class)[...,1:]\n","    y_pred = y_pred[...,1:]\n","\n","    true_pos = K.sum(y_true_onehot * y_pred, axis=[1,2,3])\n","    true_neg = K.sum((1-y_true_onehot) * (1-y_pred), axis=[1,2,3])\n","    false_neg = K.sum(y_true_onehot * (1-y_pred), axis=[1,2,3])\n","    false_pos = K.sum((1-y_true_onehot) * y_pred, axis=[1,2,3])\n","\n","    loss = 1-(true_pos)/(true_pos + alpha*false_neg + (1-alpha)*false_pos)\n","    return K.mean(loss)\n","\n","def focal_tversky(y_true, y_pred, gamma = 0.75):\n","    p = tversky_loss(y_true, y_pred)\n","    return K.pow(p, gamma)\n","\n","def cross_entropy(y_true, y_pred):\n","    return SparseCategoricalCrossentropy()(y_true, y_pred)\n","\n","def accuracy_loss(y_true, y_pred, num_class=NUM_CLASS, smooth=1e-10):\n","    y_true_onehot = tf.one_hot(tf.squeeze(y_true), depth=num_class)\n","    # y_pred = y_pred\n","\n","    true_pos = K.sum(y_true_onehot * y_pred, axis=[1,2,3]) + smooth\n","    true_neg = K.sum((1-y_true_onehot) * (1-y_pred), axis=[1,2,3])+ smooth\n","    false_neg = K.sum(y_true_onehot * (1-y_pred), axis=[1,2,3])+ smooth\n","    false_pos = K.sum((1-y_true_onehot) * y_pred, axis=[1,2,3])+ smooth\n","    loss = 1-(true_pos + true_neg)/(true_pos + true_neg + false_pos + false_neg)\n","    return K.mean(loss)\n","\n","def tversky_kahneman(y_true, y_pred, num_class = NUM_CLASS, alpha=0.5, beta=0.5, gamma=4/3, smooth=1e-7):\n","    y_pred = tf.clip_by_value(y_pred, clip_value_min=1e-6, clip_value_max=1-1e-6)\n","    y_true_onehot = tf.one_hot(tf.squeeze(y_true), depth=num_class)[...,1:]\n","    y_pred = y_pred[...,1:]\n","\n","    true_pos = K.sum(y_true_onehot * y_pred, axis=[1,2,3]) + smooth\n","    true_neg = K.sum((1-y_true_onehot) * (1-y_pred), axis=[1,2,3])+ smooth\n","    false_neg = K.sum(y_true_onehot * (1-y_pred), axis=[1,2,3])\n","    false_pos = K.sum((1-y_true_onehot) * y_pred, axis=[1,2,3])\n","\n","    _true_pos = K.sqrt(true_pos * true_neg)\n","\n","\n","    p = (0.5*true_pos + 0.5*true_neg)/(0.5*true_pos + 0.5*true_neg + alpha*false_pos + beta*false_neg)\n","    p_gamma = K.pow(p,gamma) #p^gamma\n","    _p_gamma = K.pow(1-p, gamma) #(1-p)^gamma\n","    loss = _p_gamma/K.pow(p_gamma + _p_gamma, 1/gamma)\n","    return K.mean(loss)\n","\n","def bub_loss(y_true, y_pred, num_class=NUM_CLASS, gamma=4/3, smooth=1e-10):\n","    #y l hm loss ca paper anh nh\n","    y_pred = tf.clip_by_value(y_pred, clip_value_min=1e-6, clip_value_max=1-1e-6)\n","\n","    y_true_onehot = tf.one_hot(tf.squeeze(y_true), depth=num_class)[...,1:]\n","    y_pred = y_pred[..., 1:]\n","\n","    # y_true_onehot = tf.one_hot(tf.squeeze(y_true), depth=num_class)\n","\n","\n","    true_pos = K.sum(y_true_onehot * y_pred, axis=[1,2,3]) + smooth\n","    true_neg = K.sum((1-y_true_onehot) * (1-y_pred), axis=[1,2,3]) + smooth\n","    false_neg = K.sum(y_true_onehot * (1-y_pred), axis=[1,2,3])\n","    false_pos = K.sum((1-y_true_onehot) * y_pred, axis=[1,2,3])\n","\n","    _true_neg = K.sqrt(true_pos * true_neg)\n","    p = (true_pos + _true_neg)/(true_pos + false_pos + false_neg + _true_neg)\n","    p_gamma = K.pow(p,gamma) #p^gamma\n","    _p_gamma = K.pow(1-p, gamma) #(1-p)^gamma\n","    loss = _p_gamma / K.pow(p_gamma + _p_gamma, 1/gamma)\n","    return K.mean(loss)\n","\n","def _bub_loss(y_true, y_pred, num_class=NUM_CLASS, gamma=4/3, smooth=1e-7):\n","    # y cng l hm loss ca paper c m b 1 stage tversky kahneman anh nh, ci ny n tng ng l1 l2 anh \n","    y_pred = tf.clip_by_value(y_pred, clip_value_min=1e-6, clip_value_max=1-1e-6)\n","\n","    y_true_onehot = tf.one_hot(tf.squeeze(y_true), depth=num_class)[...,1:]\n","    y_pred = y_pred[..., 1:]\n","\n","    # y_true_onehot = tf.one_hot(tf.squeeze(y_true), depth=num_class)\n","\n","\n","    true_pos = K.sum(y_true_onehot * y_pred, axis=[1,2,3]) + smooth\n","    true_neg = K.sum((1-y_true_onehot) * (1-y_pred), axis=[1,2,3]) + smooth\n","    false_neg = K.sum(y_true_onehot * (1-y_pred), axis=[1,2,3])\n","    false_pos = K.sum((1-y_true_onehot) * y_pred, axis=[1,2,3])\n","\n","    _true_neg = K.sqrt(true_pos * true_neg)\n","    p = (true_pos + _true_neg)/(true_pos + false_pos + false_neg + _true_neg)\n","    return K.mean(1-p)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BMUB-hBVziza"},"outputs":[],"source":["#  bub_loss(y_true, b)\n","# a = tf.random.uniform((2, 160, 160, 1))\n","# b = model(a)"]},{"cell_type":"markdown","metadata":{"id":"Z2GnIUkpGRiv"},"source":["## model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1669451759803,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"_fR2O91tTsbE","outputId":"4b257256-d0b6-49f8-bf41-9b6c70cddc02"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["%cd \"/content\"\n","!rm -rf weights"]},{"cell_type":"markdown","metadata":{"id":"JyEQoVXjKC6V"},"source":["em thay model vao day nha"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1669451760228,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"_xCeqcQiGTAd","outputId":"14aa1374-74f5-42f7-8221-ecb122e426cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1w-TuKfFg1p_kmorgOYNhTF-HPfPcx4Ab/brain_mri_segmentation\n"]}],"source":["%cd \"/content/drive/MyDrive/brain_mri_segmentation\"\n","# %run UnetModel.ipynb\n","# model = seg_net(input_shape=(128, 128, 1), out_channels=4)"]},{"cell_type":"markdown","metadata":{"id":"6oHZYAWqB7MM"},"source":["## training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYF9oWUzJyUH"},"outputs":[],"source":["#callbacks\n","earlystopping = EarlyStopping(monitor='val_mean_dice', mode='max', verbose=1, patience=50)\n","# save the best model with lower validation loss\n","checkpointer = ModelCheckpoint(filepath=\"/content/weights/ckpt{val_mean_dice:.4f}.h5\", monitor=\"val_mean_dice\", mode=\"max\", verbose=1, save_best_only=True, save_weights_only=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_mean_dice', mode='max', verbose=1, patience=12, min_lr=1e-7, factor=0.5)"]},{"cell_type":"markdown","metadata":{"id":"Ww5lLsB5z5_v"},"source":["em thay ham loss o day"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1669451765942,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"w19s0akRKPEQ","outputId":"b82c5462-d8f2-417f-d294-edd52d4a9635"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["%cd \"/content/\"\n","os.makedirs(\"weights\", exist_ok=True)\n","# model.load_weights(\"/content/weights/ckpt0.8299.h5\")\n","model.compile(optimizer=Nadam(learning_rate=1e-3), \\\n","              loss=cross_entropy, \\\n","              metrics=[dice_rv, dice_myo, dice_lv, mean_dice]) #anh dng bub hoc _bub anh nh"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":15475984,"status":"error","timestamp":1669105438737,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"xtbk805vOpw_","outputId":"92c7abbd-c54b-4d65-db0b-7e4210a4c434"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","164/164 [==============================] - ETA: 0s - loss: 0.2244 - dice_rv: 0.4012 - dice_myo: 0.5214 - dice_lv: 0.6621 - mean_dice: 0.5282\n","Epoch 1: val_mean_dice improved from -inf to 0.29587, saving model to /content/weights/ckpt0.2959.h5\n","164/164 [==============================] - 157s 592ms/step - loss: 0.2244 - dice_rv: 0.4012 - dice_myo: 0.5214 - dice_lv: 0.6621 - mean_dice: 0.5282 - val_loss: 0.3350 - val_dice_rv: 0.2172 - val_dice_myo: 0.2846 - val_dice_lv: 0.3858 - val_mean_dice: 0.2959 - lr: 0.0010\n","Epoch 2/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0890 - dice_rv: 0.6238 - dice_myo: 0.7233 - dice_lv: 0.8254 - mean_dice: 0.7242\n","Epoch 2: val_mean_dice improved from 0.29587 to 0.57295, saving model to /content/weights/ckpt0.5729.h5\n","164/164 [==============================] - 94s 576ms/step - loss: 0.0890 - dice_rv: 0.6238 - dice_myo: 0.7233 - dice_lv: 0.8254 - mean_dice: 0.7242 - val_loss: 0.1549 - val_dice_rv: 0.4622 - val_dice_myo: 0.5459 - val_dice_lv: 0.7108 - val_mean_dice: 0.5729 - lr: 0.0010\n","Epoch 3/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0648 - dice_rv: 0.6869 - dice_myo: 0.7735 - dice_lv: 0.8564 - mean_dice: 0.7723\n","Epoch 3: val_mean_dice improved from 0.57295 to 0.69519, saving model to /content/weights/ckpt0.6952.h5\n","164/164 [==============================] - 95s 578ms/step - loss: 0.0648 - dice_rv: 0.6869 - dice_myo: 0.7735 - dice_lv: 0.8564 - mean_dice: 0.7723 - val_loss: 0.0826 - val_dice_rv: 0.6134 - val_dice_myo: 0.6744 - val_dice_lv: 0.7977 - val_mean_dice: 0.6952 - lr: 0.0010\n","Epoch 4/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0524 - dice_rv: 0.7294 - dice_myo: 0.8021 - dice_lv: 0.8771 - mean_dice: 0.8029\n","Epoch 4: val_mean_dice improved from 0.69519 to 0.77062, saving model to /content/weights/ckpt0.7706.h5\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0524 - dice_rv: 0.7294 - dice_myo: 0.8021 - dice_lv: 0.8771 - mean_dice: 0.8029 - val_loss: 0.0589 - val_dice_rv: 0.7074 - val_dice_myo: 0.7482 - val_dice_lv: 0.8563 - val_mean_dice: 0.7706 - lr: 0.0010\n","Epoch 5/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0449 - dice_rv: 0.7559 - dice_myo: 0.8231 - dice_lv: 0.8891 - mean_dice: 0.8227\n","Epoch 5: val_mean_dice improved from 0.77062 to 0.77201, saving model to /content/weights/ckpt0.7720.h5\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0449 - dice_rv: 0.7559 - dice_myo: 0.8231 - dice_lv: 0.8891 - mean_dice: 0.8227 - val_loss: 0.0605 - val_dice_rv: 0.7038 - val_dice_myo: 0.7472 - val_dice_lv: 0.8650 - val_mean_dice: 0.7720 - lr: 0.0010\n","Epoch 6/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0476 - dice_rv: 0.7690 - dice_myo: 0.8284 - dice_lv: 0.8914 - mean_dice: 0.8296\n","Epoch 6: val_mean_dice did not improve from 0.77201\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0476 - dice_rv: 0.7690 - dice_myo: 0.8284 - dice_lv: 0.8914 - mean_dice: 0.8296 - val_loss: 0.1720 - val_dice_rv: 0.3971 - val_dice_myo: 0.5744 - val_dice_lv: 0.6256 - val_mean_dice: 0.5324 - lr: 0.0010\n","Epoch 7/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0480 - dice_rv: 0.7524 - dice_myo: 0.8189 - dice_lv: 0.8846 - mean_dice: 0.8186\n","Epoch 7: val_mean_dice improved from 0.77201 to 0.79513, saving model to /content/weights/ckpt0.7951.h5\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0480 - dice_rv: 0.7524 - dice_myo: 0.8189 - dice_lv: 0.8846 - mean_dice: 0.8186 - val_loss: 0.0468 - val_dice_rv: 0.7392 - val_dice_myo: 0.7693 - val_dice_lv: 0.8769 - val_mean_dice: 0.7951 - lr: 0.0010\n","Epoch 8/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0353 - dice_rv: 0.8142 - dice_myo: 0.8529 - dice_lv: 0.9089 - mean_dice: 0.8586\n","Epoch 8: val_mean_dice did not improve from 0.79513\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0353 - dice_rv: 0.8142 - dice_myo: 0.8529 - dice_lv: 0.9089 - mean_dice: 0.8586 - val_loss: 0.0490 - val_dice_rv: 0.7376 - val_dice_myo: 0.7772 - val_dice_lv: 0.8705 - val_mean_dice: 0.7951 - lr: 0.0010\n","Epoch 9/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0318 - dice_rv: 0.8347 - dice_myo: 0.8646 - dice_lv: 0.9165 - mean_dice: 0.8720\n","Epoch 9: val_mean_dice improved from 0.79513 to 0.80562, saving model to /content/weights/ckpt0.8056.h5\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0318 - dice_rv: 0.8347 - dice_myo: 0.8646 - dice_lv: 0.9165 - mean_dice: 0.8720 - val_loss: 0.0501 - val_dice_rv: 0.7529 - val_dice_myo: 0.7873 - val_dice_lv: 0.8767 - val_mean_dice: 0.8056 - lr: 0.0010\n","Epoch 10/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0304 - dice_rv: 0.8457 - dice_myo: 0.8698 - dice_lv: 0.9188 - mean_dice: 0.8781\n","Epoch 10: val_mean_dice improved from 0.80562 to 0.80893, saving model to /content/weights/ckpt0.8089.h5\n","164/164 [==============================] - 95s 577ms/step - loss: 0.0304 - dice_rv: 0.8457 - dice_myo: 0.8698 - dice_lv: 0.9188 - mean_dice: 0.8781 - val_loss: 0.0496 - val_dice_rv: 0.7637 - val_dice_myo: 0.7841 - val_dice_lv: 0.8790 - val_mean_dice: 0.8089 - lr: 0.0010\n","Epoch 11/500\n","164/164 [==============================] - ETA: 0s - loss: 0.1397 - dice_rv: 0.5895 - dice_myo: 0.6712 - dice_lv: 0.7662 - mean_dice: 0.6756\n","Epoch 11: val_mean_dice did not improve from 0.80893\n","164/164 [==============================] - 94s 571ms/step - loss: 0.1397 - dice_rv: 0.5895 - dice_myo: 0.6712 - dice_lv: 0.7662 - mean_dice: 0.6756 - val_loss: 0.1180 - val_dice_rv: 0.5501 - val_dice_myo: 0.6722 - val_dice_lv: 0.7883 - val_mean_dice: 0.6702 - lr: 0.0010\n","Epoch 12/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0978 - dice_rv: 0.5976 - dice_myo: 0.7291 - dice_lv: 0.8216 - mean_dice: 0.7161\n","Epoch 12: val_mean_dice did not improve from 0.80893\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0978 - dice_rv: 0.5976 - dice_myo: 0.7291 - dice_lv: 0.8216 - mean_dice: 0.7161 - val_loss: 0.1005 - val_dice_rv: 0.5850 - val_dice_myo: 0.6999 - val_dice_lv: 0.8341 - val_mean_dice: 0.7063 - lr: 0.0010\n","Epoch 13/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0627 - dice_rv: 0.6798 - dice_myo: 0.7862 - dice_lv: 0.8660 - mean_dice: 0.7773\n","Epoch 13: val_mean_dice did not improve from 0.80893\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0627 - dice_rv: 0.6798 - dice_myo: 0.7862 - dice_lv: 0.8660 - mean_dice: 0.7773 - val_loss: 0.0563 - val_dice_rv: 0.6894 - val_dice_myo: 0.7607 - val_dice_lv: 0.8619 - val_mean_dice: 0.7707 - lr: 0.0010\n","Epoch 14/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0499 - dice_rv: 0.7223 - dice_myo: 0.8156 - dice_lv: 0.8836 - mean_dice: 0.8072\n","Epoch 14: val_mean_dice did not improve from 0.80893\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0499 - dice_rv: 0.7223 - dice_myo: 0.8156 - dice_lv: 0.8836 - mean_dice: 0.8072 - val_loss: 0.0524 - val_dice_rv: 0.7435 - val_dice_myo: 0.7766 - val_dice_lv: 0.8734 - val_mean_dice: 0.7978 - lr: 0.0010\n","Epoch 15/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0430 - dice_rv: 0.7571 - dice_myo: 0.8347 - dice_lv: 0.8964 - mean_dice: 0.8294\n","Epoch 15: val_mean_dice did not improve from 0.80893\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0430 - dice_rv: 0.7571 - dice_myo: 0.8347 - dice_lv: 0.8964 - mean_dice: 0.8294 - val_loss: 0.0510 - val_dice_rv: 0.7261 - val_dice_myo: 0.7812 - val_dice_lv: 0.8743 - val_mean_dice: 0.7939 - lr: 0.0010\n","Epoch 16/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0384 - dice_rv: 0.7849 - dice_myo: 0.8442 - dice_lv: 0.9022 - mean_dice: 0.8438\n","Epoch 16: val_mean_dice did not improve from 0.80893\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0384 - dice_rv: 0.7849 - dice_myo: 0.8442 - dice_lv: 0.9022 - mean_dice: 0.8438 - val_loss: 0.0490 - val_dice_rv: 0.7519 - val_dice_myo: 0.7874 - val_dice_lv: 0.8785 - val_mean_dice: 0.8059 - lr: 0.0010\n","Epoch 17/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0353 - dice_rv: 0.7999 - dice_myo: 0.8562 - dice_lv: 0.9073 - mean_dice: 0.8545\n","Epoch 17: val_mean_dice did not improve from 0.80893\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0353 - dice_rv: 0.7999 - dice_myo: 0.8562 - dice_lv: 0.9073 - mean_dice: 0.8545 - val_loss: 0.0524 - val_dice_rv: 0.7542 - val_dice_myo: 0.7776 - val_dice_lv: 0.8818 - val_mean_dice: 0.8045 - lr: 0.0010\n","Epoch 18/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0326 - dice_rv: 0.8207 - dice_myo: 0.8653 - dice_lv: 0.9133 - mean_dice: 0.8664\n","Epoch 18: val_mean_dice did not improve from 0.80893\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0326 - dice_rv: 0.8207 - dice_myo: 0.8653 - dice_lv: 0.9133 - mean_dice: 0.8664 - val_loss: 0.0500 - val_dice_rv: 0.7367 - val_dice_myo: 0.7967 - val_dice_lv: 0.8888 - val_mean_dice: 0.8074 - lr: 0.0010\n","Epoch 19/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0312 - dice_rv: 0.8369 - dice_myo: 0.8720 - dice_lv: 0.9204 - mean_dice: 0.8764\n","Epoch 19: val_mean_dice did not improve from 0.80893\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0312 - dice_rv: 0.8369 - dice_myo: 0.8720 - dice_lv: 0.9204 - mean_dice: 0.8764 - val_loss: 0.0515 - val_dice_rv: 0.7460 - val_dice_myo: 0.7966 - val_dice_lv: 0.8820 - val_mean_dice: 0.8082 - lr: 0.0010\n","Epoch 20/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0304 - dice_rv: 0.8405 - dice_myo: 0.8746 - dice_lv: 0.9210 - mean_dice: 0.8787\n","Epoch 20: val_mean_dice improved from 0.80893 to 0.81623, saving model to /content/weights/ckpt0.8162.h5\n","164/164 [==============================] - 94s 576ms/step - loss: 0.0304 - dice_rv: 0.8405 - dice_myo: 0.8746 - dice_lv: 0.9210 - mean_dice: 0.8787 - val_loss: 0.0536 - val_dice_rv: 0.7572 - val_dice_myo: 0.8039 - val_dice_lv: 0.8875 - val_mean_dice: 0.8162 - lr: 0.0010\n","Epoch 21/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0287 - dice_rv: 0.8563 - dice_myo: 0.8805 - dice_lv: 0.9242 - mean_dice: 0.8870\n","Epoch 21: val_mean_dice did not improve from 0.81623\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0287 - dice_rv: 0.8563 - dice_myo: 0.8805 - dice_lv: 0.9242 - mean_dice: 0.8870 - val_loss: 0.0521 - val_dice_rv: 0.7716 - val_dice_myo: 0.8031 - val_dice_lv: 0.8730 - val_mean_dice: 0.8159 - lr: 0.0010\n","Epoch 22/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0271 - dice_rv: 0.8656 - dice_myo: 0.8869 - dice_lv: 0.9268 - mean_dice: 0.8931\n","Epoch 22: val_mean_dice improved from 0.81623 to 0.82094, saving model to /content/weights/ckpt0.8209.h5\n","164/164 [==============================] - 95s 577ms/step - loss: 0.0271 - dice_rv: 0.8656 - dice_myo: 0.8869 - dice_lv: 0.9268 - mean_dice: 0.8931 - val_loss: 0.0523 - val_dice_rv: 0.7824 - val_dice_myo: 0.8017 - val_dice_lv: 0.8787 - val_mean_dice: 0.8209 - lr: 0.0010\n","Epoch 23/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0262 - dice_rv: 0.8765 - dice_myo: 0.8881 - dice_lv: 0.9292 - mean_dice: 0.8979\n","Epoch 23: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0262 - dice_rv: 0.8765 - dice_myo: 0.8881 - dice_lv: 0.9292 - mean_dice: 0.8979 - val_loss: 0.0509 - val_dice_rv: 0.7489 - val_dice_myo: 0.7917 - val_dice_lv: 0.8887 - val_mean_dice: 0.8098 - lr: 0.0010\n","Epoch 24/500\n","164/164 [==============================] - ETA: 0s - loss: 0.1121 - dice_rv: 0.6615 - dice_myo: 0.7425 - dice_lv: 0.8288 - mean_dice: 0.7443\n","Epoch 24: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 573ms/step - loss: 0.1121 - dice_rv: 0.6615 - dice_myo: 0.7425 - dice_lv: 0.8288 - mean_dice: 0.7443 - val_loss: 0.0714 - val_dice_rv: 0.6250 - val_dice_myo: 0.7396 - val_dice_lv: 0.8293 - val_mean_dice: 0.7313 - lr: 0.0010\n","Epoch 25/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0612 - dice_rv: 0.6957 - dice_myo: 0.7925 - dice_lv: 0.8653 - mean_dice: 0.7845\n","Epoch 25: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0612 - dice_rv: 0.6957 - dice_myo: 0.7925 - dice_lv: 0.8653 - mean_dice: 0.7845 - val_loss: 0.0528 - val_dice_rv: 0.6817 - val_dice_myo: 0.7660 - val_dice_lv: 0.8661 - val_mean_dice: 0.7713 - lr: 0.0010\n","Epoch 26/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0438 - dice_rv: 0.7624 - dice_myo: 0.8322 - dice_lv: 0.8940 - mean_dice: 0.8296\n","Epoch 26: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0438 - dice_rv: 0.7624 - dice_myo: 0.8322 - dice_lv: 0.8940 - mean_dice: 0.8296 - val_loss: 0.0530 - val_dice_rv: 0.6779 - val_dice_myo: 0.7986 - val_dice_lv: 0.8705 - val_mean_dice: 0.7823 - lr: 0.0010\n","Epoch 27/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0373 - dice_rv: 0.7963 - dice_myo: 0.8481 - dice_lv: 0.9027 - mean_dice: 0.8490\n","Epoch 27: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0373 - dice_rv: 0.7963 - dice_myo: 0.8481 - dice_lv: 0.9027 - mean_dice: 0.8490 - val_loss: 0.0471 - val_dice_rv: 0.7324 - val_dice_myo: 0.7944 - val_dice_lv: 0.8802 - val_mean_dice: 0.8023 - lr: 0.0010\n","Epoch 28/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0337 - dice_rv: 0.8228 - dice_myo: 0.8602 - dice_lv: 0.9112 - mean_dice: 0.8647\n","Epoch 28: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0337 - dice_rv: 0.8228 - dice_myo: 0.8602 - dice_lv: 0.9112 - mean_dice: 0.8647 - val_loss: 0.0443 - val_dice_rv: 0.7658 - val_dice_myo: 0.8053 - val_dice_lv: 0.8892 - val_mean_dice: 0.8201 - lr: 0.0010\n","Epoch 29/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0312 - dice_rv: 0.8376 - dice_myo: 0.8702 - dice_lv: 0.9167 - mean_dice: 0.8749\n","Epoch 29: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0312 - dice_rv: 0.8376 - dice_myo: 0.8702 - dice_lv: 0.9167 - mean_dice: 0.8749 - val_loss: 0.0469 - val_dice_rv: 0.7666 - val_dice_myo: 0.8021 - val_dice_lv: 0.8875 - val_mean_dice: 0.8187 - lr: 0.0010\n","Epoch 30/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0298 - dice_rv: 0.8459 - dice_myo: 0.8756 - dice_lv: 0.9215 - mean_dice: 0.8810\n","Epoch 30: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0298 - dice_rv: 0.8459 - dice_myo: 0.8756 - dice_lv: 0.9215 - mean_dice: 0.8810 - val_loss: 0.0518 - val_dice_rv: 0.7356 - val_dice_myo: 0.7996 - val_dice_lv: 0.8838 - val_mean_dice: 0.8063 - lr: 0.0010\n","Epoch 31/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0284 - dice_rv: 0.8576 - dice_myo: 0.8798 - dice_lv: 0.9254 - mean_dice: 0.8876\n","Epoch 31: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0284 - dice_rv: 0.8576 - dice_myo: 0.8798 - dice_lv: 0.9254 - mean_dice: 0.8876 - val_loss: 0.0519 - val_dice_rv: 0.7582 - val_dice_myo: 0.8053 - val_dice_lv: 0.8871 - val_mean_dice: 0.8169 - lr: 0.0010\n","Epoch 32/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0272 - dice_rv: 0.8660 - dice_myo: 0.8838 - dice_lv: 0.9262 - mean_dice: 0.8920\n","Epoch 32: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0272 - dice_rv: 0.8660 - dice_myo: 0.8838 - dice_lv: 0.9262 - mean_dice: 0.8920 - val_loss: 0.0545 - val_dice_rv: 0.7304 - val_dice_myo: 0.8025 - val_dice_lv: 0.8844 - val_mean_dice: 0.8058 - lr: 0.0010\n","Epoch 33/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0267 - dice_rv: 0.8723 - dice_myo: 0.8888 - dice_lv: 0.9298 - mean_dice: 0.8970\n","Epoch 33: val_mean_dice did not improve from 0.82094\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0267 - dice_rv: 0.8723 - dice_myo: 0.8888 - dice_lv: 0.9298 - mean_dice: 0.8970 - val_loss: 0.0553 - val_dice_rv: 0.7495 - val_dice_myo: 0.8037 - val_dice_lv: 0.8868 - val_mean_dice: 0.8133 - lr: 0.0010\n","Epoch 34/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0257 - dice_rv: 0.8831 - dice_myo: 0.8911 - dice_lv: 0.9309 - mean_dice: 0.9017\n","Epoch 34: val_mean_dice improved from 0.82094 to 0.82205, saving model to /content/weights/ckpt0.8221.h5\n","164/164 [==============================] - 94s 576ms/step - loss: 0.0257 - dice_rv: 0.8831 - dice_myo: 0.8911 - dice_lv: 0.9309 - mean_dice: 0.9017 - val_loss: 0.0516 - val_dice_rv: 0.7683 - val_dice_myo: 0.8086 - val_dice_lv: 0.8892 - val_mean_dice: 0.8221 - lr: 0.0010\n","Epoch 35/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0249 - dice_rv: 0.8825 - dice_myo: 0.8942 - dice_lv: 0.9322 - mean_dice: 0.9030\n","Epoch 35: val_mean_dice improved from 0.82205 to 0.82240, saving model to /content/weights/ckpt0.8224.h5\n","164/164 [==============================] - 94s 576ms/step - loss: 0.0249 - dice_rv: 0.8825 - dice_myo: 0.8942 - dice_lv: 0.9322 - mean_dice: 0.9030 - val_loss: 0.0515 - val_dice_rv: 0.7753 - val_dice_myo: 0.8026 - val_dice_lv: 0.8893 - val_mean_dice: 0.8224 - lr: 0.0010\n","Epoch 36/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0248 - dice_rv: 0.8837 - dice_myo: 0.8946 - dice_lv: 0.9331 - mean_dice: 0.9038\n","Epoch 36: val_mean_dice improved from 0.82240 to 0.82302, saving model to /content/weights/ckpt0.8230.h5\n","164/164 [==============================] - 95s 577ms/step - loss: 0.0248 - dice_rv: 0.8837 - dice_myo: 0.8946 - dice_lv: 0.9331 - mean_dice: 0.9038 - val_loss: 0.0529 - val_dice_rv: 0.7630 - val_dice_myo: 0.8094 - val_dice_lv: 0.8967 - val_mean_dice: 0.8230 - lr: 0.0010\n","Epoch 37/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0244 - dice_rv: 0.8874 - dice_myo: 0.8951 - dice_lv: 0.9337 - mean_dice: 0.9054\n","Epoch 37: val_mean_dice did not improve from 0.82302\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0244 - dice_rv: 0.8874 - dice_myo: 0.8951 - dice_lv: 0.9337 - mean_dice: 0.9054 - val_loss: 0.0525 - val_dice_rv: 0.7669 - val_dice_myo: 0.8138 - val_dice_lv: 0.8880 - val_mean_dice: 0.8229 - lr: 0.0010\n","Epoch 38/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0239 - dice_rv: 0.8902 - dice_myo: 0.8994 - dice_lv: 0.9358 - mean_dice: 0.9085\n","Epoch 38: val_mean_dice did not improve from 0.82302\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0239 - dice_rv: 0.8902 - dice_myo: 0.8994 - dice_lv: 0.9358 - mean_dice: 0.9085 - val_loss: 0.0512 - val_dice_rv: 0.7564 - val_dice_myo: 0.8062 - val_dice_lv: 0.8845 - val_mean_dice: 0.8157 - lr: 0.0010\n","Epoch 39/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0236 - dice_rv: 0.8901 - dice_myo: 0.9018 - dice_lv: 0.9383 - mean_dice: 0.9101\n","Epoch 39: val_mean_dice did not improve from 0.82302\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0236 - dice_rv: 0.8901 - dice_myo: 0.9018 - dice_lv: 0.9383 - mean_dice: 0.9101 - val_loss: 0.0516 - val_dice_rv: 0.7538 - val_dice_myo: 0.8070 - val_dice_lv: 0.8871 - val_mean_dice: 0.8160 - lr: 0.0010\n","Epoch 40/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0227 - dice_rv: 0.9027 - dice_myo: 0.9025 - dice_lv: 0.9375 - mean_dice: 0.9142\n","Epoch 40: val_mean_dice did not improve from 0.82302\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0227 - dice_rv: 0.9027 - dice_myo: 0.9025 - dice_lv: 0.9375 - mean_dice: 0.9142 - val_loss: 0.0547 - val_dice_rv: 0.7541 - val_dice_myo: 0.8109 - val_dice_lv: 0.8911 - val_mean_dice: 0.8187 - lr: 0.0010\n","Epoch 41/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0265 - dice_rv: 0.8675 - dice_myo: 0.8918 - dice_lv: 0.9334 - mean_dice: 0.8976\n","Epoch 41: val_mean_dice improved from 0.82302 to 0.82689, saving model to /content/weights/ckpt0.8269.h5\n","164/164 [==============================] - 95s 577ms/step - loss: 0.0265 - dice_rv: 0.8675 - dice_myo: 0.8918 - dice_lv: 0.9334 - mean_dice: 0.8976 - val_loss: 0.0503 - val_dice_rv: 0.7703 - val_dice_myo: 0.8158 - val_dice_lv: 0.8945 - val_mean_dice: 0.8269 - lr: 0.0010\n","Epoch 42/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0221 - dice_rv: 0.9047 - dice_myo: 0.9053 - dice_lv: 0.9390 - mean_dice: 0.9163\n","Epoch 42: val_mean_dice did not improve from 0.82689\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0221 - dice_rv: 0.9047 - dice_myo: 0.9053 - dice_lv: 0.9390 - mean_dice: 0.9163 - val_loss: 0.0538 - val_dice_rv: 0.7602 - val_dice_myo: 0.8103 - val_dice_lv: 0.8869 - val_mean_dice: 0.8192 - lr: 0.0010\n","Epoch 43/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0216 - dice_rv: 0.9067 - dice_myo: 0.9068 - dice_lv: 0.9405 - mean_dice: 0.9180\n","Epoch 43: val_mean_dice did not improve from 0.82689\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0216 - dice_rv: 0.9067 - dice_myo: 0.9068 - dice_lv: 0.9405 - mean_dice: 0.9180 - val_loss: 0.0556 - val_dice_rv: 0.7686 - val_dice_myo: 0.8117 - val_dice_lv: 0.8907 - val_mean_dice: 0.8237 - lr: 0.0010\n","Epoch 44/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0211 - dice_rv: 0.9088 - dice_myo: 0.9096 - dice_lv: 0.9418 - mean_dice: 0.9201\n","Epoch 44: val_mean_dice did not improve from 0.82689\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0211 - dice_rv: 0.9088 - dice_myo: 0.9096 - dice_lv: 0.9418 - mean_dice: 0.9201 - val_loss: 0.0534 - val_dice_rv: 0.7634 - val_dice_myo: 0.8048 - val_dice_lv: 0.8886 - val_mean_dice: 0.8189 - lr: 0.0010\n","Epoch 45/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0219 - dice_rv: 0.8965 - dice_myo: 0.9056 - dice_lv: 0.9391 - mean_dice: 0.9138\n","Epoch 45: val_mean_dice improved from 0.82689 to 0.82800, saving model to /content/weights/ckpt0.8280.h5\n","164/164 [==============================] - 95s 576ms/step - loss: 0.0219 - dice_rv: 0.8965 - dice_myo: 0.9056 - dice_lv: 0.9391 - mean_dice: 0.9138 - val_loss: 0.0522 - val_dice_rv: 0.7815 - val_dice_myo: 0.8097 - val_dice_lv: 0.8927 - val_mean_dice: 0.8280 - lr: 0.0010\n","Epoch 46/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0211 - dice_rv: 0.9068 - dice_myo: 0.9101 - dice_lv: 0.9418 - mean_dice: 0.9196\n","Epoch 46: val_mean_dice did not improve from 0.82800\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0211 - dice_rv: 0.9068 - dice_myo: 0.9101 - dice_lv: 0.9418 - mean_dice: 0.9196 - val_loss: 0.0537 - val_dice_rv: 0.7655 - val_dice_myo: 0.8136 - val_dice_lv: 0.8917 - val_mean_dice: 0.8236 - lr: 0.0010\n","Epoch 47/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0211 - dice_rv: 0.9076 - dice_myo: 0.9114 - dice_lv: 0.9431 - mean_dice: 0.9207\n","Epoch 47: val_mean_dice did not improve from 0.82800\n","164/164 [==============================] - 94s 570ms/step - loss: 0.0211 - dice_rv: 0.9076 - dice_myo: 0.9114 - dice_lv: 0.9431 - mean_dice: 0.9207 - val_loss: 0.0615 - val_dice_rv: 0.7334 - val_dice_myo: 0.8120 - val_dice_lv: 0.8912 - val_mean_dice: 0.8122 - lr: 0.0010\n","Epoch 48/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0264 - dice_rv: 0.8652 - dice_myo: 0.8938 - dice_lv: 0.9330 - mean_dice: 0.8973\n","Epoch 48: val_mean_dice improved from 0.82800 to 0.83031, saving model to /content/weights/ckpt0.8303.h5\n","164/164 [==============================] - 95s 577ms/step - loss: 0.0264 - dice_rv: 0.8652 - dice_myo: 0.8938 - dice_lv: 0.9330 - mean_dice: 0.8973 - val_loss: 0.0494 - val_dice_rv: 0.7797 - val_dice_myo: 0.8230 - val_dice_lv: 0.8882 - val_mean_dice: 0.8303 - lr: 0.0010\n","Epoch 49/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0209 - dice_rv: 0.9112 - dice_myo: 0.9112 - dice_lv: 0.9429 - mean_dice: 0.9218\n","Epoch 49: val_mean_dice improved from 0.83031 to 0.83652, saving model to /content/weights/ckpt0.8365.h5\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0209 - dice_rv: 0.9112 - dice_myo: 0.9112 - dice_lv: 0.9429 - mean_dice: 0.9218 - val_loss: 0.0508 - val_dice_rv: 0.7866 - val_dice_myo: 0.8294 - val_dice_lv: 0.8936 - val_mean_dice: 0.8365 - lr: 0.0010\n","Epoch 50/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0198 - dice_rv: 0.9195 - dice_myo: 0.9150 - dice_lv: 0.9449 - mean_dice: 0.9265\n","Epoch 50: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0198 - dice_rv: 0.9195 - dice_myo: 0.9150 - dice_lv: 0.9449 - mean_dice: 0.9265 - val_loss: 0.0530 - val_dice_rv: 0.7748 - val_dice_myo: 0.8196 - val_dice_lv: 0.8936 - val_mean_dice: 0.8293 - lr: 0.0010\n","Epoch 51/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0194 - dice_rv: 0.9209 - dice_myo: 0.9167 - dice_lv: 0.9457 - mean_dice: 0.9278\n","Epoch 51: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0194 - dice_rv: 0.9209 - dice_myo: 0.9167 - dice_lv: 0.9457 - mean_dice: 0.9278 - val_loss: 0.0536 - val_dice_rv: 0.7775 - val_dice_myo: 0.8211 - val_dice_lv: 0.8874 - val_mean_dice: 0.8286 - lr: 0.0010\n","Epoch 52/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0193 - dice_rv: 0.9211 - dice_myo: 0.9159 - dice_lv: 0.9458 - mean_dice: 0.9276\n","Epoch 52: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0193 - dice_rv: 0.9211 - dice_myo: 0.9159 - dice_lv: 0.9458 - mean_dice: 0.9276 - val_loss: 0.0594 - val_dice_rv: 0.7686 - val_dice_myo: 0.8177 - val_dice_lv: 0.8839 - val_mean_dice: 0.8234 - lr: 0.0010\n","Epoch 53/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0192 - dice_rv: 0.9226 - dice_myo: 0.9167 - dice_lv: 0.9473 - mean_dice: 0.9289\n","Epoch 53: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0192 - dice_rv: 0.9226 - dice_myo: 0.9167 - dice_lv: 0.9473 - mean_dice: 0.9289 - val_loss: 0.0550 - val_dice_rv: 0.7752 - val_dice_myo: 0.8206 - val_dice_lv: 0.8909 - val_mean_dice: 0.8289 - lr: 0.0010\n","Epoch 54/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0186 - dice_rv: 0.9259 - dice_myo: 0.9205 - dice_lv: 0.9496 - mean_dice: 0.9320\n","Epoch 54: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0186 - dice_rv: 0.9259 - dice_myo: 0.9205 - dice_lv: 0.9496 - mean_dice: 0.9320 - val_loss: 0.0583 - val_dice_rv: 0.7594 - val_dice_myo: 0.8140 - val_dice_lv: 0.8842 - val_mean_dice: 0.8192 - lr: 0.0010\n","Epoch 55/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0185 - dice_rv: 0.9241 - dice_myo: 0.9202 - dice_lv: 0.9485 - mean_dice: 0.9309\n","Epoch 55: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0185 - dice_rv: 0.9241 - dice_myo: 0.9202 - dice_lv: 0.9485 - mean_dice: 0.9309 - val_loss: 0.0579 - val_dice_rv: 0.7662 - val_dice_myo: 0.8204 - val_dice_lv: 0.8898 - val_mean_dice: 0.8255 - lr: 0.0010\n","Epoch 56/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0190 - dice_rv: 0.9212 - dice_myo: 0.9175 - dice_lv: 0.9477 - mean_dice: 0.9288\n","Epoch 56: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0190 - dice_rv: 0.9212 - dice_myo: 0.9175 - dice_lv: 0.9477 - mean_dice: 0.9288 - val_loss: 0.0572 - val_dice_rv: 0.7469 - val_dice_myo: 0.8100 - val_dice_lv: 0.8857 - val_mean_dice: 0.8142 - lr: 0.0010\n","Epoch 57/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0208 - dice_rv: 0.9015 - dice_myo: 0.9129 - dice_lv: 0.9447 - mean_dice: 0.9197\n","Epoch 57: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0208 - dice_rv: 0.9015 - dice_myo: 0.9129 - dice_lv: 0.9447 - mean_dice: 0.9197 - val_loss: 0.0471 - val_dice_rv: 0.7348 - val_dice_myo: 0.8257 - val_dice_lv: 0.8883 - val_mean_dice: 0.8162 - lr: 0.0010\n","Epoch 58/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0216 - dice_rv: 0.8979 - dice_myo: 0.9072 - dice_lv: 0.9420 - mean_dice: 0.9157\n","Epoch 58: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0216 - dice_rv: 0.8979 - dice_myo: 0.9072 - dice_lv: 0.9420 - mean_dice: 0.9157 - val_loss: 0.0527 - val_dice_rv: 0.7786 - val_dice_myo: 0.8169 - val_dice_lv: 0.8921 - val_mean_dice: 0.8292 - lr: 0.0010\n","Epoch 59/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0187 - dice_rv: 0.9212 - dice_myo: 0.9194 - dice_lv: 0.9499 - mean_dice: 0.9301\n","Epoch 59: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0187 - dice_rv: 0.9212 - dice_myo: 0.9194 - dice_lv: 0.9499 - mean_dice: 0.9301 - val_loss: 0.0529 - val_dice_rv: 0.7647 - val_dice_myo: 0.8191 - val_dice_lv: 0.8943 - val_mean_dice: 0.8260 - lr: 0.0010\n","Epoch 60/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0178 - dice_rv: 0.9310 - dice_myo: 0.9234 - dice_lv: 0.9513 - mean_dice: 0.9352\n","Epoch 60: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0178 - dice_rv: 0.9310 - dice_myo: 0.9234 - dice_lv: 0.9513 - mean_dice: 0.9352 - val_loss: 0.0557 - val_dice_rv: 0.7593 - val_dice_myo: 0.8162 - val_dice_lv: 0.8919 - val_mean_dice: 0.8225 - lr: 0.0010\n","Epoch 61/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0174 - dice_rv: 0.9329 - dice_myo: 0.9249 - dice_lv: 0.9514 - mean_dice: 0.9364\n","Epoch 61: val_mean_dice did not improve from 0.83652\n","\n","Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0174 - dice_rv: 0.9329 - dice_myo: 0.9249 - dice_lv: 0.9514 - mean_dice: 0.9364 - val_loss: 0.0578 - val_dice_rv: 0.7760 - val_dice_myo: 0.8132 - val_dice_lv: 0.8854 - val_mean_dice: 0.8249 - lr: 0.0010\n","Epoch 62/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0164 - dice_rv: 0.9396 - dice_myo: 0.9303 - dice_lv: 0.9550 - mean_dice: 0.9416\n","Epoch 62: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 93s 565ms/step - loss: 0.0164 - dice_rv: 0.9396 - dice_myo: 0.9303 - dice_lv: 0.9550 - mean_dice: 0.9416 - val_loss: 0.0595 - val_dice_rv: 0.7608 - val_dice_myo: 0.8158 - val_dice_lv: 0.8926 - val_mean_dice: 0.8231 - lr: 5.0000e-04\n","Epoch 63/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0159 - dice_rv: 0.9426 - dice_myo: 0.9322 - dice_lv: 0.9567 - mean_dice: 0.9438\n","Epoch 63: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0159 - dice_rv: 0.9426 - dice_myo: 0.9322 - dice_lv: 0.9567 - mean_dice: 0.9438 - val_loss: 0.0622 - val_dice_rv: 0.7547 - val_dice_myo: 0.8128 - val_dice_lv: 0.8896 - val_mean_dice: 0.8190 - lr: 5.0000e-04\n","Epoch 64/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0156 - dice_rv: 0.9440 - dice_myo: 0.9331 - dice_lv: 0.9570 - mean_dice: 0.9447\n","Epoch 64: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0156 - dice_rv: 0.9440 - dice_myo: 0.9331 - dice_lv: 0.9570 - mean_dice: 0.9447 - val_loss: 0.0627 - val_dice_rv: 0.7599 - val_dice_myo: 0.8144 - val_dice_lv: 0.8863 - val_mean_dice: 0.8202 - lr: 5.0000e-04\n","Epoch 65/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0157 - dice_rv: 0.9416 - dice_myo: 0.9325 - dice_lv: 0.9571 - mean_dice: 0.9437\n","Epoch 65: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0157 - dice_rv: 0.9416 - dice_myo: 0.9325 - dice_lv: 0.9571 - mean_dice: 0.9437 - val_loss: 0.0635 - val_dice_rv: 0.7599 - val_dice_myo: 0.8148 - val_dice_lv: 0.8874 - val_mean_dice: 0.8207 - lr: 5.0000e-04\n","Epoch 66/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0155 - dice_rv: 0.9435 - dice_myo: 0.9332 - dice_lv: 0.9572 - mean_dice: 0.9446\n","Epoch 66: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 93s 567ms/step - loss: 0.0155 - dice_rv: 0.9435 - dice_myo: 0.9332 - dice_lv: 0.9572 - mean_dice: 0.9446 - val_loss: 0.0641 - val_dice_rv: 0.7708 - val_dice_myo: 0.8241 - val_dice_lv: 0.8870 - val_mean_dice: 0.8273 - lr: 5.0000e-04\n","Epoch 67/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0153 - dice_rv: 0.9447 - dice_myo: 0.9334 - dice_lv: 0.9566 - mean_dice: 0.9449\n","Epoch 67: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 93s 569ms/step - loss: 0.0153 - dice_rv: 0.9447 - dice_myo: 0.9334 - dice_lv: 0.9566 - mean_dice: 0.9449 - val_loss: 0.0661 - val_dice_rv: 0.7605 - val_dice_myo: 0.8145 - val_dice_lv: 0.8826 - val_mean_dice: 0.8192 - lr: 5.0000e-04\n","Epoch 68/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0153 - dice_rv: 0.9434 - dice_myo: 0.9335 - dice_lv: 0.9584 - mean_dice: 0.9451\n","Epoch 68: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0153 - dice_rv: 0.9434 - dice_myo: 0.9335 - dice_lv: 0.9584 - mean_dice: 0.9451 - val_loss: 0.0633 - val_dice_rv: 0.7477 - val_dice_myo: 0.8123 - val_dice_lv: 0.8872 - val_mean_dice: 0.8157 - lr: 5.0000e-04\n","Epoch 69/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0151 - dice_rv: 0.9462 - dice_myo: 0.9351 - dice_lv: 0.9584 - mean_dice: 0.9465\n","Epoch 69: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 93s 569ms/step - loss: 0.0151 - dice_rv: 0.9462 - dice_myo: 0.9351 - dice_lv: 0.9584 - mean_dice: 0.9465 - val_loss: 0.0664 - val_dice_rv: 0.7557 - val_dice_myo: 0.8149 - val_dice_lv: 0.8813 - val_mean_dice: 0.8173 - lr: 5.0000e-04\n","Epoch 70/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0151 - dice_rv: 0.9416 - dice_myo: 0.9348 - dice_lv: 0.9578 - mean_dice: 0.9447\n","Epoch 70: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 92s 564ms/step - loss: 0.0151 - dice_rv: 0.9416 - dice_myo: 0.9348 - dice_lv: 0.9578 - mean_dice: 0.9447 - val_loss: 0.0658 - val_dice_rv: 0.7678 - val_dice_myo: 0.8165 - val_dice_lv: 0.8865 - val_mean_dice: 0.8236 - lr: 5.0000e-04\n","Epoch 71/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0151 - dice_rv: 0.9448 - dice_myo: 0.9355 - dice_lv: 0.9590 - mean_dice: 0.9464\n","Epoch 71: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 93s 568ms/step - loss: 0.0151 - dice_rv: 0.9448 - dice_myo: 0.9355 - dice_lv: 0.9590 - mean_dice: 0.9464 - val_loss: 0.0651 - val_dice_rv: 0.7730 - val_dice_myo: 0.8168 - val_dice_lv: 0.8873 - val_mean_dice: 0.8257 - lr: 5.0000e-04\n","Epoch 72/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0149 - dice_rv: 0.9447 - dice_myo: 0.9352 - dice_lv: 0.9587 - mean_dice: 0.9462\n","Epoch 72: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0149 - dice_rv: 0.9447 - dice_myo: 0.9352 - dice_lv: 0.9587 - mean_dice: 0.9462 - val_loss: 0.0651 - val_dice_rv: 0.7634 - val_dice_myo: 0.8125 - val_dice_lv: 0.8864 - val_mean_dice: 0.8208 - lr: 5.0000e-04\n","Epoch 73/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0149 - dice_rv: 0.9460 - dice_myo: 0.9353 - dice_lv: 0.9587 - mean_dice: 0.9466\n","Epoch 73: val_mean_dice did not improve from 0.83652\n","\n","Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0149 - dice_rv: 0.9460 - dice_myo: 0.9353 - dice_lv: 0.9587 - mean_dice: 0.9466 - val_loss: 0.0622 - val_dice_rv: 0.7673 - val_dice_myo: 0.8157 - val_dice_lv: 0.8925 - val_mean_dice: 0.8251 - lr: 5.0000e-04\n","Epoch 74/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0143 - dice_rv: 0.9484 - dice_myo: 0.9384 - dice_lv: 0.9602 - mean_dice: 0.9490\n","Epoch 74: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 92s 563ms/step - loss: 0.0143 - dice_rv: 0.9484 - dice_myo: 0.9384 - dice_lv: 0.9602 - mean_dice: 0.9490 - val_loss: 0.0647 - val_dice_rv: 0.7619 - val_dice_myo: 0.8202 - val_dice_lv: 0.8898 - val_mean_dice: 0.8240 - lr: 2.5000e-04\n","Epoch 75/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0139 - dice_rv: 0.9508 - dice_myo: 0.9396 - dice_lv: 0.9604 - mean_dice: 0.9503\n","Epoch 75: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 93s 569ms/step - loss: 0.0139 - dice_rv: 0.9508 - dice_myo: 0.9396 - dice_lv: 0.9604 - mean_dice: 0.9503 - val_loss: 0.0654 - val_dice_rv: 0.7621 - val_dice_myo: 0.8173 - val_dice_lv: 0.8877 - val_mean_dice: 0.8223 - lr: 2.5000e-04\n","Epoch 76/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0139 - dice_rv: 0.9524 - dice_myo: 0.9400 - dice_lv: 0.9616 - mean_dice: 0.9513\n","Epoch 76: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0139 - dice_rv: 0.9524 - dice_myo: 0.9400 - dice_lv: 0.9616 - mean_dice: 0.9513 - val_loss: 0.0670 - val_dice_rv: 0.7669 - val_dice_myo: 0.8187 - val_dice_lv: 0.8901 - val_mean_dice: 0.8253 - lr: 2.5000e-04\n","Epoch 77/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0138 - dice_rv: 0.9511 - dice_myo: 0.9404 - dice_lv: 0.9621 - mean_dice: 0.9512\n","Epoch 77: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 93s 565ms/step - loss: 0.0138 - dice_rv: 0.9511 - dice_myo: 0.9404 - dice_lv: 0.9621 - mean_dice: 0.9512 - val_loss: 0.0671 - val_dice_rv: 0.7581 - val_dice_myo: 0.8180 - val_dice_lv: 0.8883 - val_mean_dice: 0.8215 - lr: 2.5000e-04\n","Epoch 78/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0137 - dice_rv: 0.9524 - dice_myo: 0.9402 - dice_lv: 0.9620 - mean_dice: 0.9515\n","Epoch 78: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 92s 562ms/step - loss: 0.0137 - dice_rv: 0.9524 - dice_myo: 0.9402 - dice_lv: 0.9620 - mean_dice: 0.9515 - val_loss: 0.0673 - val_dice_rv: 0.7753 - val_dice_myo: 0.8164 - val_dice_lv: 0.8877 - val_mean_dice: 0.8265 - lr: 2.5000e-04\n","Epoch 79/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0137 - dice_rv: 0.9506 - dice_myo: 0.9414 - dice_lv: 0.9628 - mean_dice: 0.9516\n","Epoch 79: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 93s 566ms/step - loss: 0.0137 - dice_rv: 0.9506 - dice_myo: 0.9414 - dice_lv: 0.9628 - mean_dice: 0.9516 - val_loss: 0.0663 - val_dice_rv: 0.7665 - val_dice_myo: 0.8184 - val_dice_lv: 0.8907 - val_mean_dice: 0.8252 - lr: 2.5000e-04\n","Epoch 80/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0136 - dice_rv: 0.9536 - dice_myo: 0.9417 - dice_lv: 0.9631 - mean_dice: 0.9528\n","Epoch 80: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0136 - dice_rv: 0.9536 - dice_myo: 0.9417 - dice_lv: 0.9631 - mean_dice: 0.9528 - val_loss: 0.0687 - val_dice_rv: 0.7658 - val_dice_myo: 0.8203 - val_dice_lv: 0.8871 - val_mean_dice: 0.8244 - lr: 2.5000e-04\n","Epoch 81/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0135 - dice_rv: 0.9522 - dice_myo: 0.9422 - dice_lv: 0.9630 - mean_dice: 0.9524\n","Epoch 81: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 571ms/step - loss: 0.0135 - dice_rv: 0.9522 - dice_myo: 0.9422 - dice_lv: 0.9630 - mean_dice: 0.9524 - val_loss: 0.0678 - val_dice_rv: 0.7583 - val_dice_myo: 0.8185 - val_dice_lv: 0.8917 - val_mean_dice: 0.8228 - lr: 2.5000e-04\n","Epoch 82/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0135 - dice_rv: 0.9515 - dice_myo: 0.9421 - dice_lv: 0.9632 - mean_dice: 0.9523\n","Epoch 82: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0135 - dice_rv: 0.9515 - dice_myo: 0.9421 - dice_lv: 0.9632 - mean_dice: 0.9523 - val_loss: 0.0671 - val_dice_rv: 0.7662 - val_dice_myo: 0.8148 - val_dice_lv: 0.8840 - val_mean_dice: 0.8217 - lr: 2.5000e-04\n","Epoch 83/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0134 - dice_rv: 0.9526 - dice_myo: 0.9422 - dice_lv: 0.9624 - mean_dice: 0.9524\n","Epoch 83: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 93s 568ms/step - loss: 0.0134 - dice_rv: 0.9526 - dice_myo: 0.9422 - dice_lv: 0.9624 - mean_dice: 0.9524 - val_loss: 0.0680 - val_dice_rv: 0.7650 - val_dice_myo: 0.8139 - val_dice_lv: 0.8831 - val_mean_dice: 0.8207 - lr: 2.5000e-04\n","Epoch 84/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0134 - dice_rv: 0.9530 - dice_myo: 0.9421 - dice_lv: 0.9635 - mean_dice: 0.9529\n","Epoch 84: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 93s 569ms/step - loss: 0.0134 - dice_rv: 0.9530 - dice_myo: 0.9421 - dice_lv: 0.9635 - mean_dice: 0.9529 - val_loss: 0.0680 - val_dice_rv: 0.7608 - val_dice_myo: 0.8147 - val_dice_lv: 0.8838 - val_mean_dice: 0.8198 - lr: 2.5000e-04\n","Epoch 85/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0133 - dice_rv: 0.9527 - dice_myo: 0.9418 - dice_lv: 0.9631 - mean_dice: 0.9525\n","Epoch 85: val_mean_dice did not improve from 0.83652\n","\n","Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","164/164 [==============================] - 93s 566ms/step - loss: 0.0133 - dice_rv: 0.9527 - dice_myo: 0.9418 - dice_lv: 0.9631 - mean_dice: 0.9525 - val_loss: 0.0684 - val_dice_rv: 0.7677 - val_dice_myo: 0.8158 - val_dice_lv: 0.8840 - val_mean_dice: 0.8225 - lr: 2.5000e-04\n","Epoch 86/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0130 - dice_rv: 0.9542 - dice_myo: 0.9434 - dice_lv: 0.9637 - mean_dice: 0.9538\n","Epoch 86: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 92s 564ms/step - loss: 0.0130 - dice_rv: 0.9542 - dice_myo: 0.9434 - dice_lv: 0.9637 - mean_dice: 0.9538 - val_loss: 0.0691 - val_dice_rv: 0.7657 - val_dice_myo: 0.8152 - val_dice_lv: 0.8871 - val_mean_dice: 0.8227 - lr: 1.2500e-04\n","Epoch 87/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0129 - dice_rv: 0.9562 - dice_myo: 0.9443 - dice_lv: 0.9640 - mean_dice: 0.9548\n","Epoch 87: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0129 - dice_rv: 0.9562 - dice_myo: 0.9443 - dice_lv: 0.9640 - mean_dice: 0.9548 - val_loss: 0.0701 - val_dice_rv: 0.7631 - val_dice_myo: 0.8131 - val_dice_lv: 0.8818 - val_mean_dice: 0.8193 - lr: 1.2500e-04\n","Epoch 88/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0128 - dice_rv: 0.9558 - dice_myo: 0.9447 - dice_lv: 0.9638 - mean_dice: 0.9548\n","Epoch 88: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0128 - dice_rv: 0.9558 - dice_myo: 0.9447 - dice_lv: 0.9638 - mean_dice: 0.9548 - val_loss: 0.0703 - val_dice_rv: 0.7646 - val_dice_myo: 0.8146 - val_dice_lv: 0.8828 - val_mean_dice: 0.8206 - lr: 1.2500e-04\n","Epoch 89/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0128 - dice_rv: 0.9558 - dice_myo: 0.9447 - dice_lv: 0.9644 - mean_dice: 0.9550\n","Epoch 89: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0128 - dice_rv: 0.9558 - dice_myo: 0.9447 - dice_lv: 0.9644 - mean_dice: 0.9550 - val_loss: 0.0704 - val_dice_rv: 0.7617 - val_dice_myo: 0.8139 - val_dice_lv: 0.8843 - val_mean_dice: 0.8200 - lr: 1.2500e-04\n","Epoch 90/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0128 - dice_rv: 0.9564 - dice_myo: 0.9451 - dice_lv: 0.9652 - mean_dice: 0.9556\n","Epoch 90: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0128 - dice_rv: 0.9564 - dice_myo: 0.9451 - dice_lv: 0.9652 - mean_dice: 0.9556 - val_loss: 0.0708 - val_dice_rv: 0.7572 - val_dice_myo: 0.8137 - val_dice_lv: 0.8857 - val_mean_dice: 0.8189 - lr: 1.2500e-04\n","Epoch 91/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0127 - dice_rv: 0.9562 - dice_myo: 0.9451 - dice_lv: 0.9647 - mean_dice: 0.9553\n","Epoch 91: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0127 - dice_rv: 0.9562 - dice_myo: 0.9451 - dice_lv: 0.9647 - mean_dice: 0.9553 - val_loss: 0.0711 - val_dice_rv: 0.7607 - val_dice_myo: 0.8176 - val_dice_lv: 0.8879 - val_mean_dice: 0.8221 - lr: 1.2500e-04\n","Epoch 92/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0127 - dice_rv: 0.9562 - dice_myo: 0.9449 - dice_lv: 0.9645 - mean_dice: 0.9552\n","Epoch 92: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0127 - dice_rv: 0.9562 - dice_myo: 0.9449 - dice_lv: 0.9645 - mean_dice: 0.9552 - val_loss: 0.0704 - val_dice_rv: 0.7609 - val_dice_myo: 0.8133 - val_dice_lv: 0.8829 - val_mean_dice: 0.8190 - lr: 1.2500e-04\n","Epoch 93/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0126 - dice_rv: 0.9563 - dice_myo: 0.9453 - dice_lv: 0.9643 - mean_dice: 0.9553\n","Epoch 93: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0126 - dice_rv: 0.9563 - dice_myo: 0.9453 - dice_lv: 0.9643 - mean_dice: 0.9553 - val_loss: 0.0721 - val_dice_rv: 0.7644 - val_dice_myo: 0.8147 - val_dice_lv: 0.8840 - val_mean_dice: 0.8210 - lr: 1.2500e-04\n","Epoch 94/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0126 - dice_rv: 0.9552 - dice_myo: 0.9453 - dice_lv: 0.9651 - mean_dice: 0.9552\n","Epoch 94: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0126 - dice_rv: 0.9552 - dice_myo: 0.9453 - dice_lv: 0.9651 - mean_dice: 0.9552 - val_loss: 0.0705 - val_dice_rv: 0.7670 - val_dice_myo: 0.8141 - val_dice_lv: 0.8849 - val_mean_dice: 0.8220 - lr: 1.2500e-04\n","Epoch 95/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0126 - dice_rv: 0.9565 - dice_myo: 0.9455 - dice_lv: 0.9652 - mean_dice: 0.9557\n","Epoch 95: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0126 - dice_rv: 0.9565 - dice_myo: 0.9455 - dice_lv: 0.9652 - mean_dice: 0.9557 - val_loss: 0.0730 - val_dice_rv: 0.7621 - val_dice_myo: 0.8164 - val_dice_lv: 0.8875 - val_mean_dice: 0.8220 - lr: 1.2500e-04\n","Epoch 96/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0125 - dice_rv: 0.9581 - dice_myo: 0.9449 - dice_lv: 0.9652 - mean_dice: 0.9561\n","Epoch 96: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0125 - dice_rv: 0.9581 - dice_myo: 0.9449 - dice_lv: 0.9652 - mean_dice: 0.9561 - val_loss: 0.0731 - val_dice_rv: 0.7630 - val_dice_myo: 0.8123 - val_dice_lv: 0.8859 - val_mean_dice: 0.8204 - lr: 1.2500e-04\n","Epoch 97/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0125 - dice_rv: 0.9564 - dice_myo: 0.9458 - dice_lv: 0.9653 - mean_dice: 0.9558\n","Epoch 97: val_mean_dice did not improve from 0.83652\n","\n","Epoch 97: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0125 - dice_rv: 0.9564 - dice_myo: 0.9458 - dice_lv: 0.9653 - mean_dice: 0.9558 - val_loss: 0.0719 - val_dice_rv: 0.7693 - val_dice_myo: 0.8147 - val_dice_lv: 0.8848 - val_mean_dice: 0.8229 - lr: 1.2500e-04\n","Epoch 98/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0124 - dice_rv: 0.9565 - dice_myo: 0.9467 - dice_lv: 0.9654 - mean_dice: 0.9562\n","Epoch 98: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0124 - dice_rv: 0.9565 - dice_myo: 0.9467 - dice_lv: 0.9654 - mean_dice: 0.9562 - val_loss: 0.0723 - val_dice_rv: 0.7638 - val_dice_myo: 0.8132 - val_dice_lv: 0.8846 - val_mean_dice: 0.8205 - lr: 6.2500e-05\n","Epoch 99/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0123 - dice_rv: 0.9580 - dice_myo: 0.9468 - dice_lv: 0.9664 - mean_dice: 0.9571\n","Epoch 99: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0123 - dice_rv: 0.9580 - dice_myo: 0.9468 - dice_lv: 0.9664 - mean_dice: 0.9571 - val_loss: 0.0726 - val_dice_rv: 0.7636 - val_dice_myo: 0.8126 - val_dice_lv: 0.8855 - val_mean_dice: 0.8206 - lr: 6.2500e-05\n","Epoch 100/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0123 - dice_rv: 0.9574 - dice_myo: 0.9469 - dice_lv: 0.9658 - mean_dice: 0.9567\n","Epoch 100: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0123 - dice_rv: 0.9574 - dice_myo: 0.9469 - dice_lv: 0.9658 - mean_dice: 0.9567 - val_loss: 0.0722 - val_dice_rv: 0.7627 - val_dice_myo: 0.8126 - val_dice_lv: 0.8837 - val_mean_dice: 0.8197 - lr: 6.2500e-05\n","Epoch 101/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0122 - dice_rv: 0.9590 - dice_myo: 0.9470 - dice_lv: 0.9668 - mean_dice: 0.9576\n","Epoch 101: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0122 - dice_rv: 0.9590 - dice_myo: 0.9470 - dice_lv: 0.9668 - mean_dice: 0.9576 - val_loss: 0.0732 - val_dice_rv: 0.7615 - val_dice_myo: 0.8128 - val_dice_lv: 0.8863 - val_mean_dice: 0.8202 - lr: 6.2500e-05\n","Epoch 102/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0123 - dice_rv: 0.9577 - dice_myo: 0.9473 - dice_lv: 0.9662 - mean_dice: 0.9571\n","Epoch 102: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0123 - dice_rv: 0.9577 - dice_myo: 0.9473 - dice_lv: 0.9662 - mean_dice: 0.9571 - val_loss: 0.0722 - val_dice_rv: 0.7632 - val_dice_myo: 0.8130 - val_dice_lv: 0.8873 - val_mean_dice: 0.8212 - lr: 6.2500e-05\n","Epoch 103/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0122 - dice_rv: 0.9582 - dice_myo: 0.9474 - dice_lv: 0.9664 - mean_dice: 0.9573\n","Epoch 103: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0122 - dice_rv: 0.9582 - dice_myo: 0.9474 - dice_lv: 0.9664 - mean_dice: 0.9573 - val_loss: 0.0734 - val_dice_rv: 0.7637 - val_dice_myo: 0.8126 - val_dice_lv: 0.8845 - val_mean_dice: 0.8203 - lr: 6.2500e-05\n","Epoch 104/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0122 - dice_rv: 0.9585 - dice_myo: 0.9472 - dice_lv: 0.9666 - mean_dice: 0.9574\n","Epoch 104: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0122 - dice_rv: 0.9585 - dice_myo: 0.9472 - dice_lv: 0.9666 - mean_dice: 0.9574 - val_loss: 0.0729 - val_dice_rv: 0.7627 - val_dice_myo: 0.8130 - val_dice_lv: 0.8864 - val_mean_dice: 0.8207 - lr: 6.2500e-05\n","Epoch 105/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0122 - dice_rv: 0.9588 - dice_myo: 0.9473 - dice_lv: 0.9664 - mean_dice: 0.9575\n","Epoch 105: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0122 - dice_rv: 0.9588 - dice_myo: 0.9473 - dice_lv: 0.9664 - mean_dice: 0.9575 - val_loss: 0.0733 - val_dice_rv: 0.7644 - val_dice_myo: 0.8126 - val_dice_lv: 0.8850 - val_mean_dice: 0.8207 - lr: 6.2500e-05\n","Epoch 106/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0122 - dice_rv: 0.9578 - dice_myo: 0.9471 - dice_lv: 0.9667 - mean_dice: 0.9572\n","Epoch 106: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0122 - dice_rv: 0.9578 - dice_myo: 0.9471 - dice_lv: 0.9667 - mean_dice: 0.9572 - val_loss: 0.0729 - val_dice_rv: 0.7632 - val_dice_myo: 0.8127 - val_dice_lv: 0.8887 - val_mean_dice: 0.8215 - lr: 6.2500e-05\n","Epoch 107/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0121 - dice_rv: 0.9578 - dice_myo: 0.9474 - dice_lv: 0.9669 - mean_dice: 0.9573\n","Epoch 107: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0121 - dice_rv: 0.9578 - dice_myo: 0.9474 - dice_lv: 0.9669 - mean_dice: 0.9573 - val_loss: 0.0732 - val_dice_rv: 0.7646 - val_dice_myo: 0.8130 - val_dice_lv: 0.8865 - val_mean_dice: 0.8214 - lr: 6.2500e-05\n","Epoch 108/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0122 - dice_rv: 0.9581 - dice_myo: 0.9476 - dice_lv: 0.9672 - mean_dice: 0.9576\n","Epoch 108: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0122 - dice_rv: 0.9581 - dice_myo: 0.9476 - dice_lv: 0.9672 - mean_dice: 0.9576 - val_loss: 0.0735 - val_dice_rv: 0.7641 - val_dice_myo: 0.8127 - val_dice_lv: 0.8861 - val_mean_dice: 0.8210 - lr: 6.2500e-05\n","Epoch 109/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0121 - dice_rv: 0.9599 - dice_myo: 0.9480 - dice_lv: 0.9668 - mean_dice: 0.9583\n","Epoch 109: val_mean_dice did not improve from 0.83652\n","\n","Epoch 109: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0121 - dice_rv: 0.9599 - dice_myo: 0.9480 - dice_lv: 0.9668 - mean_dice: 0.9583 - val_loss: 0.0739 - val_dice_rv: 0.7668 - val_dice_myo: 0.8131 - val_dice_lv: 0.8837 - val_mean_dice: 0.8212 - lr: 6.2500e-05\n","Epoch 110/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0120 - dice_rv: 0.9596 - dice_myo: 0.9482 - dice_lv: 0.9674 - mean_dice: 0.9584\n","Epoch 110: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0120 - dice_rv: 0.9596 - dice_myo: 0.9482 - dice_lv: 0.9674 - mean_dice: 0.9584 - val_loss: 0.0737 - val_dice_rv: 0.7676 - val_dice_myo: 0.8127 - val_dice_lv: 0.8865 - val_mean_dice: 0.8223 - lr: 3.1250e-05\n","Epoch 111/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0120 - dice_rv: 0.9596 - dice_myo: 0.9485 - dice_lv: 0.9672 - mean_dice: 0.9584\n","Epoch 111: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0120 - dice_rv: 0.9596 - dice_myo: 0.9485 - dice_lv: 0.9672 - mean_dice: 0.9584 - val_loss: 0.0742 - val_dice_rv: 0.7737 - val_dice_myo: 0.8129 - val_dice_lv: 0.8872 - val_mean_dice: 0.8246 - lr: 3.1250e-05\n","Epoch 112/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0120 - dice_rv: 0.9589 - dice_myo: 0.9482 - dice_lv: 0.9679 - mean_dice: 0.9583\n","Epoch 112: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0120 - dice_rv: 0.9589 - dice_myo: 0.9482 - dice_lv: 0.9679 - mean_dice: 0.9583 - val_loss: 0.0747 - val_dice_rv: 0.7664 - val_dice_myo: 0.8137 - val_dice_lv: 0.8839 - val_mean_dice: 0.8213 - lr: 3.1250e-05\n","Epoch 113/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0120 - dice_rv: 0.9596 - dice_myo: 0.9485 - dice_lv: 0.9676 - mean_dice: 0.9586\n","Epoch 113: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0120 - dice_rv: 0.9596 - dice_myo: 0.9485 - dice_lv: 0.9676 - mean_dice: 0.9586 - val_loss: 0.0747 - val_dice_rv: 0.7661 - val_dice_myo: 0.8135 - val_dice_lv: 0.8868 - val_mean_dice: 0.8221 - lr: 3.1250e-05\n","Epoch 114/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0120 - dice_rv: 0.9602 - dice_myo: 0.9482 - dice_lv: 0.9672 - mean_dice: 0.9585\n","Epoch 114: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0120 - dice_rv: 0.9602 - dice_myo: 0.9482 - dice_lv: 0.9672 - mean_dice: 0.9585 - val_loss: 0.0745 - val_dice_rv: 0.7695 - val_dice_myo: 0.8130 - val_dice_lv: 0.8839 - val_mean_dice: 0.8221 - lr: 3.1250e-05\n","Epoch 115/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0120 - dice_rv: 0.9601 - dice_myo: 0.9483 - dice_lv: 0.9672 - mean_dice: 0.9585\n","Epoch 115: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0120 - dice_rv: 0.9601 - dice_myo: 0.9483 - dice_lv: 0.9672 - mean_dice: 0.9585 - val_loss: 0.0746 - val_dice_rv: 0.7651 - val_dice_myo: 0.8121 - val_dice_lv: 0.8861 - val_mean_dice: 0.8211 - lr: 3.1250e-05\n","Epoch 116/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0120 - dice_rv: 0.9592 - dice_myo: 0.9479 - dice_lv: 0.9664 - mean_dice: 0.9578\n","Epoch 116: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0120 - dice_rv: 0.9592 - dice_myo: 0.9479 - dice_lv: 0.9664 - mean_dice: 0.9578 - val_loss: 0.0751 - val_dice_rv: 0.7684 - val_dice_myo: 0.8129 - val_dice_lv: 0.8865 - val_mean_dice: 0.8226 - lr: 3.1250e-05\n","Epoch 117/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0119 - dice_rv: 0.9604 - dice_myo: 0.9485 - dice_lv: 0.9672 - mean_dice: 0.9587\n","Epoch 117: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0119 - dice_rv: 0.9604 - dice_myo: 0.9485 - dice_lv: 0.9672 - mean_dice: 0.9587 - val_loss: 0.0747 - val_dice_rv: 0.7708 - val_dice_myo: 0.8125 - val_dice_lv: 0.8863 - val_mean_dice: 0.8232 - lr: 3.1250e-05\n","Epoch 118/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0119 - dice_rv: 0.9593 - dice_myo: 0.9483 - dice_lv: 0.9664 - mean_dice: 0.9580\n","Epoch 118: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0119 - dice_rv: 0.9593 - dice_myo: 0.9483 - dice_lv: 0.9664 - mean_dice: 0.9580 - val_loss: 0.0753 - val_dice_rv: 0.7719 - val_dice_myo: 0.8119 - val_dice_lv: 0.8867 - val_mean_dice: 0.8235 - lr: 3.1250e-05\n","Epoch 119/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0119 - dice_rv: 0.9600 - dice_myo: 0.9484 - dice_lv: 0.9670 - mean_dice: 0.9585\n","Epoch 119: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0119 - dice_rv: 0.9600 - dice_myo: 0.9484 - dice_lv: 0.9670 - mean_dice: 0.9585 - val_loss: 0.0748 - val_dice_rv: 0.7610 - val_dice_myo: 0.8120 - val_dice_lv: 0.8836 - val_mean_dice: 0.8188 - lr: 3.1250e-05\n","Epoch 120/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0119 - dice_rv: 0.9602 - dice_myo: 0.9486 - dice_lv: 0.9669 - mean_dice: 0.9586\n","Epoch 120: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0119 - dice_rv: 0.9602 - dice_myo: 0.9486 - dice_lv: 0.9669 - mean_dice: 0.9586 - val_loss: 0.0751 - val_dice_rv: 0.7671 - val_dice_myo: 0.8131 - val_dice_lv: 0.8865 - val_mean_dice: 0.8222 - lr: 3.1250e-05\n","Epoch 121/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0119 - dice_rv: 0.9593 - dice_myo: 0.9483 - dice_lv: 0.9673 - mean_dice: 0.9583\n","Epoch 121: val_mean_dice did not improve from 0.83652\n","\n","Epoch 121: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0119 - dice_rv: 0.9593 - dice_myo: 0.9483 - dice_lv: 0.9673 - mean_dice: 0.9583 - val_loss: 0.0752 - val_dice_rv: 0.7682 - val_dice_myo: 0.8128 - val_dice_lv: 0.8861 - val_mean_dice: 0.8224 - lr: 3.1250e-05\n","Epoch 122/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0119 - dice_rv: 0.9594 - dice_myo: 0.9486 - dice_lv: 0.9671 - mean_dice: 0.9584\n","Epoch 122: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0119 - dice_rv: 0.9594 - dice_myo: 0.9486 - dice_lv: 0.9671 - mean_dice: 0.9584 - val_loss: 0.0751 - val_dice_rv: 0.7686 - val_dice_myo: 0.8123 - val_dice_lv: 0.8863 - val_mean_dice: 0.8224 - lr: 1.5625e-05\n","Epoch 123/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0119 - dice_rv: 0.9591 - dice_myo: 0.9488 - dice_lv: 0.9676 - mean_dice: 0.9585\n","Epoch 123: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0119 - dice_rv: 0.9591 - dice_myo: 0.9488 - dice_lv: 0.9676 - mean_dice: 0.9585 - val_loss: 0.0753 - val_dice_rv: 0.7661 - val_dice_myo: 0.8126 - val_dice_lv: 0.8859 - val_mean_dice: 0.8215 - lr: 1.5625e-05\n","Epoch 124/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0119 - dice_rv: 0.9606 - dice_myo: 0.9488 - dice_lv: 0.9667 - mean_dice: 0.9587\n","Epoch 124: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0119 - dice_rv: 0.9606 - dice_myo: 0.9488 - dice_lv: 0.9667 - mean_dice: 0.9587 - val_loss: 0.0754 - val_dice_rv: 0.7701 - val_dice_myo: 0.8129 - val_dice_lv: 0.8870 - val_mean_dice: 0.8233 - lr: 1.5625e-05\n","Epoch 125/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0119 - dice_rv: 0.9594 - dice_myo: 0.9483 - dice_lv: 0.9674 - mean_dice: 0.9584\n","Epoch 125: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 574ms/step - loss: 0.0119 - dice_rv: 0.9594 - dice_myo: 0.9483 - dice_lv: 0.9674 - mean_dice: 0.9584 - val_loss: 0.0753 - val_dice_rv: 0.7693 - val_dice_myo: 0.8131 - val_dice_lv: 0.8864 - val_mean_dice: 0.8229 - lr: 1.5625e-05\n","Epoch 126/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0119 - dice_rv: 0.9586 - dice_myo: 0.9483 - dice_lv: 0.9672 - mean_dice: 0.9580\n","Epoch 126: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 572ms/step - loss: 0.0119 - dice_rv: 0.9586 - dice_myo: 0.9483 - dice_lv: 0.9672 - mean_dice: 0.9580 - val_loss: 0.0753 - val_dice_rv: 0.7700 - val_dice_myo: 0.8122 - val_dice_lv: 0.8862 - val_mean_dice: 0.8228 - lr: 1.5625e-05\n","Epoch 127/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0118 - dice_rv: 0.9605 - dice_myo: 0.9485 - dice_lv: 0.9676 - mean_dice: 0.9589\n","Epoch 127: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0118 - dice_rv: 0.9605 - dice_myo: 0.9485 - dice_lv: 0.9676 - mean_dice: 0.9589 - val_loss: 0.0758 - val_dice_rv: 0.7682 - val_dice_myo: 0.8129 - val_dice_lv: 0.8843 - val_mean_dice: 0.8218 - lr: 1.5625e-05\n","Epoch 128/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0118 - dice_rv: 0.9584 - dice_myo: 0.9491 - dice_lv: 0.9672 - mean_dice: 0.9582\n","Epoch 128: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 573ms/step - loss: 0.0118 - dice_rv: 0.9584 - dice_myo: 0.9491 - dice_lv: 0.9672 - mean_dice: 0.9582 - val_loss: 0.0757 - val_dice_rv: 0.7660 - val_dice_myo: 0.8127 - val_dice_lv: 0.8839 - val_mean_dice: 0.8209 - lr: 1.5625e-05\n","Epoch 129/500\n","164/164 [==============================] - ETA: 0s - loss: 0.0118 - dice_rv: 0.9604 - dice_myo: 0.9484 - dice_lv: 0.9678 - mean_dice: 0.9589\n","Epoch 129: val_mean_dice did not improve from 0.83652\n","164/164 [==============================] - 94s 575ms/step - loss: 0.0118 - dice_rv: 0.9604 - dice_myo: 0.9484 - dice_lv: 0.9678 - mean_dice: 0.9589 - val_loss: 0.0756 - val_dice_rv: 0.7678 - val_dice_myo: 0.8125 - val_dice_lv: 0.8866 - val_mean_dice: 0.8223 - lr: 1.5625e-05\n","Epoch 130/500\n","145/164 [=========================>....] - ETA: 10s - loss: 0.0118 - dice_rv: 0.9589 - dice_myo: 0.9489 - dice_lv: 0.9672 - mean_dice: 0.9583"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-567480cca301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.fit(train_dataset, epochs = 500, callbacks=[checkpointer, reduce_lr], validation_data=test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eaQBiacoouCm"},"outputs":[],"source":["model.save_weights(\"/content/weights/last_weight.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OEd3EV8_jgUU","outputId":"ba4bcfbe-6de4-4632-c99c-28318fd8bf4f"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_31a99338-99bc-4666-b6c0-37cb879cfe79\", \"ckpt0.8323.h5\", 48187296)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_bbcb26d0-a863-4584-be83-8e9ae4ee272f\", \"ckpt0.8270.h5\", 48187296)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_48902ff1-7c0b-4a3e-9e2e-6411241b8cb0\", \"ckpt0.8266.h5\", 48187296)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_e36e47d5-bbb3-4d43-befe-d0090688adfd\", \"ckpt0.8243.h5\", 48187296)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_e0d9c120-9f04-43a7-acd6-d52358f26348\", \"ckpt0.8221.h5\", 48187296)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_93b0ba73-aa08-4723-b48f-9b4e0df4083a\", \"ckpt0.8190.h5\", 48187296)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["a = sorted(glob.glob(\"/content/weights/*\"))\n","from google.colab import files\n","for i in range(1, 7):\n","    files.download(a[-i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiKZ9afi7WSM"},"outputs":[],"source":["files.download(a[-2])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7917,"status":"ok","timestamp":1668749320883,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"VZBSnMhDpgW-","outputId":"d0bd5a65-397d-4b80-ea69-835464946140"},"outputs":[{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 8s 118ms/step - loss: 0.0623 - dice_rv: 0.7890 - dice_myo: 0.8220 - dice_lv: 0.8803 - mean_dice: 0.8305\n"]},{"data":{"text/plain":["[0.062341056764125824,\n"," 0.7889867424964905,\n"," 0.8220412135124207,\n"," 0.8803408741950989,\n"," 0.8304561972618103]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate(test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"6sgv6lFefrj8"},"source":["## evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B6qZDxQKf1Yi"},"outputs":[],"source":["def dice_volume_rv(y_true, y_pred, smooth = 1e-5):\n","    y_pred = np.where(y_pred == 1, 1., 0.)\n","    y_true = np.where(y_true == 1, 1., 0.)\n","    intersection = np.sum(y_true * y_pred)\n","    cardinality  = np.sum(y_true + y_pred)\n","    return (2. * intersection + smooth) / (cardinality + smooth)\n","\n","def dice_volume_myo(y_true, y_pred, smooth = 1e-5):\n","    y_pred = np.where(y_pred == 2, 1., 0.)\n","    y_true = np.where(y_true == 2, 1., 0.)\n","    intersection = np.sum(y_true * y_pred)\n","    cardinality  = np.sum(y_true + y_pred)\n","    return (2. * intersection + smooth) / (cardinality + smooth)\n","\n","def dice_volume_lv(y_true, y_pred, smooth = 1e-5):\n","    y_pred = np.where(y_pred == 3, 1., 0.)\n","    y_true = np.where(y_true == 3, 1., 0.)\n","    intersection = np.sum(y_true * y_pred)\n","    cardinality  = np.sum(y_true + y_pred)\n","    return (2. * intersection + smooth) / (cardinality + smooth)\n","def center_crop(img, crop_size = (128, 128)):\n","    img_crop = np.zeros(crop_size)\n","    w_in, h_in, d_in = img.shape\n","    img_crop = np.zeros((*crop_size,d_in))\n","    w_out, h_out = crop_size\n","    sub_w = max((w_in - w_out)//2-20, 0)\n","    sub_h = max((h_in - h_out)//2-8, 0)\n","    \n","    img_clone = img[sub_w:sub_w+w_out, sub_h:sub_h+h_out]\n","    img_crop[:img_clone.shape[0], :img_clone.shape[1]] = img_clone\n","    return img_crop\n","\n","def iou_volume_rv(y_true, y_pred, smooth = 1e-5):\n","    y_pred = np.where(y_pred == 1, 1., 0.)\n","    y_true = np.where(y_true == 1, 1., 0.)\n","    intersection = np.sum(y_true * y_pred)\n","    cardinality  = np.sum(y_true + y_pred) - intersection\n","    return (intersection + smooth) / (cardinality + smooth)\n","\n","def iou_volume_myo(y_true, y_pred, smooth = 1e-5):\n","    y_pred = np.where(y_pred == 2, 1., 0.)\n","    y_true = np.where(y_true == 2, 1., 0.)\n","    intersection = np.sum(y_true * y_pred)\n","    cardinality  = np.sum(y_true + y_pred) - intersection\n","    return (intersection + smooth) / (cardinality + smooth)\n","\n","def iou_volume_lv(y_true, y_pred, smooth = 1e-5):\n","    y_pred = np.where(y_pred == 3, 1., 0.)\n","    y_true = np.where(y_true == 3, 1., 0.)\n","    intersection = np.sum(y_true * y_pred)\n","    cardinality  = np.sum(y_true + y_pred) - intersection\n","    return (intersection + smooth) / (cardinality + smooth)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4932,"status":"ok","timestamp":1669453034452,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"r8_ELlM5f2AS","outputId":"6374110b-6420-41c0-e1dc-b78899473113"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|| 1/1 [00:04<00:00,  4.72s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"," best weight is: /content/weights/ckpt0.8297.h5 with max mean dice :0.9044990590989276, \n"," dice_rv:0.8953302790291549, dice_myo:0.8766990754238778, dice_lv:0.9414678228437501, \n"," hd_rv:11.926268878540682, hd_myo:8.23042546011208, hd_lv: 8.15082805653686, mean_hd:9.43584079839654 \n"," iou_rv:0.8181425526795977, iou_myo:0.7825662653344263, iou_lv:0.8916206799098016, mean_iou:0.8307764993079418\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["%cd \"/content/drive/MyDrive/brain_mri_segmentation\"\n","all_files = sorted(glob.glob(\"./dataACDCA/training/*\"))\n","np.random.seed(42)\n","np.random.shuffle(all_files)\n","train_count = 70\n","train_files = all_files[:train_count]\n","test_files = all_files[train_count : train_count + 10]+all_files[-10:]\n","valid_files = all_files[train_count + 10: train_count + 20]\n","weight_path = sorted(glob.glob(\"/content/weights/*\"), reverse=True)\n","max_score = 0\n","max_dice_rv, max_dice_myo, max_dice_lv = 0, 0, 0\n","best_weight = \"\"\n","list_iou_rv, list_iou_myo, list_iou_lv = [], [], []\n","\n","# em muon evaluate 1 weight hay top k-weight thi em chinh dong nay nhe\n","# anh dang de evaluate top 10 weight RV\n","k = 10\n","weight_path = [\"/content/weights/ckpt0.8297.h5\"]\n","\n","for weight in tqdm(weight_path[:k]):\n","    \n","    model.load_weights(weight)\n","    mask_predict = np.argmax(model.predict(x_test), axis=-1)\n","    list_rv, list_myo, list_lv, hausdorff_distance_list = [], [], [], []\n","    count = 0\n","\n","    for files in test_files:\n","        list_image = [x for x in glob.glob(files+\"/*\") if x.find('frame') != -1 and x.find('gt') == -1]\n","        for image_name in list_image:\n","            num = image_name.find(\"nii\")\n","            mask_name = image_name[:num-1] +\"_gt.nii.gz\" \n","            image = nib.load(image_name).get_fdata().astype(np.uint16)\n","            label = nib.load(mask_name).get_fdata().astype(np.uint8)\n","            image = center_crop(image)\n","            label = center_crop(label)\n","            label_pred = np.zeros_like(label)\n","            for z in range(label.shape[-1]):\n","                label_pred[..., z] = mask_predict[count]\n","                count += 1\n","            list_rv.append(dice_volume_rv(label, label_pred))\n","            list_myo.append(dice_volume_myo(label, label_pred))\n","            list_lv.append(dice_volume_lv(label, label_pred))\n","            list_iou_rv.append(iou_volume_rv(label, label_pred))\n","            list_iou_myo.append(iou_volume_myo(label, label_pred))\n","            list_iou_lv.append(iou_volume_lv(label, label_pred))\n","            hausdorff_distance_list.append(hausdorff_distance(label[None], label_pred[None], 100).numpy()[0])\n","\n","    hausdorff_distance_list = np.stack(hausdorff_distance_list)\n","    diceRV = np.mean(list_rv)\n","    diceMYO = np.mean(list_myo)\n","    diceLV = np.mean(list_lv)\n","\n","    iouRV = np.mean(list_iou_rv)\n","    iouMYO = np.mean(list_iou_myo)\n","    iouLV = np.mean(list_iou_lv)\n","\n","    dice_ave = np.mean([diceRV, diceMYO, diceLV])\n","    clear_output()\n","\n","    if max_score < dice_ave:\n","        max_dice_rv, max_dice_myo, max_dice_lv = diceRV, diceMYO, diceLV\n","        max_iou_rv, max_iou_myo, max_iou_lv = iouRV, iouMYO, iouLV\n","        min_hd_rv, min_hd_myo, min_hd_lv = np.mean(hausdorff_distance_list, 0)\n","\n","        mean_hd = np.mean([min_hd_rv, min_hd_myo, min_hd_lv])\n","        mean_iou = np.mean([max_iou_rv, max_iou_myo, max_iou_lv])\n","        max_score = dice_ave\n","\n","        best_weight = weight\n","print(f\"\\n best weight is: {best_weight} with max mean dice :{max_score}, \\n \\\n","dice_rv:{max_dice_rv}, dice_myo:{max_dice_myo}, dice_lv:{max_dice_lv}, \\n hd_rv:{min_hd_rv}, \\\n","hd_myo:{min_hd_myo}, hd_lv: {min_hd_lv}, mean_hd:{mean_hd} \\n \\\n","iou_rv:{max_iou_rv}, iou_myo:{max_iou_myo}, iou_lv:{max_iou_lv}, mean_iou:{mean_iou}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1668749183370,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"ac8DIpKMD97S","outputId":"2e9b7489-a8c6-4342-db95-29839d609062"},"outputs":[{"data":{"text/plain":["(1, 128, 128, 8)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["label[None].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1668749183371,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"},"user_tz":-420},"id":"Rj9Ey92q80Tt","outputId":"3e8ad16b-eb7a-48d8-9960-4c6891aa614f"},"outputs":[{"data":{"text/plain":["(1, 128, 128, 8)"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["label_pred[None].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KssLVfAM857t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669453245886,"user_tz":-420,"elapsed":1028,"user":{"displayName":"Minh Nhat Trinh","userId":"12425805762404293245"}},"outputId":"c7d9faf0-3af5-4097-a144-40e5db84ca7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1w-TuKfFg1p_kmorgOYNhTF-HPfPcx4Ab/brain_mri_segmentation/weight\n"]}],"source":["%cd \"/content/drive/MyDrive/brain_mri_segmentation/weight\"\n","np.savez_compressed(\"proposed\", mask_predict)"]},{"cell_type":"code","source":[],"metadata":{"id":"Hl0bts2rKht1"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["E2Y3xZbs4pqe","7Ky_Sm9W90Uk","KvDV_mvpTrA6","6Hj2Sf2wcv5k","BxnCiIzBxyln","90WG2qodcUKV","IBQgiYIcyXvG","gzAyEyor3Xci","tPiu7yXRoGl9","KyJ2U-32eULg"],"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}